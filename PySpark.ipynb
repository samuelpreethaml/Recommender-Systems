{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PySpark",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "dyRLRBeslCts",
        "colab_type": "code",
        "outputId": "f0060601-d8cd-4ea3-9ef0-79de181558b7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "tf.test.gpu_device_name()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/device:GPU:0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6k4WH02IlTk8",
        "colab_type": "code",
        "outputId": "1f3b487e-2cbe-4cbd-87dc-5fc159e10657",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!pip install pyspark\n",
        "!pip install findspark\n",
        "!pip install tensorflowonspark\n",
        "!pip install sparkdl\n",
        "!pip install tensorframes\n",
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "!wget -q  https://www-us.apache.org/dist/spark/spark-2.4.4/spark-2.4.4-bin-hadoop2.7.tgz\n",
        "!tar xvf spark-2.4.4-bin-hadoop2.7.tgz"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pyspark\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/87/21/f05c186f4ddb01d15d0ddc36ef4b7e3cedbeb6412274a41f26b55a650ee5/pyspark-2.4.4.tar.gz (215.7MB)\n",
            "\u001b[K     |████████████████████████████████| 215.7MB 48kB/s \n",
            "\u001b[?25hCollecting py4j==0.10.7 (from pyspark)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e3/53/c737818eb9a7dc32a7cd4f1396e787bd94200c3997c72c1dbe028587bd76/py4j-0.10.7-py2.py3-none-any.whl (197kB)\n",
            "\u001b[K     |████████████████████████████████| 204kB 47.0MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-2.4.4-py2.py3-none-any.whl size=216130387 sha256=c48366a307fa67a4db88b9a28d1144563ff2b9640e376d44bcc466a002135afe\n",
            "  Stored in directory: /root/.cache/pip/wheels/ab/09/4d/0d184230058e654eb1b04467dbc1292f00eaa186544604b471\n",
            "Successfully built pyspark\n",
            "Installing collected packages: py4j, pyspark\n",
            "Successfully installed py4j-0.10.7 pyspark-2.4.4\n",
            "Collecting findspark\n",
            "  Downloading https://files.pythonhosted.org/packages/b1/c8/e6e1f6a303ae5122dc28d131b5a67c5eb87cbf8f7ac5b9f87764ea1b1e1e/findspark-1.3.0-py2.py3-none-any.whl\n",
            "Installing collected packages: findspark\n",
            "Successfully installed findspark-1.3.0\n",
            "Collecting tensorflowonspark\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/98/d4/ca4b466f40522ff34991ecc6e6f31ca9de8aa7efd226b89534e9a39bd8d9/tensorflowonspark-1.4.3-py2.py3-none-any.whl (41kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 8.5MB/s \n",
            "\u001b[?25hInstalling collected packages: tensorflowonspark\n",
            "Successfully installed tensorflowonspark-1.4.3\n",
            "Collecting sparkdl\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/70/e6/c520f801b945f3d03dbf47e1abb7a454cda328d1592f9854dcec69bed097/sparkdl-0.2.2-py3-none-any.whl (99kB)\n",
            "\u001b[K     |████████████████████████████████| 102kB 5.9MB/s \n",
            "\u001b[?25hInstalling collected packages: sparkdl\n",
            "Successfully installed sparkdl-0.2.2\n",
            "Collecting tensorframes\n",
            "  Downloading https://files.pythonhosted.org/packages/59/ae/e8607d0bc5d722694250dcfce59cc9d530e93406079c7d1bf4cb4bbe9d9a/tensorframes-0.2.9-py3-none-any.whl\n",
            "Installing collected packages: tensorframes\n",
            "Successfully installed tensorframes-0.2.9\n",
            "spark-2.4.4-bin-hadoop2.7/\n",
            "spark-2.4.4-bin-hadoop2.7/R/\n",
            "spark-2.4.4-bin-hadoop2.7/R/lib/\n",
            "spark-2.4.4-bin-hadoop2.7/R/lib/sparkr.zip\n",
            "spark-2.4.4-bin-hadoop2.7/R/lib/SparkR/\n",
            "spark-2.4.4-bin-hadoop2.7/R/lib/SparkR/INDEX\n",
            "spark-2.4.4-bin-hadoop2.7/R/lib/SparkR/html/\n",
            "spark-2.4.4-bin-hadoop2.7/R/lib/SparkR/html/R.css\n",
            "spark-2.4.4-bin-hadoop2.7/R/lib/SparkR/html/00Index.html\n",
            "spark-2.4.4-bin-hadoop2.7/R/lib/SparkR/help/\n",
            "spark-2.4.4-bin-hadoop2.7/R/lib/SparkR/help/aliases.rds\n",
            "spark-2.4.4-bin-hadoop2.7/R/lib/SparkR/help/AnIndex\n",
            "spark-2.4.4-bin-hadoop2.7/R/lib/SparkR/help/SparkR.rdx\n",
            "spark-2.4.4-bin-hadoop2.7/R/lib/SparkR/help/SparkR.rdb\n",
            "spark-2.4.4-bin-hadoop2.7/R/lib/SparkR/help/paths.rds\n",
            "spark-2.4.4-bin-hadoop2.7/R/lib/SparkR/worker/\n",
            "spark-2.4.4-bin-hadoop2.7/R/lib/SparkR/worker/worker.R\n",
            "spark-2.4.4-bin-hadoop2.7/R/lib/SparkR/worker/daemon.R\n",
            "spark-2.4.4-bin-hadoop2.7/R/lib/SparkR/tests/\n",
            "spark-2.4.4-bin-hadoop2.7/R/lib/SparkR/tests/testthat/\n",
            "spark-2.4.4-bin-hadoop2.7/R/lib/SparkR/tests/testthat/test_basic.R\n",
            "spark-2.4.4-bin-hadoop2.7/R/lib/SparkR/profile/\n",
            "spark-2.4.4-bin-hadoop2.7/R/lib/SparkR/profile/shell.R\n",
            "spark-2.4.4-bin-hadoop2.7/R/lib/SparkR/profile/general.R\n",
            "spark-2.4.4-bin-hadoop2.7/R/lib/SparkR/R/\n",
            "spark-2.4.4-bin-hadoop2.7/R/lib/SparkR/R/SparkR.rdx\n",
            "spark-2.4.4-bin-hadoop2.7/R/lib/SparkR/R/SparkR.rdb\n",
            "spark-2.4.4-bin-hadoop2.7/R/lib/SparkR/R/SparkR\n",
            "spark-2.4.4-bin-hadoop2.7/R/lib/SparkR/Meta/\n",
            "spark-2.4.4-bin-hadoop2.7/R/lib/SparkR/Meta/nsInfo.rds\n",
            "spark-2.4.4-bin-hadoop2.7/R/lib/SparkR/Meta/links.rds\n",
            "spark-2.4.4-bin-hadoop2.7/R/lib/SparkR/Meta/hsearch.rds\n",
            "spark-2.4.4-bin-hadoop2.7/R/lib/SparkR/Meta/Rd.rds\n",
            "spark-2.4.4-bin-hadoop2.7/R/lib/SparkR/Meta/features.rds\n",
            "spark-2.4.4-bin-hadoop2.7/R/lib/SparkR/Meta/package.rds\n",
            "spark-2.4.4-bin-hadoop2.7/R/lib/SparkR/DESCRIPTION\n",
            "spark-2.4.4-bin-hadoop2.7/R/lib/SparkR/NAMESPACE\n",
            "spark-2.4.4-bin-hadoop2.7/sbin/\n",
            "spark-2.4.4-bin-hadoop2.7/sbin/stop-shuffle-service.sh\n",
            "spark-2.4.4-bin-hadoop2.7/sbin/start-thriftserver.sh\n",
            "spark-2.4.4-bin-hadoop2.7/sbin/start-slave.sh\n",
            "spark-2.4.4-bin-hadoop2.7/sbin/start-shuffle-service.sh\n",
            "spark-2.4.4-bin-hadoop2.7/sbin/start-mesos-shuffle-service.sh\n",
            "spark-2.4.4-bin-hadoop2.7/sbin/start-master.sh\n",
            "spark-2.4.4-bin-hadoop2.7/sbin/start-history-server.sh\n",
            "spark-2.4.4-bin-hadoop2.7/sbin/spark-config.sh\n",
            "spark-2.4.4-bin-hadoop2.7/sbin/stop-thriftserver.sh\n",
            "spark-2.4.4-bin-hadoop2.7/sbin/stop-slaves.sh\n",
            "spark-2.4.4-bin-hadoop2.7/sbin/stop-slave.sh\n",
            "spark-2.4.4-bin-hadoop2.7/sbin/stop-mesos-shuffle-service.sh\n",
            "spark-2.4.4-bin-hadoop2.7/sbin/stop-mesos-dispatcher.sh\n",
            "spark-2.4.4-bin-hadoop2.7/sbin/stop-master.sh\n",
            "spark-2.4.4-bin-hadoop2.7/sbin/stop-history-server.sh\n",
            "spark-2.4.4-bin-hadoop2.7/sbin/stop-all.sh\n",
            "spark-2.4.4-bin-hadoop2.7/sbin/start-slaves.sh\n",
            "spark-2.4.4-bin-hadoop2.7/sbin/start-mesos-dispatcher.sh\n",
            "spark-2.4.4-bin-hadoop2.7/sbin/start-all.sh\n",
            "spark-2.4.4-bin-hadoop2.7/sbin/spark-daemons.sh\n",
            "spark-2.4.4-bin-hadoop2.7/sbin/spark-daemon.sh\n",
            "spark-2.4.4-bin-hadoop2.7/sbin/slaves.sh\n",
            "spark-2.4.4-bin-hadoop2.7/python/\n",
            "spark-2.4.4-bin-hadoop2.7/python/dist/\n",
            "spark-2.4.4-bin-hadoop2.7/python/pyspark.egg-info/\n",
            "spark-2.4.4-bin-hadoop2.7/python/pyspark.egg-info/SOURCES.txt\n",
            "spark-2.4.4-bin-hadoop2.7/python/pyspark.egg-info/dependency_links.txt\n",
            "spark-2.4.4-bin-hadoop2.7/python/pyspark.egg-info/top_level.txt\n",
            "spark-2.4.4-bin-hadoop2.7/python/pyspark.egg-info/PKG-INFO\n",
            "spark-2.4.4-bin-hadoop2.7/python/pyspark.egg-info/requires.txt\n",
            "spark-2.4.4-bin-hadoop2.7/python/README.md\n",
            "spark-2.4.4-bin-hadoop2.7/python/MANIFEST.in\n",
            "spark-2.4.4-bin-hadoop2.7/python/setup.py\n",
            "spark-2.4.4-bin-hadoop2.7/python/run-tests.py\n",
            "spark-2.4.4-bin-hadoop2.7/python/run-tests-with-coverage\n",
            "spark-2.4.4-bin-hadoop2.7/python/test_support/\n",
            "spark-2.4.4-bin-hadoop2.7/python/test_support/userlibrary.py\n",
            "spark-2.4.4-bin-hadoop2.7/python/test_support/userlib-0.1.zip\n",
            "spark-2.4.4-bin-hadoop2.7/python/test_support/sql/\n",
            "spark-2.4.4-bin-hadoop2.7/python/test_support/sql/text-test.txt\n",
            "spark-2.4.4-bin-hadoop2.7/python/test_support/sql/streaming/\n",
            "spark-2.4.4-bin-hadoop2.7/python/test_support/sql/streaming/text-test.txt\n",
            "spark-2.4.4-bin-hadoop2.7/python/test_support/sql/people_array_utf16le.json\n",
            "spark-2.4.4-bin-hadoop2.7/python/test_support/sql/people_array.json\n",
            "spark-2.4.4-bin-hadoop2.7/python/test_support/sql/people1.json\n",
            "spark-2.4.4-bin-hadoop2.7/python/test_support/sql/people.json\n",
            "spark-2.4.4-bin-hadoop2.7/python/test_support/sql/parquet_partitioned/\n",
            "spark-2.4.4-bin-hadoop2.7/python/test_support/sql/parquet_partitioned/year=2015/\n",
            "spark-2.4.4-bin-hadoop2.7/python/test_support/sql/parquet_partitioned/year=2015/month=9/\n",
            "spark-2.4.4-bin-hadoop2.7/python/test_support/sql/parquet_partitioned/year=2015/month=9/day=1/\n",
            "spark-2.4.4-bin-hadoop2.7/python/test_support/sql/parquet_partitioned/year=2015/month=9/day=1/part-r-00007.gz.parquet\n",
            "spark-2.4.4-bin-hadoop2.7/python/test_support/sql/parquet_partitioned/year=2015/month=9/day=1/.part-r-00007.gz.parquet.crc\n",
            "spark-2.4.4-bin-hadoop2.7/python/test_support/sql/parquet_partitioned/year=2015/month=10/\n",
            "spark-2.4.4-bin-hadoop2.7/python/test_support/sql/parquet_partitioned/year=2015/month=10/day=26/\n",
            "spark-2.4.4-bin-hadoop2.7/python/test_support/sql/parquet_partitioned/year=2015/month=10/day=26/part-r-00005.gz.parquet\n",
            "spark-2.4.4-bin-hadoop2.7/python/test_support/sql/parquet_partitioned/year=2015/month=10/day=26/.part-r-00005.gz.parquet.crc\n",
            "spark-2.4.4-bin-hadoop2.7/python/test_support/sql/parquet_partitioned/year=2015/month=10/day=25/\n",
            "spark-2.4.4-bin-hadoop2.7/python/test_support/sql/parquet_partitioned/year=2015/month=10/day=25/part-r-00004.gz.parquet\n",
            "spark-2.4.4-bin-hadoop2.7/python/test_support/sql/parquet_partitioned/year=2015/month=10/day=25/part-r-00002.gz.parquet\n",
            "spark-2.4.4-bin-hadoop2.7/python/test_support/sql/parquet_partitioned/year=2015/month=10/day=25/.part-r-00004.gz.parquet.crc\n",
            "spark-2.4.4-bin-hadoop2.7/python/test_support/sql/parquet_partitioned/year=2015/month=10/day=25/.part-r-00002.gz.parquet.crc\n",
            "spark-2.4.4-bin-hadoop2.7/python/test_support/sql/parquet_partitioned/year=2014/\n",
            "spark-2.4.4-bin-hadoop2.7/python/test_support/sql/parquet_partitioned/year=2014/month=9/\n",
            "spark-2.4.4-bin-hadoop2.7/python/test_support/sql/parquet_partitioned/year=2014/month=9/day=1/\n",
            "spark-2.4.4-bin-hadoop2.7/python/test_support/sql/parquet_partitioned/year=2014/month=9/day=1/part-r-00008.gz.parquet\n",
            "spark-2.4.4-bin-hadoop2.7/python/test_support/sql/parquet_partitioned/year=2014/month=9/day=1/.part-r-00008.gz.parquet.crc\n",
            "spark-2.4.4-bin-hadoop2.7/python/test_support/sql/parquet_partitioned/_metadata\n",
            "spark-2.4.4-bin-hadoop2.7/python/test_support/sql/parquet_partitioned/_common_metadata\n",
            "spark-2.4.4-bin-hadoop2.7/python/test_support/sql/parquet_partitioned/_SUCCESS\n",
            "spark-2.4.4-bin-hadoop2.7/python/test_support/sql/orc_partitioned/\n",
            "spark-2.4.4-bin-hadoop2.7/python/test_support/sql/orc_partitioned/b=1/\n",
            "spark-2.4.4-bin-hadoop2.7/python/test_support/sql/orc_partitioned/b=1/c=1/\n",
            "spark-2.4.4-bin-hadoop2.7/python/test_support/sql/orc_partitioned/b=1/c=1/part-r-00000-829af031-b970-49d6-ad39-30460a0be2c8.orc\n",
            "spark-2.4.4-bin-hadoop2.7/python/test_support/sql/orc_partitioned/b=1/c=1/.part-r-00000-829af031-b970-49d6-ad39-30460a0be2c8.orc.crc\n",
            "spark-2.4.4-bin-hadoop2.7/python/test_support/sql/orc_partitioned/b=0/\n",
            "spark-2.4.4-bin-hadoop2.7/python/test_support/sql/orc_partitioned/b=0/c=0/\n",
            "spark-2.4.4-bin-hadoop2.7/python/test_support/sql/orc_partitioned/b=0/c=0/part-r-00000-829af031-b970-49d6-ad39-30460a0be2c8.orc\n",
            "spark-2.4.4-bin-hadoop2.7/python/test_support/sql/orc_partitioned/b=0/c=0/.part-r-00000-829af031-b970-49d6-ad39-30460a0be2c8.orc.crc\n",
            "spark-2.4.4-bin-hadoop2.7/python/test_support/sql/orc_partitioned/_SUCCESS\n",
            "spark-2.4.4-bin-hadoop2.7/python/test_support/sql/ages_newlines.csv\n",
            "spark-2.4.4-bin-hadoop2.7/python/test_support/sql/ages.csv\n",
            "spark-2.4.4-bin-hadoop2.7/python/test_support/hello/\n",
            "spark-2.4.4-bin-hadoop2.7/python/test_support/hello/sub_hello/\n",
            "spark-2.4.4-bin-hadoop2.7/python/test_support/hello/sub_hello/sub_hello.txt\n",
            "spark-2.4.4-bin-hadoop2.7/python/test_support/hello/hello.txt\n",
            "spark-2.4.4-bin-hadoop2.7/python/test_support/SimpleHTTPServer.py\n",
            "spark-2.4.4-bin-hadoop2.7/python/test_coverage/\n",
            "spark-2.4.4-bin-hadoop2.7/python/test_coverage/sitecustomize.py\n",
            "spark-2.4.4-bin-hadoop2.7/python/test_coverage/coverage_daemon.py\n",
            "spark-2.4.4-bin-hadoop2.7/python/test_coverage/conf/\n",
            "spark-2.4.4-bin-hadoop2.7/python/test_coverage/conf/spark-defaults.conf\n",
            "spark-2.4.4-bin-hadoop2.7/python/setup.cfg\n",
            "spark-2.4.4-bin-hadoop2.7/python/run-tests\n",
            "spark-2.4.4-bin-hadoop2.7/python/pyspark/\n",
            "spark-2.4.4-bin-hadoop2.7/python/pyspark/python/\n",
            "spark-2.4.4-bin-hadoop2.7/python/pyspark/python/pyspark/\n",
            "spark-2.4.4-bin-hadoop2.7/python/pyspark/python/pyspark/shell.py\n",
            "spark-2.4.4-bin-hadoop2.7/python/pyspark/shuffle.py\n",
            "spark-2.4.4-bin-hadoop2.7/python/pyspark/serializers.py\n",
            "spark-2.4.4-bin-hadoop2.7/python/pyspark/rdd.py\n",
            "spark-2.4.4-bin-hadoop2.7/python/pyspark/profiler.py\n",
            "spark-2.4.4-bin-hadoop2.7/python/pyspark/java_gateway.py\n",
            "spark-2.4.4-bin-hadoop2.7/python/pyspark/files.py\n",
            "spark-2.4.4-bin-hadoop2.7/python/pyspark/daemon.py\n",
            "spark-2.4.4-bin-hadoop2.7/python/pyspark/context.py\n",
            "spark-2.4.4-bin-hadoop2.7/python/pyspark/conf.py\n",
            "spark-2.4.4-bin-hadoop2.7/python/pyspark/cloudpickle.py\n",
            "spark-2.4.4-bin-hadoop2.7/python/pyspark/broadcast.py\n",
            "spark-2.4.4-bin-hadoop2.7/python/pyspark/accumulators.py\n",
            "spark-2.4.4-bin-hadoop2.7/python/pyspark/__init__.py\n",
            "spark-2.4.4-bin-hadoop2.7/python/pyspark/worker.py\n",
            "spark-2.4.4-bin-hadoop2.7/python/pyspark/version.py\n",
            "spark-2.4.4-bin-hadoop2.7/python/pyspark/util.py\n",
            "spark-2.4.4-bin-hadoop2.7/python/pyspark/tests.py\n",
            "spark-2.4.4-bin-hadoop2.7/python/pyspark/test_serializers.py\n",
            "spark-2.4.4-bin-hadoop2.7/python/pyspark/test_broadcast.py\n",
            "spark-2.4.4-bin-hadoop2.7/python/pyspark/taskcontext.py\n",
            "spark-2.4.4-bin-hadoop2.7/python/pyspark/storagelevel.py\n",
            "spark-2.4.4-bin-hadoop2.7/python/pyspark/traceback_utils.py\n",
            "spark-2.4.4-bin-hadoop2.7/python/pyspark/streaming/\n",
            "spark-2.4.4-bin-hadoop2.7/python/pyspark/streaming/tests.py\n",
            "spark-2.4.4-bin-hadoop2.7/python/pyspark/streaming/kinesis.py\n",
            "spark-2.4.4-bin-hadoop2.7/python/pyspark/streaming/kafka.py\n",
            "spark-2.4.4-bin-hadoop2.7/python/pyspark/streaming/flume.py\n",
            "spark-2.4.4-bin-hadoop2.7/python/pyspark/streaming/dstream.py\n",
            "spark-2.4.4-bin-hadoop2.7/python/pyspark/streaming/context.py\n",
            "spark-2.4.4-bin-hadoop2.7/python/pyspark/streaming/util.py\n",
            "spark-2.4.4-bin-hadoop2.7/python/pyspark/streaming/listener.py\n",
            "spark-2.4.4-bin-hadoop2.7/python/pyspark/streaming/__init__.py\n",
            "spark-2.4.4-bin-hadoop2.7/python/pyspark/status.py\n",
            "spark-2.4.4-bin-hadoop2.7/python/pyspark/statcounter.py\n",
            "spark-2.4.4-bin-hadoop2.7/python/pyspark/sql/\n",
            "spark-2.4.4-bin-hadoop2.7/python/pyspark/sql/tests.py\n",
            "spark-2.4.4-bin-hadoop2.7/python/pyspark/sql/streaming.py\n",
            "spark-2.4.4-bin-hadoop2.7/python/pyspark/sql/session.py\n",
            "spark-2.4.4-bin-hadoop2.7/python/pyspark/sql/readwriter.py\n",
            "spark-2.4.4-bin-hadoop2.7/python/pyspark/sql/functions.py\n",
            "spark-2.4.4-bin-hadoop2.7/python/pyspark/sql/dataframe.py\n",
            "spark-2.4.4-bin-hadoop2.7/python/pyspark/sql/context.py\n",
            "spark-2.4.4-bin-hadoop2.7/python/pyspark/sql/window.py\n",
            "spark-2.4.4-bin-hadoop2.7/python/pyspark/sql/utils.py\n",
            "spark-2.4.4-bin-hadoop2.7/python/pyspark/sql/udf.py\n",
            "spark-2.4.4-bin-hadoop2.7/python/pyspark/sql/types.py\n",
            "spark-2.4.4-bin-hadoop2.7/python/pyspark/sql/group.py\n",
            "spark-2.4.4-bin-hadoop2.7/python/pyspark/sql/conf.py\n",
            "spark-2.4.4-bin-hadoop2.7/python/pyspark/sql/column.py\n",
            "spark-2.4.4-bin-hadoop2.7/python/pyspark/sql/catalog.py\n",
            "spark-2.4.4-bin-hadoop2.7/python/pyspark/sql/__init__.py\n",
            "spark-2.4.4-bin-hadoop2.7/python/pyspark/shell.py\n",
            "spark-2.4.4-bin-hadoop2.7/python/pyspark/resultiterable.py\n",
            "spark-2.4.4-bin-hadoop2.7/python/pyspark/rddsampler.py\n",
            "spark-2.4.4-bin-hadoop2.7/python/pyspark/mllib/\n",
            "spark-2.4.4-bin-hadoop2.7/python/pyspark/mllib/util.py\n",
            "spark-2.4.4-bin-hadoop2.7/python/pyspark/mllib/tree.py\n",
            "spark-2.4.4-bin-hadoop2.7/python/pyspark/mllib/tests.py\n",
            "spark-2.4.4-bin-hadoop2.7/python/pyspark/mllib/regression.py\n",
            "spark-2.4.4-bin-hadoop2.7/python/pyspark/mllib/recommendation.py\n",
            "spark-2.4.4-bin-hadoop2.7/python/pyspark/mllib/random.py\n",
            "spark-2.4.4-bin-hadoop2.7/python/pyspark/mllib/fpm.py\n",
            "spark-2.4.4-bin-hadoop2.7/python/pyspark/mllib/feature.py\n",
            "spark-2.4.4-bin-hadoop2.7/python/pyspark/mllib/evaluation.py\n",
            "spark-2.4.4-bin-hadoop2.7/python/pyspark/mllib/clustering.py\n",
            "spark-2.4.4-bin-hadoop2.7/python/pyspark/mllib/classification.py\n",
            "spark-2.4.4-bin-hadoop2.7/python/pyspark/mllib/stat/\n",
            "spark-2.4.4-bin-hadoop2.7/python/pyspark/mllib/stat/_statistics.py\n",
            "spark-2.4.4-bin-hadoop2.7/python/pyspark/mllib/stat/test.py\n",
            "spark-2.4.4-bin-hadoop2.7/python/pyspark/mllib/stat/distribution.py\n",
            "spark-2.4.4-bin-hadoop2.7/python/pyspark/mllib/stat/__init__.py\n",
            "spark-2.4.4-bin-hadoop2.7/python/pyspark/mllib/stat/KernelDensity.py\n",
            "spark-2.4.4-bin-hadoop2.7/python/pyspark/mllib/linalg/\n",
            "spark-2.4.4-bin-hadoop2.7/python/pyspark/mllib/linalg/distributed.py\n",
            "spark-2.4.4-bin-hadoop2.7/python/pyspark/mllib/linalg/__init__.py\n",
            "spark-2.4.4-bin-hadoop2.7/python/pyspark/mllib/common.py\n",
            "spark-2.4.4-bin-hadoop2.7/python/pyspark/mllib/__init__.py\n",
            "spark-2.4.4-bin-hadoop2.7/python/pyspark/ml/\n",
            "spark-2.4.4-bin-hadoop2.7/python/pyspark/ml/wrapper.py\n",
            "spark-2.4.4-bin-hadoop2.7/python/pyspark/ml/util.py\n",
            "spark-2.4.4-bin-hadoop2.7/python/pyspark/ml/tuning.py\n",
            "spark-2.4.4-bin-hadoop2.7/python/pyspark/ml/tests.py\n",
            "spark-2.4.4-bin-hadoop2.7/python/pyspark/ml/regression.py\n",
            "spark-2.4.4-bin-hadoop2.7/python/pyspark/ml/recommendation.py\n",
            "spark-2.4.4-bin-hadoop2.7/python/pyspark/ml/image.py\n",
            "spark-2.4.4-bin-hadoop2.7/python/pyspark/ml/fpm.py\n",
            "spark-2.4.4-bin-hadoop2.7/python/pyspark/ml/feature.py\n",
            "spark-2.4.4-bin-hadoop2.7/python/pyspark/ml/evaluation.py\n",
            "spark-2.4.4-bin-hadoop2.7/python/pyspark/ml/clustering.py\n",
            "spark-2.4.4-bin-hadoop2.7/python/pyspark/ml/classification.py\n",
            "spark-2.4.4-bin-hadoop2.7/python/pyspark/ml/stat.py\n",
            "spark-2.4.4-bin-hadoop2.7/python/pyspark/ml/pipeline.py\n",
            "spark-2.4.4-bin-hadoop2.7/python/pyspark/ml/param/\n",
            "spark-2.4.4-bin-hadoop2.7/python/pyspark/ml/param/shared.py\n",
            "spark-2.4.4-bin-hadoop2.7/python/pyspark/ml/param/_shared_params_code_gen.py\n",
            "spark-2.4.4-bin-hadoop2.7/python/pyspark/ml/param/__init__.py\n",
            "spark-2.4.4-bin-hadoop2.7/python/pyspark/ml/linalg/\n",
            "spark-2.4.4-bin-hadoop2.7/python/pyspark/ml/linalg/__init__.py\n",
            "spark-2.4.4-bin-hadoop2.7/python/pyspark/ml/common.py\n",
            "spark-2.4.4-bin-hadoop2.7/python/pyspark/ml/base.py\n",
            "spark-2.4.4-bin-hadoop2.7/python/pyspark/ml/__init__.py\n",
            "spark-2.4.4-bin-hadoop2.7/python/pyspark/join.py\n",
            "spark-2.4.4-bin-hadoop2.7/python/pyspark/heapq3.py\n",
            "spark-2.4.4-bin-hadoop2.7/python/pyspark/find_spark_home.py\n",
            "spark-2.4.4-bin-hadoop2.7/python/pyspark/_globals.py\n",
            "spark-2.4.4-bin-hadoop2.7/python/pylintrc\n",
            "spark-2.4.4-bin-hadoop2.7/python/lib/\n",
            "spark-2.4.4-bin-hadoop2.7/python/lib/pyspark.zip\n",
            "spark-2.4.4-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip\n",
            "spark-2.4.4-bin-hadoop2.7/python/lib/PY4J_LICENSE.txt\n",
            "spark-2.4.4-bin-hadoop2.7/python/docs/\n",
            "spark-2.4.4-bin-hadoop2.7/python/docs/pyspark.streaming.rst\n",
            "spark-2.4.4-bin-hadoop2.7/python/docs/pyspark.sql.rst\n",
            "spark-2.4.4-bin-hadoop2.7/python/docs/epytext.py\n",
            "spark-2.4.4-bin-hadoop2.7/python/docs/conf.py\n",
            "spark-2.4.4-bin-hadoop2.7/python/docs/Makefile\n",
            "spark-2.4.4-bin-hadoop2.7/python/docs/pyspark.rst\n",
            "spark-2.4.4-bin-hadoop2.7/python/docs/pyspark.mllib.rst\n",
            "spark-2.4.4-bin-hadoop2.7/python/docs/pyspark.ml.rst\n",
            "spark-2.4.4-bin-hadoop2.7/python/docs/make2.bat\n",
            "spark-2.4.4-bin-hadoop2.7/python/docs/make.bat\n",
            "spark-2.4.4-bin-hadoop2.7/python/docs/index.rst\n",
            "spark-2.4.4-bin-hadoop2.7/python/docs/_templates/\n",
            "spark-2.4.4-bin-hadoop2.7/python/docs/_templates/layout.html\n",
            "spark-2.4.4-bin-hadoop2.7/python/docs/_static/\n",
            "spark-2.4.4-bin-hadoop2.7/python/docs/_static/pyspark.js\n",
            "spark-2.4.4-bin-hadoop2.7/python/docs/_static/pyspark.css\n",
            "spark-2.4.4-bin-hadoop2.7/python/.gitignore\n",
            "spark-2.4.4-bin-hadoop2.7/python/.coveragerc\n",
            "spark-2.4.4-bin-hadoop2.7/bin/\n",
            "spark-2.4.4-bin-hadoop2.7/bin/spark-class\n",
            "spark-2.4.4-bin-hadoop2.7/bin/pyspark2.cmd\n",
            "spark-2.4.4-bin-hadoop2.7/bin/pyspark\n",
            "spark-2.4.4-bin-hadoop2.7/bin/load-spark-env.sh\n",
            "spark-2.4.4-bin-hadoop2.7/bin/load-spark-env.cmd\n",
            "spark-2.4.4-bin-hadoop2.7/bin/docker-image-tool.sh\n",
            "spark-2.4.4-bin-hadoop2.7/bin/sparkR2.cmd\n",
            "spark-2.4.4-bin-hadoop2.7/bin/sparkR.cmd\n",
            "spark-2.4.4-bin-hadoop2.7/bin/sparkR\n",
            "spark-2.4.4-bin-hadoop2.7/bin/spark-submit2.cmd\n",
            "spark-2.4.4-bin-hadoop2.7/bin/spark-submit.cmd\n",
            "spark-2.4.4-bin-hadoop2.7/bin/spark-submit\n",
            "spark-2.4.4-bin-hadoop2.7/bin/spark-sql2.cmd\n",
            "spark-2.4.4-bin-hadoop2.7/bin/spark-sql.cmd\n",
            "spark-2.4.4-bin-hadoop2.7/bin/spark-sql\n",
            "spark-2.4.4-bin-hadoop2.7/bin/spark-shell2.cmd\n",
            "spark-2.4.4-bin-hadoop2.7/bin/spark-shell.cmd\n",
            "spark-2.4.4-bin-hadoop2.7/bin/spark-shell\n",
            "spark-2.4.4-bin-hadoop2.7/bin/spark-class2.cmd\n",
            "spark-2.4.4-bin-hadoop2.7/bin/spark-class.cmd\n",
            "spark-2.4.4-bin-hadoop2.7/bin/run-example.cmd\n",
            "spark-2.4.4-bin-hadoop2.7/bin/run-example\n",
            "spark-2.4.4-bin-hadoop2.7/bin/pyspark.cmd\n",
            "spark-2.4.4-bin-hadoop2.7/bin/find-spark-home.cmd\n",
            "spark-2.4.4-bin-hadoop2.7/bin/find-spark-home\n",
            "spark-2.4.4-bin-hadoop2.7/bin/beeline.cmd\n",
            "spark-2.4.4-bin-hadoop2.7/bin/beeline\n",
            "spark-2.4.4-bin-hadoop2.7/README.md\n",
            "spark-2.4.4-bin-hadoop2.7/conf/\n",
            "spark-2.4.4-bin-hadoop2.7/conf/spark-env.sh.template\n",
            "spark-2.4.4-bin-hadoop2.7/conf/spark-defaults.conf.template\n",
            "spark-2.4.4-bin-hadoop2.7/conf/slaves.template\n",
            "spark-2.4.4-bin-hadoop2.7/conf/metrics.properties.template\n",
            "spark-2.4.4-bin-hadoop2.7/conf/log4j.properties.template\n",
            "spark-2.4.4-bin-hadoop2.7/conf/fairscheduler.xml.template\n",
            "spark-2.4.4-bin-hadoop2.7/conf/docker.properties.template\n",
            "spark-2.4.4-bin-hadoop2.7/data/\n",
            "spark-2.4.4-bin-hadoop2.7/data/mllib/\n",
            "spark-2.4.4-bin-hadoop2.7/data/mllib/gmm_data.txt\n",
            "spark-2.4.4-bin-hadoop2.7/data/mllib/als/\n",
            "spark-2.4.4-bin-hadoop2.7/data/mllib/als/test.data\n",
            "spark-2.4.4-bin-hadoop2.7/data/mllib/als/sample_movielens_ratings.txt\n",
            "spark-2.4.4-bin-hadoop2.7/data/mllib/streaming_kmeans_data_test.txt\n",
            "spark-2.4.4-bin-hadoop2.7/data/mllib/sample_svm_data.txt\n",
            "spark-2.4.4-bin-hadoop2.7/data/mllib/sample_multiclass_classification_data.txt\n",
            "spark-2.4.4-bin-hadoop2.7/data/mllib/sample_movielens_data.txt\n",
            "spark-2.4.4-bin-hadoop2.7/data/mllib/sample_linear_regression_data.txt\n",
            "spark-2.4.4-bin-hadoop2.7/data/mllib/sample_libsvm_data.txt\n",
            "spark-2.4.4-bin-hadoop2.7/data/mllib/sample_lda_libsvm_data.txt\n",
            "spark-2.4.4-bin-hadoop2.7/data/mllib/sample_lda_data.txt\n",
            "spark-2.4.4-bin-hadoop2.7/data/mllib/sample_kmeans_data.txt\n",
            "spark-2.4.4-bin-hadoop2.7/data/mllib/sample_isotonic_regression_libsvm_data.txt\n",
            "spark-2.4.4-bin-hadoop2.7/data/mllib/sample_fpgrowth.txt\n",
            "spark-2.4.4-bin-hadoop2.7/data/mllib/sample_binary_classification_data.txt\n",
            "spark-2.4.4-bin-hadoop2.7/data/mllib/ridge-data/\n",
            "spark-2.4.4-bin-hadoop2.7/data/mllib/ridge-data/lpsa.data\n",
            "spark-2.4.4-bin-hadoop2.7/data/mllib/pic_data.txt\n",
            "spark-2.4.4-bin-hadoop2.7/data/mllib/pagerank_data.txt\n",
            "spark-2.4.4-bin-hadoop2.7/data/mllib/kmeans_data.txt\n",
            "spark-2.4.4-bin-hadoop2.7/data/mllib/iris_libsvm.txt\n",
            "spark-2.4.4-bin-hadoop2.7/data/mllib/images/\n",
            "spark-2.4.4-bin-hadoop2.7/data/mllib/images/partitioned/\n",
            "spark-2.4.4-bin-hadoop2.7/data/mllib/images/partitioned/cls=multichannel/\n",
            "spark-2.4.4-bin-hadoop2.7/data/mllib/images/partitioned/cls=multichannel/date=2018-02/\n",
            "spark-2.4.4-bin-hadoop2.7/data/mllib/images/partitioned/cls=multichannel/date=2018-02/grayscale.jpg\n",
            "spark-2.4.4-bin-hadoop2.7/data/mllib/images/partitioned/cls=multichannel/date=2018-02/chr30.4.184.jpg\n",
            "spark-2.4.4-bin-hadoop2.7/data/mllib/images/partitioned/cls=multichannel/date=2018-01/\n",
            "spark-2.4.4-bin-hadoop2.7/data/mllib/images/partitioned/cls=multichannel/date=2018-01/BGRA_alpha_60.png\n",
            "spark-2.4.4-bin-hadoop2.7/data/mllib/images/partitioned/cls=multichannel/date=2018-01/BGRA.png\n",
            "spark-2.4.4-bin-hadoop2.7/data/mllib/images/partitioned/cls=kittens/\n",
            "spark-2.4.4-bin-hadoop2.7/data/mllib/images/partitioned/cls=kittens/date=2018-02/\n",
            "spark-2.4.4-bin-hadoop2.7/data/mllib/images/partitioned/cls=kittens/date=2018-02/DP802813.jpg\n",
            "spark-2.4.4-bin-hadoop2.7/data/mllib/images/partitioned/cls=kittens/date=2018-02/DP153539.jpg\n",
            "spark-2.4.4-bin-hadoop2.7/data/mllib/images/partitioned/cls=kittens/date=2018-02/54893.jpg\n",
            "spark-2.4.4-bin-hadoop2.7/data/mllib/images/partitioned/cls=kittens/date=2018-01/\n",
            "spark-2.4.4-bin-hadoop2.7/data/mllib/images/partitioned/cls=kittens/date=2018-01/not-image.txt\n",
            "spark-2.4.4-bin-hadoop2.7/data/mllib/images/partitioned/cls=kittens/date=2018-01/29.5.a_b_EGDP022204.jpg\n",
            "spark-2.4.4-bin-hadoop2.7/data/mllib/images/origin/\n",
            "spark-2.4.4-bin-hadoop2.7/data/mllib/images/origin/multi-channel/\n",
            "spark-2.4.4-bin-hadoop2.7/data/mllib/images/origin/multi-channel/grayscale.jpg\n",
            "spark-2.4.4-bin-hadoop2.7/data/mllib/images/origin/multi-channel/chr30.4.184.jpg\n",
            "spark-2.4.4-bin-hadoop2.7/data/mllib/images/origin/multi-channel/BGRA_alpha_60.png\n",
            "spark-2.4.4-bin-hadoop2.7/data/mllib/images/origin/multi-channel/BGRA.png\n",
            "spark-2.4.4-bin-hadoop2.7/data/mllib/images/origin/license.txt\n",
            "spark-2.4.4-bin-hadoop2.7/data/mllib/images/origin/kittens/\n",
            "spark-2.4.4-bin-hadoop2.7/data/mllib/images/origin/kittens/not-image.txt\n",
            "spark-2.4.4-bin-hadoop2.7/data/mllib/images/origin/kittens/DP802813.jpg\n",
            "spark-2.4.4-bin-hadoop2.7/data/mllib/images/origin/kittens/DP153539.jpg\n",
            "spark-2.4.4-bin-hadoop2.7/data/mllib/images/origin/kittens/54893.jpg\n",
            "spark-2.4.4-bin-hadoop2.7/data/mllib/images/origin/kittens/29.5.a_b_EGDP022204.jpg\n",
            "spark-2.4.4-bin-hadoop2.7/data/mllib/images/license.txt\n",
            "spark-2.4.4-bin-hadoop2.7/data/graphx/\n",
            "spark-2.4.4-bin-hadoop2.7/data/graphx/users.txt\n",
            "spark-2.4.4-bin-hadoop2.7/data/graphx/followers.txt\n",
            "spark-2.4.4-bin-hadoop2.7/data/streaming/\n",
            "spark-2.4.4-bin-hadoop2.7/data/streaming/AFINN-111.txt\n",
            "spark-2.4.4-bin-hadoop2.7/NOTICE\n",
            "spark-2.4.4-bin-hadoop2.7/licenses/\n",
            "spark-2.4.4-bin-hadoop2.7/licenses/LICENSE-jtransforms.html\n",
            "spark-2.4.4-bin-hadoop2.7/licenses/LICENSE-json-formatter.txt\n",
            "spark-2.4.4-bin-hadoop2.7/licenses/LICENSE-jquery.txt\n",
            "spark-2.4.4-bin-hadoop2.7/licenses/LICENSE-join.txt\n",
            "spark-2.4.4-bin-hadoop2.7/licenses/LICENSE-jodd.txt\n",
            "spark-2.4.4-bin-hadoop2.7/licenses/LICENSE-jline.txt\n",
            "spark-2.4.4-bin-hadoop2.7/licenses/LICENSE-javolution.txt\n",
            "spark-2.4.4-bin-hadoop2.7/licenses/LICENSE-javassist.html\n",
            "spark-2.4.4-bin-hadoop2.7/licenses/LICENSE-janino.txt\n",
            "spark-2.4.4-bin-hadoop2.7/licenses/LICENSE-heapq.txt\n",
            "spark-2.4.4-bin-hadoop2.7/licenses/LICENSE-graphlib-dot.txt\n",
            "spark-2.4.4-bin-hadoop2.7/licenses/LICENSE-f2j.txt\n",
            "spark-2.4.4-bin-hadoop2.7/licenses/LICENSE-datatables.txt\n",
            "spark-2.4.4-bin-hadoop2.7/licenses/LICENSE-dagre-d3.txt\n",
            "spark-2.4.4-bin-hadoop2.7/licenses/LICENSE-d3.min.js.txt\n",
            "spark-2.4.4-bin-hadoop2.7/licenses/LICENSE-cloudpickle.txt\n",
            "spark-2.4.4-bin-hadoop2.7/licenses/LICENSE-bootstrap.txt\n",
            "spark-2.4.4-bin-hadoop2.7/licenses/LICENSE-automaton.txt\n",
            "spark-2.4.4-bin-hadoop2.7/licenses/LICENSE-arpack.txt\n",
            "spark-2.4.4-bin-hadoop2.7/licenses/LICENSE-antlr.txt\n",
            "spark-2.4.4-bin-hadoop2.7/licenses/LICENSE-CC0.txt\n",
            "spark-2.4.4-bin-hadoop2.7/licenses/LICENSE-AnchorJS.txt\n",
            "spark-2.4.4-bin-hadoop2.7/licenses/LICENSE-zstd.txt\n",
            "spark-2.4.4-bin-hadoop2.7/licenses/LICENSE-zstd-jni.txt\n",
            "spark-2.4.4-bin-hadoop2.7/licenses/LICENSE-xmlenc.txt\n",
            "spark-2.4.4-bin-hadoop2.7/licenses/LICENSE-vis.txt\n",
            "spark-2.4.4-bin-hadoop2.7/licenses/LICENSE-spire.txt\n",
            "spark-2.4.4-bin-hadoop2.7/licenses/LICENSE-sorttable.js.txt\n",
            "spark-2.4.4-bin-hadoop2.7/licenses/LICENSE-slf4j.txt\n",
            "spark-2.4.4-bin-hadoop2.7/licenses/LICENSE-scopt.txt\n",
            "spark-2.4.4-bin-hadoop2.7/licenses/LICENSE-scala.txt\n",
            "spark-2.4.4-bin-hadoop2.7/licenses/LICENSE-sbt-launch-lib.txt\n",
            "spark-2.4.4-bin-hadoop2.7/licenses/LICENSE-respond.txt\n",
            "spark-2.4.4-bin-hadoop2.7/licenses/LICENSE-reflectasm.txt\n",
            "spark-2.4.4-bin-hadoop2.7/licenses/LICENSE-pyrolite.txt\n",
            "spark-2.4.4-bin-hadoop2.7/licenses/LICENSE-py4j.txt\n",
            "spark-2.4.4-bin-hadoop2.7/licenses/LICENSE-protobuf.txt\n",
            "spark-2.4.4-bin-hadoop2.7/licenses/LICENSE-pmml-model.txt\n",
            "spark-2.4.4-bin-hadoop2.7/licenses/LICENSE-paranamer.txt\n",
            "spark-2.4.4-bin-hadoop2.7/licenses/LICENSE-netlib.txt\n",
            "spark-2.4.4-bin-hadoop2.7/licenses/LICENSE-mustache.txt\n",
            "spark-2.4.4-bin-hadoop2.7/licenses/LICENSE-modernizr.txt\n",
            "spark-2.4.4-bin-hadoop2.7/licenses/LICENSE-minlog.txt\n",
            "spark-2.4.4-bin-hadoop2.7/licenses/LICENSE-matchMedia-polyfill.txt\n",
            "spark-2.4.4-bin-hadoop2.7/licenses/LICENSE-machinist.txt\n",
            "spark-2.4.4-bin-hadoop2.7/licenses/LICENSE-leveldbjni.txt\n",
            "spark-2.4.4-bin-hadoop2.7/licenses/LICENSE-kryo.txt\n",
            "spark-2.4.4-bin-hadoop2.7/LICENSE\n",
            "spark-2.4.4-bin-hadoop2.7/examples/\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/scala/\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/scala/org/\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/scala/org/apache/\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/ElementwiseProductExample.scala\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/DenseKMeans.scala\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/DecisionTreeRegressionExample.scala\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/DecisionTreeClassificationExample.scala\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/CosineSimilarity.scala\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/CorrelationsExample.scala\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/Correlations.scala\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/ChiSqSelectorExample.scala\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/BisectingKMeansExample.scala\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/BinaryClassificationMetricsExample.scala\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/AssociationRulesExample.scala\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/AbstractParams.scala\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/Word2VecExample.scala\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/TallSkinnySVD.scala\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/TallSkinnyPCA.scala\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/TFIDFExample.scala\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/SummaryStatisticsExample.scala\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/StreamingTestExample.scala\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/StreamingLogisticRegression.scala\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/StreamingLinearRegressionExample.scala\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/StreamingKMeansExample.scala\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/StratifiedSamplingExample.scala\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/StandardScalerExample.scala\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/SparseNaiveBayes.scala\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/SimpleFPGrowth.scala\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/SampledRDDs.scala\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/SVMWithSGDExample.scala\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/SVDExample.scala\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/RegressionMetricsExample.scala\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/RecommendationExample.scala\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/RandomRDDGeneration.scala\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/RandomForestRegressionExample.scala\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/RandomForestClassificationExample.scala\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/PrefixSpanExample.scala\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/PowerIterationClusteringExample.scala\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/PMMLModelExportExample.scala\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/PCAOnSourceVectorExample.scala\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/PCAOnRowMatrixExample.scala\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/PCAExample.scala\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/NormalizerExample.scala\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/NaiveBayesExample.scala\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/MultivariateSummarizer.scala\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/MulticlassMetricsExample.scala\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/MultiLabelMetricsExample.scala\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/LogisticRegressionWithLBFGSExample.scala\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/LinearRegressionWithSGDExample.scala\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/LatentDirichletAllocationExample.scala\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/LDAExample.scala\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/LBFGSExample.scala\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/KernelDensityEstimationExample.scala\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/KMeansExample.scala\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/IsotonicRegressionExample.scala\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/HypothesisTestingKolmogorovSmirnovTestExample.scala\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/HypothesisTestingExample.scala\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/GradientBoostingRegressionExample.scala\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/GradientBoostingClassificationExample.scala\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/GaussianMixtureExample.scala\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/FPGrowthExample.scala\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/RankingMetricsExample.scala\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/MovieLensALS.scala\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/LinearRegression.scala\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/GradientBoostedTreesRunner.scala\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/DecisionTreeRunner.scala\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/BinaryClassification.scala\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/Word2VecExample.scala\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/VectorSlicerExample.scala\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/VectorSizeHintExample.scala\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/VectorIndexerExample.scala\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/VectorAssemblerExample.scala\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/UnaryTransformerExample.scala\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/TokenizerExample.scala\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/TfIdfExample.scala\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/SummarizerExample.scala\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/StringIndexerExample.scala\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/StopWordsRemoverExample.scala\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/StandardScalerExample.scala\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/SQLTransformerExample.scala\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/RandomForestRegressorExample.scala\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/RandomForestExample.scala\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/RFormulaExample.scala\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/QuantileDiscretizerExample.scala\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/PowerIterationClusteringExample.scala\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/PolynomialExpansionExample.scala\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/PipelineExample.scala\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/PCAExample.scala\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/OneVsRestExample.scala\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/NormalizerExample.scala\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/NaiveBayesExample.scala\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/NGramExample.scala\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/MultilayerPerceptronClassifierExample.scala\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/MulticlassLogisticRegressionWithElasticNetExample.scala\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/ModelSelectionViaTrainValidationSplitExample.scala\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/ModelSelectionViaCrossValidationExample.scala\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/MinMaxScalerExample.scala\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/MinHashLSHExample.scala\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/MaxAbsScalerExample.scala\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/LogisticRegressionWithElasticNetExample.scala\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/LogisticRegressionSummaryExample.scala\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/LogisticRegressionExample.scala\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/LinearSVCExample.scala\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/LinearRegressionWithElasticNetExample.scala\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/LinearRegressionExample.scala\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/LDAExample.scala\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/KMeansExample.scala\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/IsotonicRegressionExample.scala\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/InteractionExample.scala\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/IndexToStringExample.scala\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/ImputerExample.scala\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/GradientBoostedTreeRegressorExample.scala\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/GeneralizedLinearRegressionExample.scala\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/GaussianMixtureExample.scala\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/GBTExample.scala\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/FeatureHasherExample.scala\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/EstimatorTransformerParamExample.scala\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/ElementwiseProductExample.scala\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/DeveloperApiExample.scala\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/DecisionTreeRegressionExample.scala\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/DecisionTreeExample.scala\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/DataFrameExample.scala\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/DCTExample.scala\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/CountVectorizerExample.scala\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/CorrelationExample.scala\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/ChiSquareTestExample.scala\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/ChiSqSelectorExample.scala\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/BucketizerExample.scala\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/BucketedRandomProjectionLSHExample.scala\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/BinarizerExample.scala\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/ALSExample.scala\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/AFTSurvivalRegressionExample.scala\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/RandomForestClassifierExample.scala\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/PrefixSpanExample.scala\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/OneHotEncoderEstimatorExample.scala\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/GradientBoostedTreeClassifierExample.scala\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/FPGrowthExample.scala\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/DecisionTreeClassificationExample.scala\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/BisectingKMeansExample.scala\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/graphx/\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/graphx/TriangleCountingExample.scala\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/graphx/SynthBenchmark.scala\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/graphx/SSSPExample.scala\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/graphx/PageRankExample.scala\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/graphx/LiveJournalPageRank.scala\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/graphx/ConnectedComponentsExample.scala\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/graphx/ComprehensiveExample.scala\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/graphx/Analytics.scala\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/graphx/AggregateMessagesExample.scala\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/SparkTC.scala\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/SparkRemoteFileTest.scala\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/SparkPi.scala\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/SparkPageRank.scala\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/SparkLR.scala\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/SparkKMeans.scala\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/SparkHdfsLR.scala\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/SparkALS.scala\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/SkewedGroupByTest.scala\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/SimpleSkewedGroupByTest.scala\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/MultiBroadcastTest.scala\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/LocalPi.scala\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/LocalLR.scala\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/LocalKMeans.scala\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/LocalFileLR.scala\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/LocalALS.scala\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/GroupByTest.scala\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ExceptionHandlingTest.scala\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/DriverSubmissionTest.scala\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/BroadcastTest.scala\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/streaming/\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/streaming/clickstream/\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/streaming/clickstream/PageViewStream.scala\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/streaming/clickstream/PageViewGenerator.scala\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/streaming/StreamingExamples.scala\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/streaming/StatefulNetworkWordCount.scala\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/streaming/SqlNetworkWordCount.scala\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/streaming/RecoverableNetworkWordCount.scala\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/streaming/RawNetworkGrep.scala\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/streaming/QueueStream.scala\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/streaming/NetworkWordCount.scala\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/streaming/HdfsWordCount.scala\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/streaming/DirectKafkaWordCount.scala\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/streaming/CustomReceiver.scala\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/sql/\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/sql/streaming/\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/sql/streaming/StructuredSessionization.scala\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/sql/streaming/StructuredNetworkWordCountWindowed.scala\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/sql/streaming/StructuredNetworkWordCount.scala\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/sql/streaming/StructuredKafkaWordCount.scala\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/sql/hive/\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/sql/hive/SparkHiveExample.scala\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/sql/UserDefinedUntypedAggregation.scala\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/sql/UserDefinedTypedAggregation.scala\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/sql/RDDRelation.scala\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/sql/SparkSQLExample.scala\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/sql/SQLDataSourceExample.scala\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/pythonconverters/\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/pythonconverters/AvroConverters.scala\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/LogQuery.scala\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/HdfsTest.scala\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/DFSReadWriteTest.scala\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/resources/\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/resources/users.parquet\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/resources/users.orc\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/resources/users.avro\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/resources/user.avsc\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/resources/people.txt\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/resources/people.json\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/resources/people.csv\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/resources/kv1.txt\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/resources/full_user.avsc\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/resources/employees.json\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/r/\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/r/streaming/\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/r/streaming/structured_network_wordcount.R\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/r/ml/\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/r/ml/svmLinear.R\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/r/ml/survreg.R\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/r/ml/randomForest.R\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/r/ml/naiveBayes.R\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/r/ml/mlp.R\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/r/ml/ml.R\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/r/ml/logit.R\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/r/ml/lda.R\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/r/ml/kstest.R\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/r/ml/kmeans.R\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/r/ml/isoreg.R\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/r/ml/glm.R\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/r/ml/gbt.R\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/r/ml/gaussianMixture.R\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/r/ml/fpm.R\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/r/ml/decisionTree.R\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/r/ml/bisectingKmeans.R\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/r/ml/als.R\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/r/dataframe.R\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/r/data-manipulation.R\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/r/RSparkSQLExample.R\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/python/\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/python/wordcount.py\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/python/transitive_closure.py\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/python/streaming/\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/python/streaming/stateful_network_wordcount.py\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/python/streaming/sql_network_wordcount.py\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/python/streaming/queue_stream.py\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/python/streaming/network_wordjoinsentiments.py\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/python/streaming/network_wordcount.py\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/python/streaming/hdfs_wordcount.py\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/python/streaming/recoverable_network_wordcount.py\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/python/streaming/kafka_wordcount.py\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/python/streaming/flume_wordcount.py\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/python/streaming/direct_kafka_wordcount.py\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/python/status_api_demo.py\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/python/sql/\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/python/sql/streaming/\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/python/sql/streaming/structured_network_wordcount_windowed.py\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/python/sql/streaming/structured_network_wordcount.py\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/python/sql/streaming/structured_kafka_wordcount.py\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/python/sql/basic.py\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/python/sql/hive.py\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/python/sql/datasource.py\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/python/sql/arrow.py\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/python/sort.py\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/python/pi.py\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/python/parquet_inputformat.py\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/python/pagerank.py\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/python/mllib/\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/python/mllib/word2vec_example.py\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/python/mllib/word2vec.py\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/python/mllib/tf_idf_example.py\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/python/mllib/svm_with_sgd_example.py\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/python/mllib/svd_example.py\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/python/mllib/summary_statistics_example.py\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/python/mllib/streaming_linear_regression_example.py\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/python/mllib/streaming_k_means_example.py\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/python/mllib/stratified_sampling_example.py\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/python/mllib/sampled_rdds.py\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/python/mllib/regression_metrics_example.py\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/python/mllib/recommendation_example.py\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/python/mllib/random_rdd_generation.py\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/python/mllib/random_forest_regression_example.py\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/python/mllib/random_forest_classification_example.py\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/python/mllib/power_iteration_clustering_example.py\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/python/mllib/pca_rowmatrix_example.py\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/python/mllib/normalizer_example.py\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/python/mllib/naive_bayes_example.py\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/python/mllib/multi_label_metrics_example.py\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/python/mllib/logistic_regression_with_lbfgs_example.py\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/python/mllib/logistic_regression.py\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/python/mllib/linear_regression_with_sgd_example.py\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/python/mllib/latent_dirichlet_allocation_example.py\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/python/mllib/kmeans.py\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/python/mllib/kernel_density_estimation_example.py\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/python/mllib/k_means_example.py\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/python/mllib/hypothesis_testing_kolmogorov_smirnov_test_example.py\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/python/mllib/hypothesis_testing_example.py\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/python/mllib/gradient_boosting_regression_example.py\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/python/mllib/gradient_boosting_classification_example.py\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/python/mllib/gaussian_mixture_model.py\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/python/mllib/gaussian_mixture_example.py\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/python/mllib/fpgrowth_example.py\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/python/mllib/elementwise_product_example.py\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/python/mllib/decision_tree_regression_example.py\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/python/mllib/decision_tree_classification_example.py\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/python/mllib/correlations_example.py\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/python/mllib/correlations.py\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/python/mllib/binary_classification_metrics_example.py\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/python/mllib/standard_scaler_example.py\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/python/mllib/ranking_metrics_example.py\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/python/mllib/multi_class_metrics_example.py\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/python/mllib/isotonic_regression_example.py\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/python/mllib/bisecting_k_means_example.py\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/python/ml/\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/python/ml/word2vec_example.py\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/python/ml/vector_slicer_example.py\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/python/ml/vector_size_hint_example.py\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/python/ml/vector_indexer_example.py\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/python/ml/vector_assembler_example.py\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/python/ml/train_validation_split.py\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/python/ml/tokenizer_example.py\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/python/ml/tf_idf_example.py\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/python/ml/summarizer_example.py\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/python/ml/string_indexer_example.py\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/python/ml/stopwords_remover_example.py\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/python/ml/standard_scaler_example.py\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/python/ml/sql_transformer.py\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/python/ml/rformula_example.py\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/python/ml/random_forest_regressor_example.py\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/python/ml/random_forest_classifier_example.py\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/python/ml/quantile_discretizer_example.py\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/python/ml/prefixspan_example.py\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/python/ml/polynomial_expansion_example.py\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/python/ml/pipeline_example.py\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/python/ml/pca_example.py\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/python/ml/one_vs_rest_example.py\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/python/ml/normalizer_example.py\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/python/ml/naive_bayes_example.py\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/python/ml/n_gram_example.py\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/python/ml/multilayer_perceptron_classification.py\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/python/ml/multiclass_logistic_regression_with_elastic_net.py\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/python/ml/min_max_scaler_example.py\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/python/ml/min_hash_lsh_example.py\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/python/ml/max_abs_scaler_example.py\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/python/ml/logistic_regression_with_elastic_net.py\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/python/ml/logistic_regression_summary_example.py\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/python/ml/linearsvc.py\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/python/ml/linear_regression_with_elastic_net.py\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/python/ml/lda_example.py\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/python/ml/kmeans_example.py\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/python/ml/isotonic_regression_example.py\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/python/ml/index_to_string_example.py\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/python/ml/imputer_example.py\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/python/ml/gradient_boosted_tree_regressor_example.py\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/python/ml/gradient_boosted_tree_classifier_example.py\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/python/ml/generalized_linear_regression_example.py\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/python/ml/gaussian_mixture_example.py\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/python/ml/fpgrowth_example.py\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/python/ml/feature_hasher_example.py\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/python/ml/estimator_transformer_param_example.py\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/python/ml/elementwise_product_example.py\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/python/ml/decision_tree_regression_example.py\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/python/ml/decision_tree_classification_example.py\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/python/ml/dct_example.py\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/python/ml/dataframe_example.py\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/python/ml/cross_validator.py\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/python/ml/count_vectorizer_example.py\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/python/ml/correlation_example.py\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/python/ml/chisq_selector_example.py\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/python/ml/chi_square_test_example.py\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/python/ml/bucketizer_example.py\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/python/ml/bucketed_random_projection_lsh_example.py\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/python/ml/binarizer_example.py\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/python/ml/als_example.py\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/python/ml/aft_survival_regression.py\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/python/ml/onehot_encoder_estimator_example.py\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/python/ml/bisecting_k_means_example.py\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/python/logistic_regression.py\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/python/kmeans.py\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/python/avro_inputformat.py\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/python/als.py\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/java/\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/java/org/\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/java/org/apache/\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/java/org/apache/spark/\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/streaming/\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/streaming/JavaStatefulNetworkWordCount.java\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/streaming/JavaSqlNetworkWordCount.java\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/streaming/JavaRecoverableNetworkWordCount.java\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/streaming/JavaRecord.java\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/streaming/JavaQueueStream.java\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/streaming/JavaNetworkWordCount.java\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/streaming/JavaDirectKafkaWordCount.java\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/streaming/JavaCustomReceiver.java\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/sql/\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/sql/streaming/\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/sql/streaming/JavaStructuredNetworkWordCountWindowed.java\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/sql/streaming/JavaStructuredNetworkWordCount.java\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/sql/streaming/JavaStructuredKafkaWordCount.java\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/sql/streaming/JavaStructuredSessionization.java\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/sql/hive/\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/sql/hive/JavaSparkHiveExample.java\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/sql/JavaUserDefinedUntypedAggregation.java\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/sql/JavaUserDefinedTypedAggregation.java\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/sql/JavaSparkSQLExample.java\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/sql/JavaSQLDataSourceExample.java\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaSummaryStatisticsExample.java\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaStreamingTestExample.java\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaStratifiedSamplingExample.java\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaSimpleFPGrowth.java\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaSVMWithSGDExample.java\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaSVDExample.java\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaRegressionMetricsExample.java\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaRecommendationExample.java\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaRandomForestRegressionExample.java\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaPrefixSpanExample.java\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaPowerIterationClusteringExample.java\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaPCAExample.java\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaNaiveBayesExample.java\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaMulticlassClassificationMetricsExample.java\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaMultiLabelClassificationMetricsExample.java\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaLogisticRegressionWithLBFGSExample.java\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaLinearRegressionWithSGDExample.java\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaLatentDirichletAllocationExample.java\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaLBFGSExample.java\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaKernelDensityEstimationExample.java\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaKMeansExample.java\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaIsotonicRegressionExample.java\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaHypothesisTestingKolmogorovSmirnovTestExample.java\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaHypothesisTestingExample.java\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaGradientBoostingRegressionExample.java\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaGradientBoostingClassificationExample.java\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaGaussianMixtureExample.java\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaElementwiseProductExample.java\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaDecisionTreeRegressionExample.java\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaDecisionTreeClassificationExample.java\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaChiSqSelectorExample.java\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaBisectingKMeansExample.java\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaBinaryClassificationMetricsExample.java\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaAssociationRulesExample.java\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaALS.java\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaRankingMetricsExample.java\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaRandomForestClassificationExample.java\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaCorrelationsExample.java\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaWord2VecExample.java\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaVectorSlicerExample.java\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaVectorSizeHintExample.java\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaVectorIndexerExample.java\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaVectorAssemblerExample.java\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaTokenizerExample.java\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaTfIdfExample.java\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaSummarizerExample.java\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaStringIndexerExample.java\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaStopWordsRemoverExample.java\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaStandardScalerExample.java\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaSQLTransformerExample.java\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaRandomForestRegressorExample.java\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaRFormulaExample.java\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaQuantileDiscretizerExample.java\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaPowerIterationClusteringExample.java\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaPolynomialExpansionExample.java\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaPipelineExample.java\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaPCAExample.java\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaOneVsRestExample.java\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaNormalizerExample.java\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaNaiveBayesExample.java\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaNGramExample.java\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaMultilayerPerceptronClassifierExample.java\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaMulticlassLogisticRegressionWithElasticNetExample.java\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaModelSelectionViaTrainValidationSplitExample.java\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaModelSelectionViaCrossValidationExample.java\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaMinMaxScalerExample.java\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaMinHashLSHExample.java\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaMaxAbsScalerExample.java\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaLogisticRegressionWithElasticNetExample.java\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaLogisticRegressionSummaryExample.java\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaLinearSVCExample.java\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaLinearRegressionWithElasticNetExample.java\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaLabeledDocument.java\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaLDAExample.java\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaKMeansExample.java\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaIsotonicRegressionExample.java\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaInteractionExample.java\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaIndexToStringExample.java\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaImputerExample.java\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaGradientBoostedTreeRegressorExample.java\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaGeneralizedLinearRegressionExample.java\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaGaussianMixtureExample.java\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaFeatureHasherExample.java\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaFPGrowthExample.java\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaEstimatorTransformerParamExample.java\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaElementwiseProductExample.java\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaDocument.java\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaDecisionTreeRegressionExample.java\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaDCTExample.java\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaCountVectorizerExample.java\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaCorrelationExample.java\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaChiSquareTestExample.java\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaChiSqSelectorExample.java\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaBucketizerExample.java\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaBucketedRandomProjectionLSHExample.java\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaBinarizerExample.java\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaAFTSurvivalRegressionExample.java\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaRandomForestClassifierExample.java\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaPrefixSpanExample.java\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaOneHotEncoderEstimatorExample.java\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaGradientBoostedTreeClassifierExample.java\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaDecisionTreeClassificationExample.java\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaBisectingKMeansExample.java\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaALSExample.java\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/JavaWordCount.java\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/JavaStatusTrackerDemo.java\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/JavaSparkPi.java\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/JavaPageRank.java\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/JavaLogQuery.java\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/JavaHdfsLR.java\n",
            "spark-2.4.4-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/JavaTC.java\n",
            "spark-2.4.4-bin-hadoop2.7/examples/jars/\n",
            "spark-2.4.4-bin-hadoop2.7/examples/jars/spark-examples_2.11-2.4.4.jar\n",
            "spark-2.4.4-bin-hadoop2.7/examples/jars/scopt_2.11-3.7.0.jar\n",
            "spark-2.4.4-bin-hadoop2.7/kubernetes/\n",
            "spark-2.4.4-bin-hadoop2.7/kubernetes/tests/\n",
            "spark-2.4.4-bin-hadoop2.7/kubernetes/tests/pyfiles.py\n",
            "spark-2.4.4-bin-hadoop2.7/kubernetes/tests/worker_memory_check.py\n",
            "spark-2.4.4-bin-hadoop2.7/kubernetes/tests/py_container_checks.py\n",
            "spark-2.4.4-bin-hadoop2.7/kubernetes/dockerfiles/\n",
            "spark-2.4.4-bin-hadoop2.7/kubernetes/dockerfiles/spark/\n",
            "spark-2.4.4-bin-hadoop2.7/kubernetes/dockerfiles/spark/entrypoint.sh\n",
            "spark-2.4.4-bin-hadoop2.7/kubernetes/dockerfiles/spark/Dockerfile\n",
            "spark-2.4.4-bin-hadoop2.7/kubernetes/dockerfiles/spark/bindings/\n",
            "spark-2.4.4-bin-hadoop2.7/kubernetes/dockerfiles/spark/bindings/python/\n",
            "spark-2.4.4-bin-hadoop2.7/kubernetes/dockerfiles/spark/bindings/python/Dockerfile\n",
            "spark-2.4.4-bin-hadoop2.7/kubernetes/dockerfiles/spark/bindings/R/\n",
            "spark-2.4.4-bin-hadoop2.7/kubernetes/dockerfiles/spark/bindings/R/Dockerfile\n",
            "spark-2.4.4-bin-hadoop2.7/yarn/\n",
            "spark-2.4.4-bin-hadoop2.7/yarn/spark-2.4.4-yarn-shuffle.jar\n",
            "spark-2.4.4-bin-hadoop2.7/jars/\n",
            "spark-2.4.4-bin-hadoop2.7/jars/jackson-mapper-asl-1.9.13.jar\n",
            "spark-2.4.4-bin-hadoop2.7/jars/jackson-jaxrs-1.9.13.jar\n",
            "spark-2.4.4-bin-hadoop2.7/jars/jackson-dataformat-yaml-2.6.7.jar\n",
            "spark-2.4.4-bin-hadoop2.7/jars/jackson-databind-2.6.7.1.jar\n",
            "spark-2.4.4-bin-hadoop2.7/jars/jackson-core-asl-1.9.13.jar\n",
            "spark-2.4.4-bin-hadoop2.7/jars/jackson-core-2.6.7.jar\n",
            "spark-2.4.4-bin-hadoop2.7/jars/jackson-annotations-2.6.7.jar\n",
            "spark-2.4.4-bin-hadoop2.7/jars/ivy-2.4.0.jar\n",
            "spark-2.4.4-bin-hadoop2.7/jars/httpcore-4.4.10.jar\n",
            "spark-2.4.4-bin-hadoop2.7/jars/httpclient-4.5.6.jar\n",
            "spark-2.4.4-bin-hadoop2.7/jars/htrace-core-3.1.0-incubating.jar\n",
            "spark-2.4.4-bin-hadoop2.7/jars/hppc-0.7.2.jar\n",
            "spark-2.4.4-bin-hadoop2.7/jars/hk2-utils-2.4.0-b34.jar\n",
            "spark-2.4.4-bin-hadoop2.7/jars/hk2-locator-2.4.0-b34.jar\n",
            "spark-2.4.4-bin-hadoop2.7/jars/hk2-api-2.4.0-b34.jar\n",
            "spark-2.4.4-bin-hadoop2.7/jars/hive-metastore-1.2.1.spark2.jar\n",
            "spark-2.4.4-bin-hadoop2.7/jars/hive-jdbc-1.2.1.spark2.jar\n",
            "spark-2.4.4-bin-hadoop2.7/jars/hive-exec-1.2.1.spark2.jar\n",
            "spark-2.4.4-bin-hadoop2.7/jars/hive-cli-1.2.1.spark2.jar\n",
            "spark-2.4.4-bin-hadoop2.7/jars/hive-beeline-1.2.1.spark2.jar\n",
            "spark-2.4.4-bin-hadoop2.7/jars/hadoop-yarn-server-web-proxy-2.7.3.jar\n",
            "spark-2.4.4-bin-hadoop2.7/jars/hadoop-yarn-server-common-2.7.3.jar\n",
            "spark-2.4.4-bin-hadoop2.7/jars/hadoop-yarn-common-2.7.3.jar\n",
            "spark-2.4.4-bin-hadoop2.7/jars/hadoop-yarn-client-2.7.3.jar\n",
            "spark-2.4.4-bin-hadoop2.7/jars/hadoop-yarn-api-2.7.3.jar\n",
            "spark-2.4.4-bin-hadoop2.7/jars/hadoop-mapreduce-client-shuffle-2.7.3.jar\n",
            "spark-2.4.4-bin-hadoop2.7/jars/hadoop-mapreduce-client-jobclient-2.7.3.jar\n",
            "spark-2.4.4-bin-hadoop2.7/jars/hadoop-mapreduce-client-core-2.7.3.jar\n",
            "spark-2.4.4-bin-hadoop2.7/jars/hadoop-mapreduce-client-common-2.7.3.jar\n",
            "spark-2.4.4-bin-hadoop2.7/jars/hadoop-mapreduce-client-app-2.7.3.jar\n",
            "spark-2.4.4-bin-hadoop2.7/jars/hadoop-hdfs-2.7.3.jar\n",
            "spark-2.4.4-bin-hadoop2.7/jars/hadoop-common-2.7.3.jar\n",
            "spark-2.4.4-bin-hadoop2.7/jars/hadoop-client-2.7.3.jar\n",
            "spark-2.4.4-bin-hadoop2.7/jars/hadoop-auth-2.7.3.jar\n",
            "spark-2.4.4-bin-hadoop2.7/jars/hadoop-annotations-2.7.3.jar\n",
            "spark-2.4.4-bin-hadoop2.7/jars/guice-servlet-3.0.jar\n",
            "spark-2.4.4-bin-hadoop2.7/jars/guice-3.0.jar\n",
            "spark-2.4.4-bin-hadoop2.7/jars/guava-14.0.1.jar\n",
            "spark-2.4.4-bin-hadoop2.7/jars/gson-2.2.4.jar\n",
            "spark-2.4.4-bin-hadoop2.7/jars/generex-1.0.1.jar\n",
            "spark-2.4.4-bin-hadoop2.7/jars/flatbuffers-1.2.0-3f79e055.jar\n",
            "spark-2.4.4-bin-hadoop2.7/jars/eigenbase-properties-1.1.5.jar\n",
            "spark-2.4.4-bin-hadoop2.7/jars/derby-10.12.1.1.jar\n",
            "spark-2.4.4-bin-hadoop2.7/jars/datanucleus-rdbms-3.2.9.jar\n",
            "spark-2.4.4-bin-hadoop2.7/jars/datanucleus-core-3.2.10.jar\n",
            "spark-2.4.4-bin-hadoop2.7/jars/datanucleus-api-jdo-3.2.6.jar\n",
            "spark-2.4.4-bin-hadoop2.7/jars/curator-recipes-2.7.1.jar\n",
            "spark-2.4.4-bin-hadoop2.7/jars/curator-framework-2.7.1.jar\n",
            "spark-2.4.4-bin-hadoop2.7/jars/curator-client-2.7.1.jar\n",
            "spark-2.4.4-bin-hadoop2.7/jars/core-1.1.2.jar\n",
            "spark-2.4.4-bin-hadoop2.7/jars/compress-lzf-1.0.3.jar\n",
            "spark-2.4.4-bin-hadoop2.7/jars/commons-pool-1.5.4.jar\n",
            "spark-2.4.4-bin-hadoop2.7/jars/commons-net-3.1.jar\n",
            "spark-2.4.4-bin-hadoop2.7/jars/commons-math3-3.4.1.jar\n",
            "spark-2.4.4-bin-hadoop2.7/jars/commons-logging-1.1.3.jar\n",
            "spark-2.4.4-bin-hadoop2.7/jars/commons-lang3-3.5.jar\n",
            "spark-2.4.4-bin-hadoop2.7/jars/commons-lang-2.6.jar\n",
            "spark-2.4.4-bin-hadoop2.7/jars/commons-io-2.4.jar\n",
            "spark-2.4.4-bin-hadoop2.7/jars/commons-httpclient-3.1.jar\n",
            "spark-2.4.4-bin-hadoop2.7/jars/commons-digester-1.8.jar\n",
            "spark-2.4.4-bin-hadoop2.7/jars/commons-dbcp-1.4.jar\n",
            "spark-2.4.4-bin-hadoop2.7/jars/commons-crypto-1.0.0.jar\n",
            "spark-2.4.4-bin-hadoop2.7/jars/commons-configuration-1.6.jar\n",
            "spark-2.4.4-bin-hadoop2.7/jars/commons-compress-1.8.1.jar\n",
            "spark-2.4.4-bin-hadoop2.7/jars/commons-compiler-3.0.9.jar\n",
            "spark-2.4.4-bin-hadoop2.7/jars/commons-collections-3.2.2.jar\n",
            "spark-2.4.4-bin-hadoop2.7/jars/commons-codec-1.10.jar\n",
            "spark-2.4.4-bin-hadoop2.7/jars/commons-cli-1.2.jar\n",
            "spark-2.4.4-bin-hadoop2.7/jars/commons-beanutils-1.9.3.jar\n",
            "spark-2.4.4-bin-hadoop2.7/jars/chill_2.11-0.9.3.jar\n",
            "spark-2.4.4-bin-hadoop2.7/jars/chill-java-0.9.3.jar\n",
            "spark-2.4.4-bin-hadoop2.7/jars/calcite-linq4j-1.2.0-incubating.jar\n",
            "spark-2.4.4-bin-hadoop2.7/jars/calcite-core-1.2.0-incubating.jar\n",
            "spark-2.4.4-bin-hadoop2.7/jars/calcite-avatica-1.2.0-incubating.jar\n",
            "spark-2.4.4-bin-hadoop2.7/jars/breeze_2.11-0.13.2.jar\n",
            "spark-2.4.4-bin-hadoop2.7/jars/breeze-macros_2.11-0.13.2.jar\n",
            "spark-2.4.4-bin-hadoop2.7/jars/bonecp-0.8.0.RELEASE.jar\n",
            "spark-2.4.4-bin-hadoop2.7/jars/avro-mapred-1.8.2-hadoop2.jar\n",
            "spark-2.4.4-bin-hadoop2.7/jars/avro-ipc-1.8.2.jar\n",
            "spark-2.4.4-bin-hadoop2.7/jars/avro-1.8.2.jar\n",
            "spark-2.4.4-bin-hadoop2.7/jars/automaton-1.11-8.jar\n",
            "spark-2.4.4-bin-hadoop2.7/jars/arrow-vector-0.10.0.jar\n",
            "spark-2.4.4-bin-hadoop2.7/jars/arrow-memory-0.10.0.jar\n",
            "spark-2.4.4-bin-hadoop2.7/jars/arrow-format-0.10.0.jar\n",
            "spark-2.4.4-bin-hadoop2.7/jars/arpack_combined_all-0.1.jar\n",
            "spark-2.4.4-bin-hadoop2.7/jars/api-util-1.0.0-M20.jar\n",
            "spark-2.4.4-bin-hadoop2.7/jars/api-asn1-api-1.0.0-M20.jar\n",
            "spark-2.4.4-bin-hadoop2.7/jars/apacheds-kerberos-codec-2.0.0-M15.jar\n",
            "spark-2.4.4-bin-hadoop2.7/jars/apacheds-i18n-2.0.0-M15.jar\n",
            "spark-2.4.4-bin-hadoop2.7/jars/apache-log4j-extras-1.2.17.jar\n",
            "spark-2.4.4-bin-hadoop2.7/jars/aopalliance-repackaged-2.4.0-b34.jar\n",
            "spark-2.4.4-bin-hadoop2.7/jars/aopalliance-1.0.jar\n",
            "spark-2.4.4-bin-hadoop2.7/jars/antlr4-runtime-4.7.jar\n",
            "spark-2.4.4-bin-hadoop2.7/jars/antlr-runtime-3.4.jar\n",
            "spark-2.4.4-bin-hadoop2.7/jars/antlr-2.7.7.jar\n",
            "spark-2.4.4-bin-hadoop2.7/jars/aircompressor-0.10.jar\n",
            "spark-2.4.4-bin-hadoop2.7/jars/activation-1.1.1.jar\n",
            "spark-2.4.4-bin-hadoop2.7/jars/ST4-4.0.4.jar\n",
            "spark-2.4.4-bin-hadoop2.7/jars/RoaringBitmap-0.7.45.jar\n",
            "spark-2.4.4-bin-hadoop2.7/jars/JavaEWAH-0.3.2.jar\n",
            "spark-2.4.4-bin-hadoop2.7/jars/zstd-jni-1.3.2-2.jar\n",
            "spark-2.4.4-bin-hadoop2.7/jars/zookeeper-3.4.6.jar\n",
            "spark-2.4.4-bin-hadoop2.7/jars/zjsonpatch-0.3.0.jar\n",
            "spark-2.4.4-bin-hadoop2.7/jars/xz-1.5.jar\n",
            "spark-2.4.4-bin-hadoop2.7/jars/xmlenc-0.52.jar\n",
            "spark-2.4.4-bin-hadoop2.7/jars/xercesImpl-2.9.1.jar\n",
            "spark-2.4.4-bin-hadoop2.7/jars/xbean-asm6-shaded-4.8.jar\n",
            "spark-2.4.4-bin-hadoop2.7/jars/validation-api-1.1.0.Final.jar\n",
            "spark-2.4.4-bin-hadoop2.7/jars/univocity-parsers-2.7.3.jar\n",
            "spark-2.4.4-bin-hadoop2.7/jars/super-csv-2.2.0.jar\n",
            "spark-2.4.4-bin-hadoop2.7/jars/stringtemplate-3.2.1.jar\n",
            "spark-2.4.4-bin-hadoop2.7/jars/stream-2.7.0.jar\n",
            "spark-2.4.4-bin-hadoop2.7/jars/stax-api-1.0.1.jar\n",
            "spark-2.4.4-bin-hadoop2.7/jars/stax-api-1.0-2.jar\n",
            "spark-2.4.4-bin-hadoop2.7/jars/spire_2.11-0.13.0.jar\n",
            "spark-2.4.4-bin-hadoop2.7/jars/spire-macros_2.11-0.13.0.jar\n",
            "spark-2.4.4-bin-hadoop2.7/jars/spark-yarn_2.11-2.4.4.jar\n",
            "spark-2.4.4-bin-hadoop2.7/jars/spark-unsafe_2.11-2.4.4.jar\n",
            "spark-2.4.4-bin-hadoop2.7/jars/spark-tags_2.11-2.4.4.jar\n",
            "spark-2.4.4-bin-hadoop2.7/jars/spark-tags_2.11-2.4.4-tests.jar\n",
            "spark-2.4.4-bin-hadoop2.7/jars/spark-streaming_2.11-2.4.4.jar\n",
            "spark-2.4.4-bin-hadoop2.7/jars/spark-sql_2.11-2.4.4.jar\n",
            "spark-2.4.4-bin-hadoop2.7/jars/spark-sketch_2.11-2.4.4.jar\n",
            "spark-2.4.4-bin-hadoop2.7/jars/spark-repl_2.11-2.4.4.jar\n",
            "spark-2.4.4-bin-hadoop2.7/jars/spark-network-shuffle_2.11-2.4.4.jar\n",
            "spark-2.4.4-bin-hadoop2.7/jars/spark-network-common_2.11-2.4.4.jar\n",
            "spark-2.4.4-bin-hadoop2.7/jars/spark-mllib_2.11-2.4.4.jar\n",
            "spark-2.4.4-bin-hadoop2.7/jars/spark-mllib-local_2.11-2.4.4.jar\n",
            "spark-2.4.4-bin-hadoop2.7/jars/spark-mesos_2.11-2.4.4.jar\n",
            "spark-2.4.4-bin-hadoop2.7/jars/spark-launcher_2.11-2.4.4.jar\n",
            "spark-2.4.4-bin-hadoop2.7/jars/spark-kvstore_2.11-2.4.4.jar\n",
            "spark-2.4.4-bin-hadoop2.7/jars/spark-kubernetes_2.11-2.4.4.jar\n",
            "spark-2.4.4-bin-hadoop2.7/jars/spark-hive_2.11-2.4.4.jar\n",
            "spark-2.4.4-bin-hadoop2.7/jars/spark-hive-thriftserver_2.11-2.4.4.jar\n",
            "spark-2.4.4-bin-hadoop2.7/jars/spark-graphx_2.11-2.4.4.jar\n",
            "spark-2.4.4-bin-hadoop2.7/jars/spark-core_2.11-2.4.4.jar\n",
            "spark-2.4.4-bin-hadoop2.7/jars/spark-catalyst_2.11-2.4.4.jar\n",
            "spark-2.4.4-bin-hadoop2.7/jars/snappy-java-1.1.7.3.jar\n",
            "spark-2.4.4-bin-hadoop2.7/jars/snappy-0.2.jar\n",
            "spark-2.4.4-bin-hadoop2.7/jars/snakeyaml-1.15.jar\n",
            "spark-2.4.4-bin-hadoop2.7/jars/slf4j-log4j12-1.7.16.jar\n",
            "spark-2.4.4-bin-hadoop2.7/jars/slf4j-api-1.7.16.jar\n",
            "spark-2.4.4-bin-hadoop2.7/jars/shims-0.7.45.jar\n",
            "spark-2.4.4-bin-hadoop2.7/jars/shapeless_2.11-2.3.2.jar\n",
            "spark-2.4.4-bin-hadoop2.7/jars/scala-xml_2.11-1.0.5.jar\n",
            "spark-2.4.4-bin-hadoop2.7/jars/scala-reflect-2.11.12.jar\n",
            "spark-2.4.4-bin-hadoop2.7/jars/scala-parser-combinators_2.11-1.1.0.jar\n",
            "spark-2.4.4-bin-hadoop2.7/jars/scala-library-2.11.12.jar\n",
            "spark-2.4.4-bin-hadoop2.7/jars/scala-compiler-2.11.12.jar\n",
            "spark-2.4.4-bin-hadoop2.7/jars/pyrolite-4.13.jar\n",
            "spark-2.4.4-bin-hadoop2.7/jars/py4j-0.10.7.jar\n",
            "spark-2.4.4-bin-hadoop2.7/jars/protobuf-java-2.5.0.jar\n",
            "spark-2.4.4-bin-hadoop2.7/jars/parquet-jackson-1.10.1.jar\n",
            "spark-2.4.4-bin-hadoop2.7/jars/parquet-hadoop-bundle-1.6.0.jar\n",
            "spark-2.4.4-bin-hadoop2.7/jars/parquet-hadoop-1.10.1.jar\n",
            "spark-2.4.4-bin-hadoop2.7/jars/parquet-format-2.4.0.jar\n",
            "spark-2.4.4-bin-hadoop2.7/jars/parquet-encoding-1.10.1.jar\n",
            "spark-2.4.4-bin-hadoop2.7/jars/parquet-common-1.10.1.jar\n",
            "spark-2.4.4-bin-hadoop2.7/jars/parquet-column-1.10.1.jar\n",
            "spark-2.4.4-bin-hadoop2.7/jars/paranamer-2.8.jar\n",
            "spark-2.4.4-bin-hadoop2.7/jars/osgi-resource-locator-1.0.1.jar\n",
            "spark-2.4.4-bin-hadoop2.7/jars/oro-2.0.8.jar\n",
            "spark-2.4.4-bin-hadoop2.7/jars/orc-shims-1.5.5.jar\n",
            "spark-2.4.4-bin-hadoop2.7/jars/orc-mapreduce-1.5.5-nohive.jar\n",
            "spark-2.4.4-bin-hadoop2.7/jars/orc-core-1.5.5-nohive.jar\n",
            "spark-2.4.4-bin-hadoop2.7/jars/opencsv-2.3.jar\n",
            "spark-2.4.4-bin-hadoop2.7/jars/okio-1.13.0.jar\n",
            "spark-2.4.4-bin-hadoop2.7/jars/okhttp-3.8.1.jar\n",
            "spark-2.4.4-bin-hadoop2.7/jars/objenesis-2.5.1.jar\n",
            "spark-2.4.4-bin-hadoop2.7/jars/netty-all-4.1.17.Final.jar\n",
            "spark-2.4.4-bin-hadoop2.7/jars/netty-3.9.9.Final.jar\n",
            "spark-2.4.4-bin-hadoop2.7/jars/minlog-1.3.0.jar\n",
            "spark-2.4.4-bin-hadoop2.7/jars/metrics-jvm-3.1.5.jar\n",
            "spark-2.4.4-bin-hadoop2.7/jars/metrics-json-3.1.5.jar\n",
            "spark-2.4.4-bin-hadoop2.7/jars/metrics-graphite-3.1.5.jar\n",
            "spark-2.4.4-bin-hadoop2.7/jars/metrics-core-3.1.5.jar\n",
            "spark-2.4.4-bin-hadoop2.7/jars/mesos-1.4.0-shaded-protobuf.jar\n",
            "spark-2.4.4-bin-hadoop2.7/jars/macro-compat_2.11-1.1.1.jar\n",
            "spark-2.4.4-bin-hadoop2.7/jars/machinist_2.11-0.6.1.jar\n",
            "spark-2.4.4-bin-hadoop2.7/jars/lz4-java-1.4.0.jar\n",
            "spark-2.4.4-bin-hadoop2.7/jars/logging-interceptor-3.12.0.jar\n",
            "spark-2.4.4-bin-hadoop2.7/jars/log4j-1.2.17.jar\n",
            "spark-2.4.4-bin-hadoop2.7/jars/libthrift-0.9.3.jar\n",
            "spark-2.4.4-bin-hadoop2.7/jars/libfb303-0.9.3.jar\n",
            "spark-2.4.4-bin-hadoop2.7/jars/leveldbjni-all-1.8.jar\n",
            "spark-2.4.4-bin-hadoop2.7/jars/kubernetes-model-common-4.1.2.jar\n",
            "spark-2.4.4-bin-hadoop2.7/jars/kubernetes-model-4.1.2.jar\n",
            "spark-2.4.4-bin-hadoop2.7/jars/kubernetes-client-4.1.2.jar\n",
            "spark-2.4.4-bin-hadoop2.7/jars/kryo-shaded-4.0.2.jar\n",
            "spark-2.4.4-bin-hadoop2.7/jars/jul-to-slf4j-1.7.16.jar\n",
            "spark-2.4.4-bin-hadoop2.7/jars/jtransforms-2.4.0.jar\n",
            "spark-2.4.4-bin-hadoop2.7/jars/jta-1.1.jar\n",
            "spark-2.4.4-bin-hadoop2.7/jars/jsr305-1.3.9.jar\n",
            "spark-2.4.4-bin-hadoop2.7/jars/jsp-api-2.1.jar\n",
            "spark-2.4.4-bin-hadoop2.7/jars/json4s-scalap_2.11-3.5.3.jar\n",
            "spark-2.4.4-bin-hadoop2.7/jars/json4s-jackson_2.11-3.5.3.jar\n",
            "spark-2.4.4-bin-hadoop2.7/jars/json4s-core_2.11-3.5.3.jar\n",
            "spark-2.4.4-bin-hadoop2.7/jars/json4s-ast_2.11-3.5.3.jar\n",
            "spark-2.4.4-bin-hadoop2.7/jars/jpam-1.1.jar\n",
            "spark-2.4.4-bin-hadoop2.7/jars/jodd-core-3.5.2.jar\n",
            "spark-2.4.4-bin-hadoop2.7/jars/joda-time-2.9.3.jar\n",
            "spark-2.4.4-bin-hadoop2.7/jars/jline-2.14.6.jar\n",
            "spark-2.4.4-bin-hadoop2.7/jars/jetty-util-6.1.26.jar\n",
            "spark-2.4.4-bin-hadoop2.7/jars/jetty-6.1.26.jar\n",
            "spark-2.4.4-bin-hadoop2.7/jars/jersey-server-2.22.2.jar\n",
            "spark-2.4.4-bin-hadoop2.7/jars/jersey-media-jaxb-2.22.2.jar\n",
            "spark-2.4.4-bin-hadoop2.7/jars/jersey-guava-2.22.2.jar\n",
            "spark-2.4.4-bin-hadoop2.7/jars/jersey-container-servlet-core-2.22.2.jar\n",
            "spark-2.4.4-bin-hadoop2.7/jars/jersey-container-servlet-2.22.2.jar\n",
            "spark-2.4.4-bin-hadoop2.7/jars/jersey-common-2.22.2.jar\n",
            "spark-2.4.4-bin-hadoop2.7/jars/jersey-client-2.22.2.jar\n",
            "spark-2.4.4-bin-hadoop2.7/jars/jdo-api-3.0.1.jar\n",
            "spark-2.4.4-bin-hadoop2.7/jars/jcl-over-slf4j-1.7.16.jar\n",
            "spark-2.4.4-bin-hadoop2.7/jars/jaxb-api-2.2.2.jar\n",
            "spark-2.4.4-bin-hadoop2.7/jars/javolution-5.5.1.jar\n",
            "spark-2.4.4-bin-hadoop2.7/jars/javax.ws.rs-api-2.0.1.jar\n",
            "spark-2.4.4-bin-hadoop2.7/jars/javax.servlet-api-3.1.0.jar\n",
            "spark-2.4.4-bin-hadoop2.7/jars/javax.inject-2.4.0-b34.jar\n",
            "spark-2.4.4-bin-hadoop2.7/jars/javax.inject-1.jar\n",
            "spark-2.4.4-bin-hadoop2.7/jars/javax.annotation-api-1.2.jar\n",
            "spark-2.4.4-bin-hadoop2.7/jars/javassist-3.18.1-GA.jar\n",
            "spark-2.4.4-bin-hadoop2.7/jars/janino-3.0.9.jar\n",
            "spark-2.4.4-bin-hadoop2.7/jars/jackson-xc-1.9.13.jar\n",
            "spark-2.4.4-bin-hadoop2.7/jars/jackson-module-scala_2.11-2.6.7.1.jar\n",
            "spark-2.4.4-bin-hadoop2.7/jars/jackson-module-paranamer-2.7.9.jar\n",
            "spark-2.4.4-bin-hadoop2.7/jars/jackson-module-jaxb-annotations-2.6.7.jar\n",
            "spark-2.4.4-bin-hadoop2.7/RELEASE\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yYXN_43rlmdv",
        "colab_type": "code",
        "outputId": "996fa9bb-a83e-458a-a181-604ae0eae859",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import torch\n",
        "from pyspark import SparkContext\n",
        "from pyspark.sql import SparkSession, SQLContext\n",
        "import findspark\n",
        "from pyspark.sql.types import StructType, StructField, FloatType, StringType\n",
        "import pyspark.sql.functions as F \n",
        "import sklearn\n",
        "from pyspark.ml.feature import VectorAssembler\n",
        "from pyspark.ml.regression import LinearRegression\n",
        "import pyspark.mllib\n",
        "import keras\n",
        "import tensorflowonspark\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import sklearn\n",
        "from sklearn import preprocessing\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow as tf\n",
        "import tensorframes as tfs\n",
        "from pyspark.sql import Row"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T0C-wAaKU5gI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mkdir /root/.kaggle"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MRVPD0pTXJzt",
        "colab_type": "code",
        "outputId": "6a41a302-c0fe-476c-c89e-a4f43f06546f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "cd /root/.kaggle"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/root/.kaggle\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7dIYMOZ-U829",
        "colab_type": "code",
        "outputId": "e7afd30f-5cd8-4c5e-d5a8-ef28015e27e4",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 91
        }
      },
      "source": [
        "from google.colab import files\n",
        "files.upload()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-73401bc4-cf5b-4e42-9ef0-44649dc1efa2\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-73401bc4-cf5b-4e42-9ef0-44649dc1efa2\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving kaggle.json to kaggle.json\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'kaggle.json': b'{\"username\":\"samuelpreethaml\",\"key\":\"14617aaa25068d81fb4b1232097ec0ec\"}'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ykH4kcT0kC3G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mkdir /root/recommender"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5WrZQK1FkLIu",
        "colab_type": "code",
        "outputId": "73e879ce-5d57-4cd3-b7f6-65313f0c10e3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "cd /root/recommender"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/root/recommender\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5RQqaFac609n",
        "colab_type": "code",
        "outputId": "27b7c78a-e041-4991-bd9b-9dbc0e76334e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "!kaggle competitions download -c santander-product-recommendation"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Warning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 /root/.kaggle/kaggle.json'\n",
            "Downloading sample_submission.csv.zip to /root/recommender\n",
            "  0% 0.00/2.28M [00:00<?, ?B/s]\n",
            "100% 2.28M/2.28M [00:00<00:00, 76.8MB/s]\n",
            "Downloading test_ver2.csv.zip to /root/recommender\n",
            " 40% 5.00M/12.4M [00:00<00:00, 18.4MB/s]\n",
            "100% 12.4M/12.4M [00:00<00:00, 35.7MB/s]\n",
            "Downloading train_ver2.csv.zip to /root/recommender\n",
            " 98% 209M/214M [00:04<00:00, 46.1MB/s]\n",
            "100% 214M/214M [00:04<00:00, 45.6MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pMMAT0e_8aeP",
        "colab_type": "code",
        "outputId": "87ee06ed-2393-4b8c-fe7a-473125c32021",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "!unzip train_ver2.csv.zip\n",
        "!unzip test_ver2.csv.zip"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  train_ver2.csv.zip\n",
            "  inflating: train_ver2.csv          \n",
            "Archive:  test_ver2.csv.zip\n",
            "  inflating: test_ver2.csv           \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QrPmys6QQFJf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-2.4.4-bin-hadoop2.7\"\n",
        "os.environ['PYSPARK_SUBMIT_ARGS'] = '--packages databricks:tensorframes:0.6.0-s_2.11 pyspark-shell'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vgWdhwfCzWmw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sc = SparkContext(master='local',appName='test1')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jl5b6BQ5SXOK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "spark = SparkSession(sc)\n",
        "sqlContext = SQLContext(sc)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FTzcKEnuPGfb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = spark.read.csv(path='train_ver2.csv',sep=',',header=True,inferSchema=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k7eQo4D4Ipbu",
        "colab_type": "code",
        "outputId": "dc29f96f-2f40-49d2-fc2c-9c81098e3389",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 867
        }
      },
      "source": [
        "df.printSchema()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "root\n",
            " |-- fecha_dato: timestamp (nullable = true)\n",
            " |-- ncodpers: double (nullable = true)\n",
            " |-- ind_empleado: string (nullable = true)\n",
            " |-- pais_residencia: string (nullable = true)\n",
            " |-- sexo: string (nullable = true)\n",
            " |-- age: string (nullable = true)\n",
            " |-- fecha_alta: timestamp (nullable = true)\n",
            " |-- ind_nuevo: string (nullable = true)\n",
            " |-- antiguedad: string (nullable = true)\n",
            " |-- indrel: string (nullable = true)\n",
            " |-- ult_fec_cli_1t: timestamp (nullable = true)\n",
            " |-- indrel_1mes: string (nullable = true)\n",
            " |-- tiprel_1mes: string (nullable = true)\n",
            " |-- indresi: string (nullable = true)\n",
            " |-- indext: string (nullable = true)\n",
            " |-- conyuemp: string (nullable = true)\n",
            " |-- canal_entrada: string (nullable = true)\n",
            " |-- indfall: string (nullable = true)\n",
            " |-- tipodom: string (nullable = true)\n",
            " |-- cod_prov: string (nullable = true)\n",
            " |-- nomprov: string (nullable = true)\n",
            " |-- ind_actividad_cliente: string (nullable = true)\n",
            " |-- renta: double (nullable = true)\n",
            " |-- segmento: string (nullable = true)\n",
            " |-- ind_ahor_fin_ult1: integer (nullable = true)\n",
            " |-- ind_aval_fin_ult1: integer (nullable = true)\n",
            " |-- ind_cco_fin_ult1: integer (nullable = true)\n",
            " |-- ind_cder_fin_ult1: integer (nullable = true)\n",
            " |-- ind_cno_fin_ult1: integer (nullable = true)\n",
            " |-- ind_ctju_fin_ult1: integer (nullable = true)\n",
            " |-- ind_ctma_fin_ult1: integer (nullable = true)\n",
            " |-- ind_ctop_fin_ult1: integer (nullable = true)\n",
            " |-- ind_ctpp_fin_ult1: integer (nullable = true)\n",
            " |-- ind_deco_fin_ult1: integer (nullable = true)\n",
            " |-- ind_deme_fin_ult1: integer (nullable = true)\n",
            " |-- ind_dela_fin_ult1: integer (nullable = true)\n",
            " |-- ind_ecue_fin_ult1: integer (nullable = true)\n",
            " |-- ind_fond_fin_ult1: integer (nullable = true)\n",
            " |-- ind_hip_fin_ult1: integer (nullable = true)\n",
            " |-- ind_plan_fin_ult1: integer (nullable = true)\n",
            " |-- ind_pres_fin_ult1: integer (nullable = true)\n",
            " |-- ind_reca_fin_ult1: integer (nullable = true)\n",
            " |-- ind_tjcr_fin_ult1: integer (nullable = true)\n",
            " |-- ind_valo_fin_ult1: integer (nullable = true)\n",
            " |-- ind_viv_fin_ult1: integer (nullable = true)\n",
            " |-- ind_nomina_ult1: string (nullable = true)\n",
            " |-- ind_nom_pens_ult1: string (nullable = true)\n",
            " |-- ind_recibo_ult1: integer (nullable = true)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iUyLNWR6r6LZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "drop_list = ['ind_empleado','pais_residencia','fecha_alta','indrel','ult_fec_cli_1t','indrel_1mes','indresi','conyuemp','indfall','tipodom','nomprov']\n",
        "dfa = df.select([column for column in df.columns if column not in drop_list])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j1UjRFT5I-ze",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dfa=dfa.fillna({'renta':1})\n",
        "dfa=dfa.withColumn(\"antiguedad\",F.when(dfa[\"antiguedad\"] =='     NA',0).otherwise(dfa[\"antiguedad\"]))\n",
        "dfa=dfa.withColumn(\"antiguedad\",F.when(dfa[\"antiguedad\"] =='-999999',0).otherwise(dfa[\"antiguedad\"]))\n",
        "dfa=dfa.withColumn(\"antiguedad\",F.when(F.isnull('antiguedad'),0).otherwise(dfa[\"antiguedad\"]))\n",
        "dfa=dfa.withColumn(\"sexo\",F.when(F.isnull('sexo'),'V').otherwise(dfa[\"sexo\"]))\n",
        "dfa=dfa.withColumn(\"age\",F.when(F.isnull('age'),25).otherwise(dfa[\"age\"]))\n",
        "dfa=dfa.withColumn(\"age\",F.when(dfa[\"age\"] ==' NA',25).otherwise(dfa[\"age\"]))\n",
        "dfa=dfa.withColumn(\"tiprel_1mes\",F.when(F.isnull('tiprel_1mes'),'A').otherwise(dfa[\"tiprel_1mes\"]))\n",
        "dfa=dfa.withColumn(\"indext\",F.when(F.isnull('indext'),'N').otherwise(dfa[\"indext\"]))\n",
        "dfa=dfa.withColumn(\"canal_entrada\",F.when(F.isnull('canal_entrada'),'KHE').otherwise(dfa[\"canal_entrada\"]))\n",
        "dfa=dfa.withColumn(\"segmento\",F.when(F.isnull('segmento'),'02 - PARTICULARES').otherwise(dfa[\"segmento\"]))\n",
        "dfa=dfa.withColumn(\"cod_prov\",F.when(F.isnull('cod_prov'),50).otherwise(dfa[\"cod_prov\"]))\n",
        "dfa=dfa.withColumn(\"ind_nuevo\",F.when(F.isnull('ind_nuevo'),0).otherwise(dfa[\"ind_nuevo\"]))\n",
        "dfa=dfa.withColumn(\"ind_actividad_cliente\",F.when(F.isnull('ind_actividad_cliente'),0).otherwise(dfa[\"ind_actividad_cliente\"]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OeS8w_PxTFDx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dfb = dfa.withColumn('total', sum(dfa[col] for col in df.columns[-24:]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8BySzGd1op-M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dfc=dfb.filter(dfb.total!=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sbzzfm1bnGTf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dfd=dfc.fillna(0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jYk5tY-akjNt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dfe=dfd.withColumn(\"fecha_year\",F.year(F.col(\"fecha_dato\")))\n",
        "dff=dfe.withColumn(\"fecha_month\",F.month(F.col(\"fecha_dato\")))\n",
        "dfg=dff.withColumn(\"fecha_year\",F.when(dff[\"fecha_year\"] ==2015,0).otherwise(1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YEqUayeRvEEL",
        "colab_type": "code",
        "outputId": "edb91721-7c1d-4446-d553-efc72f991165",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 479
        }
      },
      "source": [
        "from pyspark.ml import Pipeline\n",
        "from pyspark.ml.feature import StringIndexer\n",
        "\n",
        "indexers = [StringIndexer(inputCol=column, outputCol=column+\"_index\").fit(dfg) for column in ['sexo','tiprel_1mes','indext','canal_entrada','segmento']]\n",
        "\n",
        "\n",
        "pipeline = Pipeline(stages=indexers)\n",
        "dfl = pipeline.fit(dfg).transform(dfg)\n",
        "dfl.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-------------------+---------+----+---+---------+----------+-----------+------+-------------+--------+---------------------+------------------+------------------+-----------------+-----------------+----------------+-----------------+----------------+-----------------+-----------------+-----------------+-----------------+-----------------+-----------------+-----------------+-----------------+-----------------+----------------+-----------------+-----------------+-----------------+-----------------+-----------------+----------------+---------------+-----------------+---------------+-----+----------+-----------+----------+-----------------+------------+-------------------+--------------+\n",
            "|         fecha_dato| ncodpers|sexo|age|ind_nuevo|antiguedad|tiprel_1mes|indext|canal_entrada|cod_prov|ind_actividad_cliente|             renta|          segmento|ind_ahor_fin_ult1|ind_aval_fin_ult1|ind_cco_fin_ult1|ind_cder_fin_ult1|ind_cno_fin_ult1|ind_ctju_fin_ult1|ind_ctma_fin_ult1|ind_ctop_fin_ult1|ind_ctpp_fin_ult1|ind_deco_fin_ult1|ind_deme_fin_ult1|ind_dela_fin_ult1|ind_ecue_fin_ult1|ind_fond_fin_ult1|ind_hip_fin_ult1|ind_plan_fin_ult1|ind_pres_fin_ult1|ind_reca_fin_ult1|ind_tjcr_fin_ult1|ind_valo_fin_ult1|ind_viv_fin_ult1|ind_nomina_ult1|ind_nom_pens_ult1|ind_recibo_ult1|total|fecha_year|fecha_month|sexo_index|tiprel_1mes_index|indext_index|canal_entrada_index|segmento_index|\n",
            "+-------------------+---------+----+---+---------+----------+-----------+------+-------------+--------+---------------------+------------------+------------------+-----------------+-----------------+----------------+-----------------+----------------+-----------------+-----------------+-----------------+-----------------+-----------------+-----------------+-----------------+-----------------+-----------------+----------------+-----------------+-----------------+-----------------+-----------------+-----------------+----------------+---------------+-----------------+---------------+-----+----------+-----------+----------+-----------------+------------+-------------------+--------------+\n",
            "|2015-01-28 00:00:00|1375586.0|   H| 35|        0|         6|          A|     N|          KHL|      29|                    1|           87218.1| 02 - PARTICULARES|                0|                0|               1|                0|               0|                0|                0|                0|                0|                0|                0|                0|                0|                0|               0|                0|                0|                0|                0|                0|               0|              0|                0|              0|  1.0|         0|          1|       1.0|              0.0|         0.0|               17.0|           0.0|\n",
            "|2015-01-28 00:00:00|1050611.0|   V| 23|        0|        35|          I|     S|          KHE|      13|                    0|          35548.74|03 - UNIVERSITARIO|                0|                0|               1|                0|               0|                0|                0|                0|                0|                0|                0|                0|                0|                0|               0|                0|                0|                0|                0|                0|               0|              0|                0|              0|  1.0|         0|          1|       0.0|              1.0|         1.0|                0.0|           1.0|\n",
            "|2015-01-28 00:00:00|1050612.0|   V| 23|        0|        35|          I|     N|          KHE|      13|                    0|122179.11000000002|03 - UNIVERSITARIO|                0|                0|               1|                0|               0|                0|                0|                0|                0|                0|                0|                0|                0|                0|               0|                0|                0|                0|                0|                0|               0|              0|                0|              0|  1.0|         0|          1|       0.0|              1.0|         0.0|                0.0|           1.0|\n",
            "|2015-01-28 00:00:00|1050613.0|   H| 22|        0|        35|          I|     N|          KHD|      50|                    0|         119775.54|03 - UNIVERSITARIO|                0|                0|               0|                0|               0|                0|                0|                0|                0|                1|                0|                0|                0|                0|               0|                0|                0|                0|                0|                0|               0|              0|                0|              0|  1.0|         0|          1|       1.0|              1.0|         0.0|                7.0|           1.0|\n",
            "|2015-01-28 00:00:00|1050614.0|   V| 23|        0|        35|          A|     N|          KHE|      50|                    1|               1.0|03 - UNIVERSITARIO|                0|                0|               1|                0|               0|                0|                0|                0|                0|                0|                0|                0|                0|                0|               0|                0|                0|                0|                0|                0|               0|              0|                0|              0|  1.0|         0|          1|       0.0|              0.0|         0.0|                0.0|           1.0|\n",
            "|2015-01-28 00:00:00|1050615.0|   H| 23|        0|        35|          I|     N|          KHE|      45|                    0|          22220.04|03 - UNIVERSITARIO|                0|                0|               1|                0|               0|                0|                0|                0|                0|                0|                0|                0|                0|                0|               0|                0|                0|                0|                0|                0|               0|              0|                0|              0|  1.0|         0|          1|       1.0|              1.0|         0.0|                0.0|           1.0|\n",
            "|2015-01-28 00:00:00|1050616.0|   H| 23|        0|        35|          I|     N|          KHE|      24|                    0|         295590.36|03 - UNIVERSITARIO|                0|                0|               1|                0|               0|                0|                0|                0|                0|                0|                0|                0|                0|                0|               0|                0|                0|                0|                0|                0|               0|              0|                0|              0|  1.0|         0|          1|       1.0|              1.0|         0.0|                0.0|           1.0|\n",
            "|2015-01-28 00:00:00|1050617.0|   H| 23|        0|        35|          A|     N|          KHE|      50|                    1|         113316.66|03 - UNIVERSITARIO|                0|                0|               1|                0|               0|                0|                0|                0|                0|                0|                0|                0|                0|                0|               0|                0|                0|                0|                0|                0|               0|              0|                0|              0|  1.0|         0|          1|       1.0|              0.0|         0.0|                0.0|           1.0|\n",
            "|2015-01-28 00:00:00|1050619.0|   H| 24|        0|        35|          I|     N|          KHE|      20|                    0|               1.0|03 - UNIVERSITARIO|                0|                0|               1|                0|               0|                0|                0|                0|                0|                0|                0|                0|                0|                0|               0|                0|                0|                0|                0|                0|               0|              0|                0|              0|  1.0|         0|          1|       1.0|              1.0|         0.0|                0.0|           1.0|\n",
            "|2015-01-28 00:00:00|1050620.0|   H| 23|        0|        35|          I|     N|          KHE|      10|                    0|         113194.98|03 - UNIVERSITARIO|                0|                0|               1|                0|               0|                0|                0|                0|                0|                0|                0|                0|                0|                0|               0|                0|                0|                0|                0|                0|               0|              0|                0|              0|  1.0|         0|          1|       1.0|              1.0|         0.0|                0.0|           1.0|\n",
            "|2015-01-28 00:00:00|1050621.0|   V| 23|        0|        35|          I|     N|          KHE|      50|                    0|          72575.88|03 - UNIVERSITARIO|                0|                0|               1|                0|               0|                0|                0|                0|                0|                0|                0|                0|                0|                0|               0|                0|                0|                0|                0|                0|               0|              0|                0|              0|  1.0|         0|          1|       0.0|              1.0|         0.0|                0.0|           1.0|\n",
            "|2015-01-28 00:00:00|1050622.0|   H| 23|        0|        35|          I|     N|          KHE|      17|                    0|               1.0|03 - UNIVERSITARIO|                0|                0|               1|                0|               0|                0|                0|                0|                0|                0|                0|                0|                0|                0|               0|                0|                0|                0|                0|                0|               0|              0|                0|              0|  1.0|         0|          1|       1.0|              1.0|         0.0|                0.0|           1.0|\n",
            "|2015-01-28 00:00:00|1050623.0|   H| 23|        0|        35|          A|     N|          KHE|      49|                    1|         113538.81|03 - UNIVERSITARIO|                0|                0|               1|                0|               0|                0|                0|                0|                0|                0|                0|                0|                0|                0|               0|                0|                0|                0|                0|                0|               0|              0|                0|              0|  1.0|         0|          1|       1.0|              0.0|         0.0|                0.0|           1.0|\n",
            "|2015-01-28 00:00:00|1050624.0|   H| 65|        0|        35|          A|     N|          KHE|      50|                    1|          61605.09| 02 - PARTICULARES|                0|                0|               1|                0|               0|                0|                0|                0|                0|                0|                0|                0|                0|                0|               0|                0|                0|                0|                0|                0|               0|              0|                0|              0|  1.0|         0|          1|       1.0|              0.0|         0.0|                0.0|           0.0|\n",
            "|2015-01-28 00:00:00|1050625.0|   V| 23|        0|        35|          A|     N|          KHE|      49|                    1|               1.0|03 - UNIVERSITARIO|                0|                0|               1|                0|               0|                0|                0|                0|                0|                0|                0|                0|                0|                0|               0|                0|                0|                0|                0|                0|               0|              0|                0|              0|  1.0|         0|          1|       0.0|              0.0|         0.0|                0.0|           1.0|\n",
            "|2015-01-28 00:00:00|1050626.0|   V| 23|        0|        35|          A|     N|          KHE|       8|                    1|               1.0|03 - UNIVERSITARIO|                0|                0|               1|                0|               0|                0|                0|                0|                0|                0|                0|                0|                0|                0|               0|                0|                0|                0|                0|                0|               0|              0|                0|              0|  1.0|         0|          1|       0.0|              0.0|         0.0|                0.0|           1.0|\n",
            "|2015-01-28 00:00:00|1050610.0|   V| 24|        0|        35|          I|     N|          KHE|      37|                    1| 68318.45999999999|03 - UNIVERSITARIO|                0|                0|               1|                0|               0|                0|                0|                0|                0|                0|                0|                0|                0|                0|               0|                0|                0|                0|                0|                0|               0|              0|                0|              0|  1.0|         0|          1|       0.0|              1.0|         0.0|                0.0|           1.0|\n",
            "|2015-01-28 00:00:00|1050627.0|   H| 23|        0|        35|          I|     N|          KHE|      13|                    0|          65608.35|03 - UNIVERSITARIO|                0|                0|               1|                0|               0|                0|                0|                0|                0|                0|                0|                0|                0|                0|               0|                0|                0|                0|                0|                0|               0|              0|                0|              0|  1.0|         0|          1|       1.0|              1.0|         0.0|                0.0|           1.0|\n",
            "|2015-01-28 00:00:00|1050609.0|   H| 22|        0|        35|          I|     N|          KFA|      13|                    1|          73432.47|03 - UNIVERSITARIO|                0|                0|               1|                0|               0|                0|                0|                0|                0|                0|                0|                0|                0|                0|               0|                0|                0|                0|                0|                0|               0|              0|                0|              0|  1.0|         0|          1|       1.0|              1.0|         0.0|                4.0|           1.0|\n",
            "|2015-01-28 00:00:00|1050605.0|   V| 23|        0|        35|          I|     N|          KHE|      45|                    0|               1.0|03 - UNIVERSITARIO|                0|                0|               1|                0|               0|                0|                0|                0|                0|                0|                0|                0|                0|                0|               0|                0|                0|                0|                0|                0|               0|              0|                0|              0|  1.0|         0|          1|       0.0|              1.0|         0.0|                0.0|           1.0|\n",
            "+-------------------+---------+----+---+---------+----------+-----------+------+-------------+--------+---------------------+------------------+------------------+-----------------+-----------------+----------------+-----------------+----------------+-----------------+-----------------+-----------------+-----------------+-----------------+-----------------+-----------------+-----------------+-----------------+----------------+-----------------+-----------------+-----------------+-----------------+-----------------+----------------+---------------+-----------------+---------------+-----+----------+-----------+----------+-----------------+------------+-------------------+--------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "znNezZx0wmrU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "drop_list = ['fecha_dato','sexo','tiprel_1mes','indext','canal_entrada','segmento']\n",
        "dfk = dfl.select([column for column in dfl.columns if column not in drop_list])\n",
        "dfk=dfk.withColumn(\"ind_nuevo\",F.when(F.isnull('ind_nuevo'),0).otherwise(dfk[\"ind_nuevo\"]))\n",
        "dfk=dfk.withColumn(\"cod_prov\",F.when(F.isnull('cod_prov'),50).otherwise(dfk[\"cod_prov\"]))\n",
        "dfk=dfk.withColumn(\"ind_actividad_cliente\",F.when(F.isnull('ind_actividad_cliente'),0).otherwise(dfk[\"ind_actividad_cliente\"]))\n",
        "dfk=dfk.withColumn(\"ind_nuevo\",F.when(dfk[\"ind_nuevo\"]=='NA',0).otherwise(dfk[\"ind_nuevo\"]))\n",
        "dfk=dfk.withColumn(\"cod_prov\",F.when(dfk[\"cod_prov\"]=='NA',50).otherwise(dfk[\"cod_prov\"]))\n",
        "dfk=dfk.withColumn(\"ind_actividad_cliente\",F.when(dfk[\"ind_actividad_cliente\"]=='NA',50).otherwise(dfk[\"ind_actividad_cliente\"]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mdwNkm5M6N03",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data=dfk.select(dfk.ncodpers.cast('double'),dfk.age.cast('float'),dfk.ind_nuevo.cast('float'),dfk.antiguedad.cast('float'),dfk.cod_prov.cast('float'),dfk.ind_actividad_cliente.cast('float'),dfk.renta.cast('double'),dfk.sexo_index.cast('float'),dfk.tiprel_1mes_index.cast('float'),dfk.indext_index.cast('float'),dfk.canal_entrada_index.cast('float'),dfk.segmento_index.cast('float'),dfk.fecha_year.cast('integer'),dfk.fecha_month.cast('integer'),dfk.total.cast('integer'),dfk.ind_ahor_fin_ult1.cast('integer'),dfk.ind_aval_fin_ult1.cast('integer'),dfk.ind_cco_fin_ult1.cast('integer'),dfk.ind_cder_fin_ult1.cast('integer'),dfk.ind_cno_fin_ult1.cast('integer'),dfk.ind_ctju_fin_ult1.cast('integer'),dfk.ind_ctma_fin_ult1.cast('integer'),dfk.ind_ctop_fin_ult1.cast('integer'),dfk.ind_ctpp_fin_ult1.cast('integer'),dfk.ind_deco_fin_ult1.cast('integer'),dfk.ind_deme_fin_ult1.cast('integer'),dfk.ind_dela_fin_ult1.cast('integer'),dfk.ind_ecue_fin_ult1.cast('integer'),dfk.ind_fond_fin_ult1.cast('integer'),dfk.ind_hip_fin_ult1.cast('integer'),dfk.ind_plan_fin_ult1.cast('integer'),dfk.ind_pres_fin_ult1.cast('integer'),dfk.ind_reca_fin_ult1.cast('integer'),dfk.ind_tjcr_fin_ult1.cast('integer'),dfk.ind_valo_fin_ult1.cast('integer'),dfk.ind_viv_fin_ult1.cast('integer'),dfk.ind_nomina_ult1.cast('float'),dfk.ind_nom_pens_ult1.cast('float'),dfk.ind_recibo_ult1.cast('integer'))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ygo9ck20-oHl",
        "colab_type": "code",
        "outputId": "11b4f635-c874-4b2d-9db0-21f8e1f6f161",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 309
        }
      },
      "source": [
        "data.show(10)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+---------+----+---------+----------+--------+---------------------+------------------+----------+-----------------+------------+-------------------+--------------+----------+-----------+-----+-----------------+-----------------+----------------+-----------------+----------------+-----------------+-----------------+-----------------+-----------------+-----------------+-----------------+-----------------+-----------------+-----------------+----------------+-----------------+-----------------+-----------------+-----------------+-----------------+----------------+---------------+-----------------+---------------+\n",
            "| ncodpers| age|ind_nuevo|antiguedad|cod_prov|ind_actividad_cliente|             renta|sexo_index|tiprel_1mes_index|indext_index|canal_entrada_index|segmento_index|fecha_year|fecha_month|total|ind_ahor_fin_ult1|ind_aval_fin_ult1|ind_cco_fin_ult1|ind_cder_fin_ult1|ind_cno_fin_ult1|ind_ctju_fin_ult1|ind_ctma_fin_ult1|ind_ctop_fin_ult1|ind_ctpp_fin_ult1|ind_deco_fin_ult1|ind_deme_fin_ult1|ind_dela_fin_ult1|ind_ecue_fin_ult1|ind_fond_fin_ult1|ind_hip_fin_ult1|ind_plan_fin_ult1|ind_pres_fin_ult1|ind_reca_fin_ult1|ind_tjcr_fin_ult1|ind_valo_fin_ult1|ind_viv_fin_ult1|ind_nomina_ult1|ind_nom_pens_ult1|ind_recibo_ult1|\n",
            "+---------+----+---------+----------+--------+---------------------+------------------+----------+-----------------+------------+-------------------+--------------+----------+-----------+-----+-----------------+-----------------+----------------+-----------------+----------------+-----------------+-----------------+-----------------+-----------------+-----------------+-----------------+-----------------+-----------------+-----------------+----------------+-----------------+-----------------+-----------------+-----------------+-----------------+----------------+---------------+-----------------+---------------+\n",
            "|1375586.0|35.0|      0.0|       6.0|    29.0|                  1.0|           87218.1|       1.0|              0.0|         0.0|               17.0|           0.0|         0|          1|    1|                0|                0|               1|                0|               0|                0|                0|                0|                0|                0|                0|                0|                0|                0|               0|                0|                0|                0|                0|                0|               0|            0.0|              0.0|              0|\n",
            "|1050611.0|23.0|      0.0|      35.0|    13.0|                  0.0|          35548.74|       0.0|              1.0|         1.0|                0.0|           1.0|         0|          1|    1|                0|                0|               1|                0|               0|                0|                0|                0|                0|                0|                0|                0|                0|                0|               0|                0|                0|                0|                0|                0|               0|            0.0|              0.0|              0|\n",
            "|1050612.0|23.0|      0.0|      35.0|    13.0|                  0.0|122179.11000000002|       0.0|              1.0|         0.0|                0.0|           1.0|         0|          1|    1|                0|                0|               1|                0|               0|                0|                0|                0|                0|                0|                0|                0|                0|                0|               0|                0|                0|                0|                0|                0|               0|            0.0|              0.0|              0|\n",
            "|1050613.0|22.0|      0.0|      35.0|    50.0|                  0.0|         119775.54|       1.0|              1.0|         0.0|                7.0|           1.0|         0|          1|    1|                0|                0|               0|                0|               0|                0|                0|                0|                0|                1|                0|                0|                0|                0|               0|                0|                0|                0|                0|                0|               0|            0.0|              0.0|              0|\n",
            "|1050614.0|23.0|      0.0|      35.0|    50.0|                  1.0|               1.0|       0.0|              0.0|         0.0|                0.0|           1.0|         0|          1|    1|                0|                0|               1|                0|               0|                0|                0|                0|                0|                0|                0|                0|                0|                0|               0|                0|                0|                0|                0|                0|               0|            0.0|              0.0|              0|\n",
            "|1050615.0|23.0|      0.0|      35.0|    45.0|                  0.0|          22220.04|       1.0|              1.0|         0.0|                0.0|           1.0|         0|          1|    1|                0|                0|               1|                0|               0|                0|                0|                0|                0|                0|                0|                0|                0|                0|               0|                0|                0|                0|                0|                0|               0|            0.0|              0.0|              0|\n",
            "|1050616.0|23.0|      0.0|      35.0|    24.0|                  0.0|         295590.36|       1.0|              1.0|         0.0|                0.0|           1.0|         0|          1|    1|                0|                0|               1|                0|               0|                0|                0|                0|                0|                0|                0|                0|                0|                0|               0|                0|                0|                0|                0|                0|               0|            0.0|              0.0|              0|\n",
            "|1050617.0|23.0|      0.0|      35.0|    50.0|                  1.0|         113316.66|       1.0|              0.0|         0.0|                0.0|           1.0|         0|          1|    1|                0|                0|               1|                0|               0|                0|                0|                0|                0|                0|                0|                0|                0|                0|               0|                0|                0|                0|                0|                0|               0|            0.0|              0.0|              0|\n",
            "|1050619.0|24.0|      0.0|      35.0|    20.0|                  0.0|               1.0|       1.0|              1.0|         0.0|                0.0|           1.0|         0|          1|    1|                0|                0|               1|                0|               0|                0|                0|                0|                0|                0|                0|                0|                0|                0|               0|                0|                0|                0|                0|                0|               0|            0.0|              0.0|              0|\n",
            "|1050620.0|23.0|      0.0|      35.0|    10.0|                  0.0|         113194.98|       1.0|              1.0|         0.0|                0.0|           1.0|         0|          1|    1|                0|                0|               1|                0|               0|                0|                0|                0|                0|                0|                0|                0|                0|                0|               0|                0|                0|                0|                0|                0|               0|            0.0|              0.0|              0|\n",
            "+---------+----+---------+----------+--------+---------------------+------------------+----------+-----------------+------------+-------------------+--------------+----------+-----------+-----+-----------------+-----------------+----------------+-----------------+----------------+-----------------+-----------------+-----------------+-----------------+-----------------+-----------------+-----------------+-----------------+-----------------+----------------+-----------------+-----------------+-----------------+-----------------+-----------------+----------------+---------------+-----------------+---------------+\n",
            "only showing top 10 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dr7-8S-UESe0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vecAssembler = VectorAssembler(inputCols=[\"ncodpers\",\"age\",\"ind_nuevo\",\"antiguedad\",\"cod_prov\",\"ind_actividad_cliente\",\"renta\",\"sexo_index\",\"tiprel_1mes_index\",\"indext_index\",\"canal_entrada_index\",\"segmento_index\",\"fecha_year\",\"fecha_month\",\"total\"], outputCol='features')\n",
        "dt=vecAssembler.transform(data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Fc6Zp5gEfaY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vecAssembler = VectorAssembler(inputCols=[\"ind_ahor_fin_ult1\",\"ind_aval_fin_ult1\",\"ind_cco_fin_ult1\",'ind_cder_fin_ult1', 'ind_cno_fin_ult1','ind_ctju_fin_ult1','ind_ctma_fin_ult1','ind_ctop_fin_ult1','ind_ctpp_fin_ult1','ind_deco_fin_ult1','ind_deme_fin_ult1','ind_dela_fin_ult1','ind_ecue_fin_ult1','ind_fond_fin_ult1','ind_hip_fin_ult1','ind_plan_fin_ult1','ind_pres_fin_ult1','ind_reca_fin_ult1', 'ind_tjcr_fin_ult1','ind_valo_fin_ult1','ind_viv_fin_ult1','ind_nomina_ult1','ind_nom_pens_ult1','ind_recibo_ult1'], outputCol='label')\n",
        "dts=vecAssembler.transform(dt)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lbr23gGukdHj",
        "colab_type": "code",
        "outputId": "5938e497-f0b8-4f6b-f3bf-8527244e4d8e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 309
        }
      },
      "source": [
        "dts.show(10)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+---------+----+---------+----------+--------+---------------------+------------------+----------+-----------------+------------+-------------------+--------------+----------+-----------+-----+-----------------+-----------------+----------------+-----------------+----------------+-----------------+-----------------+-----------------+-----------------+-----------------+-----------------+-----------------+-----------------+-----------------+----------------+-----------------+-----------------+-----------------+-----------------+-----------------+----------------+---------------+-----------------+---------------+--------------------+--------------+\n",
            "| ncodpers| age|ind_nuevo|antiguedad|cod_prov|ind_actividad_cliente|             renta|sexo_index|tiprel_1mes_index|indext_index|canal_entrada_index|segmento_index|fecha_year|fecha_month|total|ind_ahor_fin_ult1|ind_aval_fin_ult1|ind_cco_fin_ult1|ind_cder_fin_ult1|ind_cno_fin_ult1|ind_ctju_fin_ult1|ind_ctma_fin_ult1|ind_ctop_fin_ult1|ind_ctpp_fin_ult1|ind_deco_fin_ult1|ind_deme_fin_ult1|ind_dela_fin_ult1|ind_ecue_fin_ult1|ind_fond_fin_ult1|ind_hip_fin_ult1|ind_plan_fin_ult1|ind_pres_fin_ult1|ind_reca_fin_ult1|ind_tjcr_fin_ult1|ind_valo_fin_ult1|ind_viv_fin_ult1|ind_nomina_ult1|ind_nom_pens_ult1|ind_recibo_ult1|            features|         label|\n",
            "+---------+----+---------+----------+--------+---------------------+------------------+----------+-----------------+------------+-------------------+--------------+----------+-----------+-----+-----------------+-----------------+----------------+-----------------+----------------+-----------------+-----------------+-----------------+-----------------+-----------------+-----------------+-----------------+-----------------+-----------------+----------------+-----------------+-----------------+-----------------+-----------------+-----------------+----------------+---------------+-----------------+---------------+--------------------+--------------+\n",
            "|1375586.0|35.0|      0.0|       6.0|    29.0|                  1.0|           87218.1|       1.0|              0.0|         0.0|               17.0|           0.0|         0|          1|    1|                0|                0|               1|                0|               0|                0|                0|                0|                0|                0|                0|                0|                0|                0|               0|                0|                0|                0|                0|                0|               0|            0.0|              0.0|              0|[1375586.0,35.0,0...|(24,[2],[1.0])|\n",
            "|1050611.0|23.0|      0.0|      35.0|    13.0|                  0.0|          35548.74|       0.0|              1.0|         1.0|                0.0|           1.0|         0|          1|    1|                0|                0|               1|                0|               0|                0|                0|                0|                0|                0|                0|                0|                0|                0|               0|                0|                0|                0|                0|                0|               0|            0.0|              0.0|              0|[1050611.0,23.0,0...|(24,[2],[1.0])|\n",
            "|1050612.0|23.0|      0.0|      35.0|    13.0|                  0.0|122179.11000000002|       0.0|              1.0|         0.0|                0.0|           1.0|         0|          1|    1|                0|                0|               1|                0|               0|                0|                0|                0|                0|                0|                0|                0|                0|                0|               0|                0|                0|                0|                0|                0|               0|            0.0|              0.0|              0|[1050612.0,23.0,0...|(24,[2],[1.0])|\n",
            "|1050613.0|22.0|      0.0|      35.0|    50.0|                  0.0|         119775.54|       1.0|              1.0|         0.0|                7.0|           1.0|         0|          1|    1|                0|                0|               0|                0|               0|                0|                0|                0|                0|                1|                0|                0|                0|                0|               0|                0|                0|                0|                0|                0|               0|            0.0|              0.0|              0|[1050613.0,22.0,0...|(24,[9],[1.0])|\n",
            "|1050614.0|23.0|      0.0|      35.0|    50.0|                  1.0|               1.0|       0.0|              0.0|         0.0|                0.0|           1.0|         0|          1|    1|                0|                0|               1|                0|               0|                0|                0|                0|                0|                0|                0|                0|                0|                0|               0|                0|                0|                0|                0|                0|               0|            0.0|              0.0|              0|[1050614.0,23.0,0...|(24,[2],[1.0])|\n",
            "|1050615.0|23.0|      0.0|      35.0|    45.0|                  0.0|          22220.04|       1.0|              1.0|         0.0|                0.0|           1.0|         0|          1|    1|                0|                0|               1|                0|               0|                0|                0|                0|                0|                0|                0|                0|                0|                0|               0|                0|                0|                0|                0|                0|               0|            0.0|              0.0|              0|[1050615.0,23.0,0...|(24,[2],[1.0])|\n",
            "|1050616.0|23.0|      0.0|      35.0|    24.0|                  0.0|         295590.36|       1.0|              1.0|         0.0|                0.0|           1.0|         0|          1|    1|                0|                0|               1|                0|               0|                0|                0|                0|                0|                0|                0|                0|                0|                0|               0|                0|                0|                0|                0|                0|               0|            0.0|              0.0|              0|[1050616.0,23.0,0...|(24,[2],[1.0])|\n",
            "|1050617.0|23.0|      0.0|      35.0|    50.0|                  1.0|         113316.66|       1.0|              0.0|         0.0|                0.0|           1.0|         0|          1|    1|                0|                0|               1|                0|               0|                0|                0|                0|                0|                0|                0|                0|                0|                0|               0|                0|                0|                0|                0|                0|               0|            0.0|              0.0|              0|[1050617.0,23.0,0...|(24,[2],[1.0])|\n",
            "|1050619.0|24.0|      0.0|      35.0|    20.0|                  0.0|               1.0|       1.0|              1.0|         0.0|                0.0|           1.0|         0|          1|    1|                0|                0|               1|                0|               0|                0|                0|                0|                0|                0|                0|                0|                0|                0|               0|                0|                0|                0|                0|                0|               0|            0.0|              0.0|              0|[1050619.0,24.0,0...|(24,[2],[1.0])|\n",
            "|1050620.0|23.0|      0.0|      35.0|    10.0|                  0.0|         113194.98|       1.0|              1.0|         0.0|                0.0|           1.0|         0|          1|    1|                0|                0|               1|                0|               0|                0|                0|                0|                0|                0|                0|                0|                0|                0|               0|                0|                0|                0|                0|                0|               0|            0.0|              0.0|              0|[1050620.0,23.0,0...|(24,[2],[1.0])|\n",
            "+---------+----+---------+----------+--------+---------------------+------------------+----------+-----------------+------------+-------------------+--------------+----------+-----------+-----+-----------------+-----------------+----------------+-----------------+----------------+-----------------+-----------------+-----------------+-----------------+-----------------+-----------------+-----------------+-----------------+-----------------+----------------+-----------------+-----------------+-----------------+-----------------+-----------------+----------------+---------------+-----------------+---------------+--------------------+--------------+\n",
            "only showing top 10 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_UuVQBYlT_OY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ncodpers=tfs.row(data,'ncodpers')\n",
        "ncod=ncodpers"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WymFEWThUEmO",
        "colab_type": "code",
        "outputId": "4987a831-419f-4384-f78a-62dff0674ca8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 734
        }
      },
      "source": [
        "tfs.map_rows(ncod,data)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "Py4JJavaError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-37-2721941e40e1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtfs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_rows\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mncod\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorframes/core.py\u001b[0m in \u001b[0;36mmap_rows\u001b[0;34m(fetches, dframe, feed_dict, initial_variables)\u001b[0m\n\u001b[1;32m    262\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdframe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_map_pd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdframe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mblock\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitial_variables\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 264\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_map\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdframe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mblock\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitial_variables\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    265\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmap_blocks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdframe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitial_variables\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_initial_variables_default\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorframes/core.py\u001b[0m in \u001b[0;36m_map\u001b[0;34m(fetches, dframe, feed_dict, block, trim, initial_variables)\u001b[0m\n\u001b[1;32m    152\u001b[0m     \u001b[0mph_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_add_shapes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuilder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m     \u001b[0m_add_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuilder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mph_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 154\u001b[0;31m     \u001b[0mjdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuilder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuildDF\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    155\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_sql\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1255\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1256\u001b[0m         return_value = get_return_value(\n\u001b[0;32m-> 1257\u001b[0;31m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[0m\u001b[1;32m   1258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1259\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtemp_arg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtemp_args\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdeco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mpy4j\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPy4JJavaError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjava_exception\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/py4j/protocol.py\u001b[0m in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    326\u001b[0m                 raise Py4JJavaError(\n\u001b[1;32m    327\u001b[0m                     \u001b[0;34m\"An error occurred while calling {0}{1}{2}.\\n\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 328\u001b[0;31m                     format(target_id, \".\", name), value)\n\u001b[0m\u001b[1;32m    329\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m                 raise Py4JError(\n",
            "\u001b[0;31mPy4JJavaError\u001b[0m: An error occurred while calling o805.buildDF.\n: java.lang.Exception: Graph input ncodpers_1 found, but no column to match it. Dataframe columns: ncodpers, age, ind_nuevo, antiguedad, cod_prov, ind_actividad_cliente, renta, sexo_index, tiprel_1mes_index, indext_index, canal_entrada_index, segmento_index, fecha_year, fecha_month, total, ind_ahor_fin_ult1, ind_aval_fin_ult1, ind_cco_fin_ult1, ind_cder_fin_ult1, ind_cno_fin_ult1, ind_ctju_fin_ult1, ind_ctma_fin_ult1, ind_ctop_fin_ult1, ind_ctpp_fin_ult1, ind_deco_fin_ult1, ind_deme_fin_ult1, ind_dela_fin_ult1, ind_ecue_fin_ult1, ind_fond_fin_ult1, ind_hip_fin_ult1, ind_plan_fin_ult1, ind_pres_fin_ult1, ind_reca_fin_ult1, ind_tjcr_fin_ult1, ind_valo_fin_ult1, ind_viv_fin_ult1, ind_nomina_ult1, ind_nom_pens_ult1, ind_recibo_ult1\n\tat org.tensorframes.impl.SchemaTransforms$$anonfun$get$1.apply(DebugRowOps.scala:55)\n\tat org.tensorframes.impl.SchemaTransforms$$anonfun$get$1.apply(DebugRowOps.scala:55)\n\tat scala.Option.getOrElse(Option.scala:121)\n\tat org.tensorframes.impl.SchemaTransforms$class.get(DebugRowOps.scala:54)\n\tat org.tensorframes.impl.SchemaTransforms$.get(DebugRowOps.scala:275)\n\tat org.tensorframes.impl.DebugRowOps$$anonfun$mapRows$1.apply(DebugRowOps.scala:421)\n\tat org.tensorframes.impl.DebugRowOps$$anonfun$mapRows$1.apply(DebugRowOps.scala:416)\n\tat scala.collection.Iterator$class.foreach(Iterator.scala:891)\n\tat scala.collection.AbstractIterator.foreach(Iterator.scala:1334)\n\tat scala.collection.MapLike$DefaultValuesIterable.foreach(MapLike.scala:206)\n\tat org.tensorframes.impl.DebugRowOps.mapRows(DebugRowOps.scala:416)\n\tat org.tensorframes.impl.PythonOpBuilder.buildDF(PythonInterface.scala:147)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n\tat java.lang.Thread.run(Thread.java:748)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kjIFaOR8SOKF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D_Uwu-zUU-L1",
        "colab_type": "code",
        "outputId": "615a5037-b38e-4041-ce63-6e18501879bd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        }
      },
      "source": [
        "df=sqlContext.createDataFrame(zip(range(10),range(1,11))).toDF('x','y')\n",
        "df.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+---+---+\n",
            "|  x|  y|\n",
            "+---+---+\n",
            "|  0|  1|\n",
            "|  1|  2|\n",
            "|  2|  3|\n",
            "|  3|  4|\n",
            "|  4|  5|\n",
            "|  5|  6|\n",
            "|  6|  7|\n",
            "|  7|  8|\n",
            "|  8|  9|\n",
            "|  9| 10|\n",
            "+---+---+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SDs24ZvkVHyN",
        "colab_type": "code",
        "outputId": "b33f95f0-c211-45f3-d99b-7d9f04b314f4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        }
      },
      "source": [
        "dir(tfs)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['__builtins__',\n",
              " '__cached__',\n",
              " '__doc__',\n",
              " '__file__',\n",
              " '__loader__',\n",
              " '__name__',\n",
              " '__package__',\n",
              " '__path__',\n",
              " '__spec__',\n",
              " '__version__',\n",
              " 'absolute_import',\n",
              " 'aggregate',\n",
              " 'analyze',\n",
              " 'block',\n",
              " 'core',\n",
              " 'map_blocks',\n",
              " 'map_rows',\n",
              " 'print_schema',\n",
              " 'reduce_blocks',\n",
              " 'reduce_rows',\n",
              " 'row']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dg2GiJLcuOHi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from pyspark.ml.classification import LogisticRegression\n",
        "for col in train.columns[15:39]:\n",
        "  lr = LogisticRegression(labelCol=col, featuresCol=\"features\",maxIter=10)\n",
        "  model = lr.fit(train)\n",
        "  model.save('/root/pyspark/'+col)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rsHDrp7z8Bu9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predictions=lrModel.transform(test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xGqVF0KowTSQ",
        "colab_type": "code",
        "outputId": "0c18e909-b030-432b-f315-83ed0f0e0d53",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
        "evaluator = BinaryClassificationEvaluator(rawPredictionCol=\"prediction\",labelCol='ind_ahor_fin_ult1')\n",
        "evaluator.evaluate(predictions)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GCZp_x7zfKGh",
        "colab_type": "code",
        "outputId": "81cf2719-b856-472a-c1a5-b2d97350ce2a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 214
        }
      },
      "source": [
        "from pyspark.mllib.recommendation import ALS, Rating\n",
        "from pyspark.mllib.evaluation import RegressionMetrics, RankingMetrics\n",
        "\n",
        "# Read in the ratings data\n",
        "lines = sc.textFile(\"data/mllib/sample_movielens_data.txt\")\n",
        "\n",
        "def parseLine(line):\n",
        "    fields = line.split(\"::\")\n",
        "    return Rating(int(fields[0]), int(fields[1]), float(fields[2]) - 2.5)\n",
        "ratings = lines.map(lambda r: parseLine(r))\n",
        "\n",
        "# Train a model on to predict user-product ratings\n",
        "model = ALS.train(ratings, 10, 10, 0.01)\n",
        "\n",
        "# Get predicted ratings on all existing user-product pairs\n",
        "testData = ratings.map(lambda p: (p.user, p.product))\n",
        "predictions = model.predictAll(testData).map(lambda r: ((r.user, r.product), r.rating))\n",
        "\n",
        "ratingsTuple = ratings.map(lambda r: ((r.user, r.product), r.rating))\n",
        "scoreAndLabels = predictions.join(ratingsTuple).map(lambda tup: tup[1])\n",
        "\n",
        "# Instantiate regression metrics to compare predicted and actual ratings\n",
        "metrics = RegressionMetrics(scoreAndLabels)\n",
        "\n",
        "# Root mean squared error\n",
        "print(\"RMSE = %s\" % metrics.rootMeanSquaredError)\n",
        "\n",
        "# R-squared\n",
        "print(\"R-squared = %s\" % metrics.r2)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-124-c96d66fd4fda>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpredictions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpyspark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluation\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mMulticlassClassificationEvaluator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mevaluator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMulticlassClassificationEvaluator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictionCol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"prediction\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mevaluator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'LogisticRegression' object has no attribute 'transform'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EJtnLMLlScyz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!cd /root/pyspark"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ji1YZrXQe874",
        "colab_type": "code",
        "outputId": "c3665108-8504-4840-b590-cc13ff258c72",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 251
        }
      },
      "source": [
        "r1 = (1, (1.0,2.0),1)\n",
        "r2 = (1, (2.0,1.0),2)\n",
        "r3 = (2, (2.0,2.0),2)\n",
        "ratings = sc.parallelize([r1, r2, r3])\n",
        "model = SVMWithSGD.train(ratings, iterations=100, step=1.0, regParam=0.01, miniBatchFraction=1.0, initialWeights=None, regType='l2', intercept=False, validateData=True, convergenceTol=0.001)\n",
        "model.predict(2, 2)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-ab1dfcf42e3d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mr2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m2.0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mr3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m2.0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mratings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparallelize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mr1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSVMWithSGD\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mratings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mregParam\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.01\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mminiBatchFraction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitialWeights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mregType\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'l2'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mintercept\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidateData\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvergenceTol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.001\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'sc' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ietvNAwfuMdn",
        "colab_type": "code",
        "outputId": "5941f1a8-f023-40b6-fdf5-89a6278949c7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 309
        }
      },
      "source": [
        "predictions.show(10)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+--------+----+---------+----------+--------+---------------------+-----------------+----------+-----------------+------------+-------------------+--------------+----------+-----------+-----+-----------------+-----------------+----------------+-----------------+----------------+-----------------+-----------------+-----------------+-----------------+-----------------+-----------------+-----------------+-----------------+-----------------+----------------+-----------------+-----------------+-----------------+-----------------+-----------------+----------------+---------------+-----------------+---------------+--------------------+--------------------+--------------------+--------------------+----------+\n",
            "|ncodpers| age|ind_nuevo|antiguedad|cod_prov|ind_actividad_cliente|            renta|sexo_index|tiprel_1mes_index|indext_index|canal_entrada_index|segmento_index|fecha_year|fecha_month|total|ind_ahor_fin_ult1|ind_aval_fin_ult1|ind_cco_fin_ult1|ind_cder_fin_ult1|ind_cno_fin_ult1|ind_ctju_fin_ult1|ind_ctma_fin_ult1|ind_ctop_fin_ult1|ind_ctpp_fin_ult1|ind_deco_fin_ult1|ind_deme_fin_ult1|ind_dela_fin_ult1|ind_ecue_fin_ult1|ind_fond_fin_ult1|ind_hip_fin_ult1|ind_plan_fin_ult1|ind_pres_fin_ult1|ind_reca_fin_ult1|ind_tjcr_fin_ult1|ind_valo_fin_ult1|ind_viv_fin_ult1|ind_nomina_ult1|ind_nom_pens_ult1|ind_recibo_ult1|            features|               label|       rawPrediction|         probability|prediction|\n",
            "+--------+----+---------+----------+--------+---------------------+-----------------+----------+-----------------+------------+-------------------+--------------+----------+-----------+-----+-----------------+-----------------+----------------+-----------------+----------------+-----------------+-----------------+-----------------+-----------------+-----------------+-----------------+-----------------+-----------------+-----------------+----------------+-----------------+-----------------+-----------------+-----------------+-----------------+----------------+---------------+-----------------+---------------+--------------------+--------------------+--------------------+--------------------+----------+\n",
            "| 15890.0|62.0|      0.0|     246.0|    28.0|                  1.0|71461.20000000001|       0.0|              0.0|         0.0|                1.0|           0.0|         0|          1|    8|                0|                0|               0|                0|               1|                0|                0|                0|                1|                0|                0|                0|                1|                0|               0|                1|                0|                0|                1|                0|               0|            1.0|              1.0|              1|[15890.0,62.0,0.0...|(24,[4,8,12,15,18...|[8.97706824851996...|[0.99987374343776...|       0.0|\n",
            "| 15892.0|61.0|      0.0|     246.0|    28.0|                  1.0|        430477.41|       1.0|              0.0|         0.0|                1.0|           2.0|         0|          1|    7|                0|                0|               0|                0|               1|                0|                0|                0|                0|                0|                0|                1|                1|                0|               0|                0|                0|                1|                1|                1|               0|            0.0|              0.0|              1|[15892.0,61.0,0.0...|(24,[4,11,12,17,1...|[8.97832352927530...|[0.99987390180579...|       0.0|\n",
            "| 15893.0|62.0|      0.0|     246.0|    28.0|                  1.0|        430477.41|       0.0|              0.0|         0.0|                1.0|           0.0|         0|          1|    2|                0|                0|               0|                0|               0|                0|                0|                0|                0|                0|                0|                1|                0|                0|               0|                0|                0|                0|                0|                1|               0|            0.0|              0.0|              0|[15893.0,62.0,0.0...|(24,[11,19],[1.0,...|[8.97874544321685...|[0.99987395499045...|       0.0|\n",
            "| 15900.0|48.0|      0.0|     246.0|    28.0|                  1.0|        105327.03|       0.0|              0.0|         0.0|                1.0|           0.0|         0|          1|    4|                0|                0|               0|                0|               1|                0|                0|                1|                0|                0|                0|                0|                0|                0|               0|                0|                0|                1|                0|                0|               0|            0.0|              0.0|              1|[15900.0,48.0,0.0...|(24,[4,7,17,23],[...|[8.97847792918999...|[0.99987392127138...|       0.0|\n",
            "| 15902.0|57.0|      0.0|     246.0|    28.0|                  1.0|        230408.25|       1.0|              0.0|         0.0|                1.0|           2.0|         0|          1|    2|                0|                0|               1|                0|               0|                0|                0|                0|                0|                0|                0|                1|                0|                0|               0|                0|                0|                0|                0|                0|               0|            0.0|              0.0|              0|[15902.0,57.0,0.0...|(24,[2,11],[1.0,1...|[8.98004648175462...|[0.99987411885260...|       0.0|\n",
            "| 15911.0|52.0|      0.0|     246.0|    28.0|                  1.0|        191298.66|       0.0|              0.0|         0.0|                1.0|           2.0|         0|          1|    8|                0|                0|               1|                0|               1|                0|                0|                0|                0|                0|                0|                1|                1|                0|               0|                1|                0|                0|                1|                1|               0|            0.0|              0.0|              1|[15911.0,52.0,0.0...|(24,[2,4,11,12,15...|[8.97791451077226...|[0.99987385022525...|       0.0|\n",
            "| 15913.0|47.0|      0.0|     246.0|    28.0|                  1.0|        163073.19|       0.0|              0.0|         0.0|                1.0|           0.0|         0|          1|    4|                0|                0|               0|                0|               0|                0|                0|                0|                0|                0|                0|                0|                1|                0|               0|                1|                0|                0|                1|                0|               0|            0.0|              0.0|              1|[15913.0,47.0,0.0...|(24,[12,15,18,23]...|[8.97845898914598...|[0.99987391888372...|       0.0|\n",
            "| 15914.0|55.0|      0.0|     246.0|    28.0|                  1.0|        331242.63|       1.0|              0.0|         0.0|                1.0|           2.0|         0|          1|    9|                0|                0|               1|                0|               1|                0|                0|                0|                0|                0|                0|                0|                1|                0|               1|                0|                1|                0|                1|                0|               0|            1.0|              1.0|              1|[15914.0,55.0,0.0...|(24,[2,4,12,14,16...|[8.97782984262902...|[0.99987383954528...|       0.0|\n",
            "| 15922.0|61.0|      0.0|     246.0|    28.0|                  1.0|         225127.5|       0.0|              0.0|         0.0|                1.0|           0.0|         0|          1|    4|                0|                0|               1|                0|               0|                0|                0|                1|                0|                0|                0|                0|                0|                0|               0|                0|                0|                0|                0|                0|               1|            0.0|              0.0|              1|[15922.0,61.0,0.0...|(24,[2,7,20,23],[...|[8.97824624094532...|[0.99987389206072...|       0.0|\n",
            "| 15925.0|62.0|      0.0|     246.0|    28.0|                  1.0|         42831.69|       0.0|              0.0|         0.0|                1.0|           0.0|         0|          1|    3|                0|                0|               1|                0|               0|                0|                0|                1|                0|                0|                0|                0|                0|                0|               0|                0|                0|                0|                1|                0|               0|            0.0|              0.0|              0|[15925.0,62.0,0.0...|(24,[2,7,18],[1.0...|[8.97864601387819...|[0.99987394245883...|       0.0|\n",
            "+--------+----+---------+----------+--------+---------------------+-----------------+----------+-----------------+------------+-------------------+--------------+----------+-----------+-----+-----------------+-----------------+----------------+-----------------+----------------+-----------------+-----------------+-----------------+-----------------+-----------------+-----------------+-----------------+-----------------+-----------------+----------------+-----------------+-----------------+-----------------+-----------------+-----------------+----------------+---------------+-----------------+---------------+--------------------+--------------------+--------------------+--------------------+----------+\n",
            "only showing top 10 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kPOGasnFvzMK",
        "colab_type": "code",
        "outputId": "07c5fabd-ef0b-4dbe-a187-bef9bc263e04",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
        "evaluator = BinaryClassificationEvaluator(rawPredictionCol=\"rawPrediction\",labelCol='ind_ahor_fin_ult1')\n",
        "evaluator.evaluate(predictions)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8861058773121893"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WiboWlMH2ExG",
        "colab_type": "code",
        "outputId": "caad2836-be6f-46a8-a15b-bd20c6c1a7d5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "from pyspark.ml.feature import BucketedRandomProjectionLSH\n",
        "from pyspark.ml.linalg import Vectors\n",
        "from pyspark.sql.functions import col\n",
        "dataA = [(0, Vectors.dense([1.0, 1.0]),),\n",
        "         (1, Vectors.dense([1.0, -1.0]),),\n",
        "         (2, Vectors.dense([-1.0, -1.0]),),\n",
        "         (3, Vectors.dense([-1.0, 1.0]),)]\n",
        "dfA = spark.createDataFrame(dataA, [\"id\", \"features\"])\n",
        "\n",
        "dataB = [(Vectors.dense([1.0, 0.0]), Vectors.dense([1.0, 0.0]),),\n",
        "         (Vectors.dense([1.0, 0.0]), Vectors.dense([-1.0, 0.0]),),\n",
        "         (Vectors.dense([1.0, 0.0]), Vectors.dense([0.0, 1.0]),),\n",
        "         (Vectors.dense([1.0, 0.0]), Vectors.dense([0.0, -1.0]),)]\n",
        "dfB = spark.createDataFrame(dataB, [\"id\", \"features\"])\n",
        "\n",
        "key = Vectors.dense([1.0, 0.0,2])\n",
        "\n",
        "brp = BucketedRandomProjectionLSH(inputCol=\"features\", outputCol=\"hashes\", bucketLength=2.0,\n",
        "                                  numHashTables=3)\n",
        "model = brp.fit(dfB)\n",
        "\n",
        "# Feature Transformation\n",
        "print(\"The hashed dataset where hashed values are stored in the column 'hashes':\")\n",
        "model.transform(dfA).show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The hashed dataset where hashed values are stored in the column 'hashes':\n",
            "+---+-----------+--------------------+\n",
            "| id|   features|              hashes|\n",
            "+---+-----------+--------------------+\n",
            "|  0|  [1.0,1.0]|[[-1.0], [0.0], [...|\n",
            "|  1| [1.0,-1.0]|[[-1.0], [0.0], [...|\n",
            "|  2|[-1.0,-1.0]|[[0.0], [-1.0], [...|\n",
            "|  3| [-1.0,1.0]|[[0.0], [-1.0], [...|\n",
            "+---+-----------+--------------------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jia8vJQiQtyO",
        "colab_type": "code",
        "outputId": "9fe00b23-152b-48cd-c8b9-f8dbc0092033",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "sc1.uiWebUrl"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<!DOCTYPE html><html>\n",
            "      <head>\n",
            "        <meta http-equiv=\"Content-type\" content=\"text/html; charset=utf-8\"/><link rel=\"stylesheet\" href=\"/static/bootstrap.min.css\" type=\"text/css\"/><link rel=\"stylesheet\" href=\"/static/vis.min.css\" type=\"text/css\"/><link rel=\"stylesheet\" href=\"/static/webui.css\" type=\"text/css\"/><link rel=\"stylesheet\" href=\"/static/timeline-view.css\" type=\"text/css\"/><script src=\"/static/sorttable.js\"></script><script src=\"/static/jquery-1.12.4.min.js\"></script><script src=\"/static/vis.min.js\"></script><script src=\"/static/bootstrap-tooltip.js\"></script><script src=\"/static/initialize-tooltips.js\"></script><script src=\"/static/table.js\"></script><script src=\"/static/additional-metrics.js\"></script><script src=\"/static/timeline-view.js\"></script><script src=\"/static/log-view.js\"></script><script src=\"/static/webui.js\"></script><script>setUIRoot('')</script>\n",
            "        \n",
            "        \n",
            "        <link rel=\"shortcut icon\" href=\"/static/spark-logo-77x50px-hd.png\"></link>\n",
            "        <title>test1 - Spark Jobs</title>\n",
            "      </head>\n",
            "      <body>\n",
            "        <div class=\"navbar navbar-static-top\">\n",
            "          <div class=\"navbar-inner\">\n",
            "            <div class=\"brand\">\n",
            "              <a href=\"/\" class=\"brand\">\n",
            "                <img src=\"/static/spark-logo-77x50px-hd.png\"/>\n",
            "                <span class=\"version\">2.4.3</span>\n",
            "              </a>\n",
            "            </div>\n",
            "            <p class=\"navbar-text pull-right\">\n",
            "              <strong title=\"test1\">test1</strong> application UI\n",
            "            </p>\n",
            "            <ul class=\"nav\"><li class=\"active\">\n",
            "        <a href=\"/jobs/\">Jobs</a>\n",
            "      </li><li class=\"\">\n",
            "        <a href=\"/stages/\">Stages</a>\n",
            "      </li><li class=\"\">\n",
            "        <a href=\"/storage/\">Storage</a>\n",
            "      </li><li class=\"\">\n",
            "        <a href=\"/environment/\">Environment</a>\n",
            "      </li><li class=\"\">\n",
            "        <a href=\"/executors/\">Executors</a>\n",
            "      </li></ul>\n",
            "          </div>\n",
            "        </div>\n",
            "        <div class=\"container-fluid\">\n",
            "          <div class=\"row-fluid\">\n",
            "            <div class=\"span12\">\n",
            "              <h3 style=\"vertical-align: bottom; display: inline-block;\">\n",
            "                Spark Jobs\n",
            "                <sup>\n",
            "      (<a data-toggle=\"tooltip\" data-placement=\"bottom\" title=\"A job is triggered by an action, like count() or saveAsTextFile(). Click on a job to see information about the stages of tasks inside it.\">?</a>)\n",
            "    </sup>\n",
            "              </h3>\n",
            "            </div>\n",
            "          </div>\n",
            "          <div>\n",
            "        <ul class=\"unstyled\">\n",
            "          <li>\n",
            "            <strong>User:</strong>\n",
            "            root\n",
            "          </li>\n",
            "          <li>\n",
            "            <strong>Total Uptime:</strong>\n",
            "            1.7 h\n",
            "          </li>\n",
            "          <li>\n",
            "            <strong>Scheduling Mode: </strong>\n",
            "            FIFO\n",
            "          </li>\n",
            "          \n",
            "          <li id=\"completed-summary\">\n",
            "                <a href=\"#completed\"><strong>Completed Jobs:</strong></a>\n",
            "                15\n",
            "              </li>\n",
            "          <li>\n",
            "                <a href=\"#failed\"><strong>Failed Jobs:</strong></a>\n",
            "                4\n",
            "              </li>\n",
            "        </ul>\n",
            "      </div><span class=\"expand-application-timeline\">\n",
            "      <span class=\"expand-application-timeline-arrow arrow-closed\"></span>\n",
            "      <a data-toggle=\"tooltip\" title=\"Shows when jobs started and ended and when executors joined or left. Drag to scroll.\n",
            "       Click Enable Zooming and use mouse wheel to zoom in/out.\" data-placement=\"right\">\n",
            "        Event Timeline\n",
            "      </a>\n",
            "    </span><div id=\"application-timeline\" class=\"collapsed\">\n",
            "      <div class=\"control-panel\">\n",
            "        <div id=\"application-timeline-zoom-lock\">\n",
            "          <input type=\"checkbox\"></input>\n",
            "          <span>Enable zooming</span>\n",
            "        </div>\n",
            "      </div>\n",
            "    </div><script type=\"text/javascript\">\n",
            "      drawApplicationTimeline(\n",
            "[\n",
            "  {\n",
            "    'id': 'executors',\n",
            "    'content': '<div>Executors</div><div class=\"legend-area\"><svg width=\"150px\" height=\"55px\">      <rect class=\"executor-added-legend\" x=\"5px\" y=\"5px\" width=\"20px\" height=\"15px\" rx=\"2px\" ry=\"2px\"></rect>      <text x=\"35px\" y=\"17px\">Added</text>      <rect class=\"executor-removed-legend\" x=\"5px\" y=\"30px\" width=\"20px\" height=\"15px\" rx=\"2px\" ry=\"2px\"></rect>      <text x=\"35px\" y=\"42px\">Removed</text>    </svg></div>',\n",
            "  },\n",
            "  {\n",
            "    'id': 'jobs',\n",
            "    'content': '<div>Jobs</div><div class=\"legend-area\"><svg width=\"150px\" height=\"85px\">      <rect class=\"succeeded-job-legend\" x=\"5px\" y=\"5px\" width=\"20px\" height=\"15px\" rx=\"2px\" ry=\"2px\"></rect>      <text x=\"35px\" y=\"17px\">Succeeded</text>      <rect class=\"failed-job-legend\" x=\"5px\" y=\"30px\" width=\"20px\" height=\"15px\" rx=\"2px\" ry=\"2px\"></rect>      <text x=\"35px\" y=\"42px\">Failed</text>      <rect class=\"running-job-legend\" x=\"5px\" y=\"55px\" width=\"20px\" height=\"15px\" rx=\"2px\" ry=\"2px\"></rect>      <text x=\"35px\" y=\"67px\">Running</text>    </svg></div>',\n",
            "  }\n",
            "]\n",
            "        ,[\n",
            "{\n",
            "  'className': 'job application-timeline-object succeeded',\n",
            "  'group': 'jobs',\n",
            "  'start': new Date(1565671994168),\n",
            "  'end': new Date(1565671994189),\n",
            "  'content': '<div class=\"application-timeline-content\"' +\n",
            "     'data-html=\"true\" data-placement=\"top\" data-toggle=\"tooltip\"' +\n",
            "     'data-title=\"runJob at PythonRDD.scala:153 (Job 15)<br>' +\n",
            "     'Status: SUCCEEDED<br>' +\n",
            "     'Submitted: 2019/08/13 04:53:14' +\n",
            "     '<br>Completed: 2019/08/13 04:53:14\">' +\n",
            "    'runJob at PythonRDD.scala:153 (Job 15)</div>'\n",
            "}\n",
            "         ,\n",
            "{\n",
            "  'className': 'job application-timeline-object succeeded',\n",
            "  'group': 'jobs',\n",
            "  'start': new Date(1565671821860),\n",
            "  'end': new Date(1565671821883),\n",
            "  'content': '<div class=\"application-timeline-content\"' +\n",
            "     'data-html=\"true\" data-placement=\"top\" data-toggle=\"tooltip\"' +\n",
            "     'data-title=\"runJob at PythonRDD.scala:153 (Job 13)<br>' +\n",
            "     'Status: SUCCEEDED<br>' +\n",
            "     'Submitted: 2019/08/13 04:50:21' +\n",
            "     '<br>Completed: 2019/08/13 04:50:21\">' +\n",
            "    'runJob at PythonRDD.scala:153 (Job 13)</div>'\n",
            "}\n",
            "         ,\n",
            "{\n",
            "  'className': 'job application-timeline-object succeeded',\n",
            "  'group': 'jobs',\n",
            "  'start': new Date(1565671818353),\n",
            "  'end': new Date(1565671818380),\n",
            "  'content': '<div class=\"application-timeline-content\"' +\n",
            "     'data-html=\"true\" data-placement=\"top\" data-toggle=\"tooltip\"' +\n",
            "     'data-title=\"runJob at PythonRDD.scala:153 (Job 12)<br>' +\n",
            "     'Status: SUCCEEDED<br>' +\n",
            "     'Submitted: 2019/08/13 04:50:18' +\n",
            "     '<br>Completed: 2019/08/13 04:50:18\">' +\n",
            "    'runJob at PythonRDD.scala:153 (Job 12)</div>'\n",
            "}\n",
            "         ,\n",
            "{\n",
            "  'className': 'job application-timeline-object succeeded',\n",
            "  'group': 'jobs',\n",
            "  'start': new Date(1565671816386),\n",
            "  'end': new Date(1565671816410),\n",
            "  'content': '<div class=\"application-timeline-content\"' +\n",
            "     'data-html=\"true\" data-placement=\"top\" data-toggle=\"tooltip\"' +\n",
            "     'data-title=\"runJob at PythonRDD.scala:153 (Job 11)<br>' +\n",
            "     'Status: SUCCEEDED<br>' +\n",
            "     'Submitted: 2019/08/13 04:50:16' +\n",
            "     '<br>Completed: 2019/08/13 04:50:16\">' +\n",
            "    'runJob at PythonRDD.scala:153 (Job 11)</div>'\n",
            "}\n",
            "         ,\n",
            "{\n",
            "  'className': 'job application-timeline-object succeeded',\n",
            "  'group': 'jobs',\n",
            "  'start': new Date(1565671814226),\n",
            "  'end': new Date(1565671814253),\n",
            "  'content': '<div class=\"application-timeline-content\"' +\n",
            "     'data-html=\"true\" data-placement=\"top\" data-toggle=\"tooltip\"' +\n",
            "     'data-title=\"runJob at PythonRDD.scala:153 (Job 10)<br>' +\n",
            "     'Status: SUCCEEDED<br>' +\n",
            "     'Submitted: 2019/08/13 04:50:14' +\n",
            "     '<br>Completed: 2019/08/13 04:50:14\">' +\n",
            "    'runJob at PythonRDD.scala:153 (Job 10)</div>'\n",
            "}\n",
            "         ,\n",
            "{\n",
            "  'className': 'job application-timeline-object succeeded',\n",
            "  'group': 'jobs',\n",
            "  'start': new Date(1565671812039),\n",
            "  'end': new Date(1565671812072),\n",
            "  'content': '<div class=\"application-timeline-content\"' +\n",
            "     'data-html=\"true\" data-placement=\"top\" data-toggle=\"tooltip\"' +\n",
            "     'data-title=\"runJob at PythonRDD.scala:153 (Job 9)<br>' +\n",
            "     'Status: SUCCEEDED<br>' +\n",
            "     'Submitted: 2019/08/13 04:50:12' +\n",
            "     '<br>Completed: 2019/08/13 04:50:12\">' +\n",
            "    'runJob at PythonRDD.scala:153 (Job 9)</div>'\n",
            "}\n",
            "         ,\n",
            "{\n",
            "  'className': 'job application-timeline-object succeeded',\n",
            "  'group': 'jobs',\n",
            "  'start': new Date(1565671809510),\n",
            "  'end': new Date(1565671809541),\n",
            "  'content': '<div class=\"application-timeline-content\"' +\n",
            "     'data-html=\"true\" data-placement=\"top\" data-toggle=\"tooltip\"' +\n",
            "     'data-title=\"runJob at PythonRDD.scala:153 (Job 8)<br>' +\n",
            "     'Status: SUCCEEDED<br>' +\n",
            "     'Submitted: 2019/08/13 04:50:09' +\n",
            "     '<br>Completed: 2019/08/13 04:50:09\">' +\n",
            "    'runJob at PythonRDD.scala:153 (Job 8)</div>'\n",
            "}\n",
            "         ,\n",
            "{\n",
            "  'className': 'job application-timeline-object succeeded',\n",
            "  'group': 'jobs',\n",
            "  'start': new Date(1565671807278),\n",
            "  'end': new Date(1565671807305),\n",
            "  'content': '<div class=\"application-timeline-content\"' +\n",
            "     'data-html=\"true\" data-placement=\"top\" data-toggle=\"tooltip\"' +\n",
            "     'data-title=\"runJob at PythonRDD.scala:153 (Job 7)<br>' +\n",
            "     'Status: SUCCEEDED<br>' +\n",
            "     'Submitted: 2019/08/13 04:50:07' +\n",
            "     '<br>Completed: 2019/08/13 04:50:07\">' +\n",
            "    'runJob at PythonRDD.scala:153 (Job 7)</div>'\n",
            "}\n",
            "         ,\n",
            "{\n",
            "  'className': 'job application-timeline-object succeeded',\n",
            "  'group': 'jobs',\n",
            "  'start': new Date(1565671803916),\n",
            "  'end': new Date(1565671803944),\n",
            "  'content': '<div class=\"application-timeline-content\"' +\n",
            "     'data-html=\"true\" data-placement=\"top\" data-toggle=\"tooltip\"' +\n",
            "     'data-title=\"runJob at PythonRDD.scala:153 (Job 6)<br>' +\n",
            "     'Status: SUCCEEDED<br>' +\n",
            "     'Submitted: 2019/08/13 04:50:03' +\n",
            "     '<br>Completed: 2019/08/13 04:50:03\">' +\n",
            "    'runJob at PythonRDD.scala:153 (Job 6)</div>'\n",
            "}\n",
            "         ,\n",
            "{\n",
            "  'className': 'job application-timeline-object succeeded',\n",
            "  'group': 'jobs',\n",
            "  'start': new Date(1565671797235),\n",
            "  'end': new Date(1565671797265),\n",
            "  'content': '<div class=\"application-timeline-content\"' +\n",
            "     'data-html=\"true\" data-placement=\"top\" data-toggle=\"tooltip\"' +\n",
            "     'data-title=\"runJob at PythonRDD.scala:153 (Job 5)<br>' +\n",
            "     'Status: SUCCEEDED<br>' +\n",
            "     'Submitted: 2019/08/13 04:49:57' +\n",
            "     '<br>Completed: 2019/08/13 04:49:57\">' +\n",
            "    'runJob at PythonRDD.scala:153 (Job 5)</div>'\n",
            "}\n",
            "         ,\n",
            "{\n",
            "  'className': 'job application-timeline-object succeeded',\n",
            "  'group': 'jobs',\n",
            "  'start': new Date(1565671616455),\n",
            "  'end': new Date(1565671616476),\n",
            "  'content': '<div class=\"application-timeline-content\"' +\n",
            "     'data-html=\"true\" data-placement=\"top\" data-toggle=\"tooltip\"' +\n",
            "     'data-title=\"runJob at PythonRDD.scala:153 (Job 4)<br>' +\n",
            "     'Status: SUCCEEDED<br>' +\n",
            "     'Submitted: 2019/08/13 04:46:56' +\n",
            "     '<br>Completed: 2019/08/13 04:46:56\">' +\n",
            "    'runJob at PythonRDD.scala:153 (Job 4)</div>'\n",
            "}\n",
            "         ,\n",
            "{\n",
            "  'className': 'job application-timeline-object succeeded',\n",
            "  'group': 'jobs',\n",
            "  'start': new Date(1565671614475),\n",
            "  'end': new Date(1565671614504),\n",
            "  'content': '<div class=\"application-timeline-content\"' +\n",
            "     'data-html=\"true\" data-placement=\"top\" data-toggle=\"tooltip\"' +\n",
            "     'data-title=\"runJob at PythonRDD.scala:153 (Job 3)<br>' +\n",
            "     'Status: SUCCEEDED<br>' +\n",
            "     'Submitted: 2019/08/13 04:46:54' +\n",
            "     '<br>Completed: 2019/08/13 04:46:54\">' +\n",
            "    'runJob at PythonRDD.scala:153 (Job 3)</div>'\n",
            "}\n",
            "         ,\n",
            "{\n",
            "  'className': 'job application-timeline-object succeeded',\n",
            "  'group': 'jobs',\n",
            "  'start': new Date(1565671331731),\n",
            "  'end': new Date(1565671400514),\n",
            "  'content': '<div class=\"application-timeline-content\"' +\n",
            "     'data-html=\"true\" data-placement=\"top\" data-toggle=\"tooltip\"' +\n",
            "     'data-title=\"runJob at SparkHadoopWriter.scala:78 (Job 2)<br>' +\n",
            "     'Status: SUCCEEDED<br>' +\n",
            "     'Submitted: 2019/08/13 04:42:11' +\n",
            "     '<br>Completed: 2019/08/13 04:43:20\">' +\n",
            "    'runJob at SparkHadoopWriter.scala:78 (Job 2)</div>'\n",
            "}\n",
            "         ,\n",
            "{\n",
            "  'className': 'job application-timeline-object succeeded',\n",
            "  'group': 'jobs',\n",
            "  'start': new Date(1565671161396),\n",
            "  'end': new Date(1565671161462),\n",
            "  'content': '<div class=\"application-timeline-content\"' +\n",
            "     'data-html=\"true\" data-placement=\"top\" data-toggle=\"tooltip\"' +\n",
            "     'data-title=\"runJob at PythonRDD.scala:153 (Job 1)<br>' +\n",
            "     'Status: SUCCEEDED<br>' +\n",
            "     'Submitted: 2019/08/13 04:39:21' +\n",
            "     '<br>Completed: 2019/08/13 04:39:21\">' +\n",
            "    'runJob at PythonRDD.scala:153 (Job 1)</div>'\n",
            "}\n",
            "         ,\n",
            "{\n",
            "  'className': 'job application-timeline-object succeeded',\n",
            "  'group': 'jobs',\n",
            "  'start': new Date(1565671116294),\n",
            "  'end': new Date(1565671117103),\n",
            "  'content': '<div class=\"application-timeline-content\"' +\n",
            "     'data-html=\"true\" data-placement=\"top\" data-toggle=\"tooltip\"' +\n",
            "     'data-title=\"runJob at PythonRDD.scala:153 (Job 0)<br>' +\n",
            "     'Status: SUCCEEDED<br>' +\n",
            "     'Submitted: 2019/08/13 04:38:36' +\n",
            "     '<br>Completed: 2019/08/13 04:38:37\">' +\n",
            "    'runJob at PythonRDD.scala:153 (Job 0)</div>'\n",
            "}\n",
            "         ,\n",
            "{\n",
            "  'className': 'job application-timeline-object failed',\n",
            "  'group': 'jobs',\n",
            "  'start': new Date(1565672032508),\n",
            "  'end': new Date(1565672032571),\n",
            "  'content': '<div class=\"application-timeline-content\"' +\n",
            "     'data-html=\"true\" data-placement=\"top\" data-toggle=\"tooltip\"' +\n",
            "     'data-title=\"runJob at PythonRDD.scala:153 (Job 18)<br>' +\n",
            "     'Status: FAILED<br>' +\n",
            "     'Submitted: 2019/08/13 04:53:52' +\n",
            "     '<br>Completed: 2019/08/13 04:53:52\">' +\n",
            "    'runJob at PythonRDD.scala:153 (Job 18)</div>'\n",
            "}\n",
            "         ,\n",
            "{\n",
            "  'className': 'job application-timeline-object failed',\n",
            "  'group': 'jobs',\n",
            "  'start': new Date(1565672028235),\n",
            "  'end': new Date(1565672028290),\n",
            "  'content': '<div class=\"application-timeline-content\"' +\n",
            "     'data-html=\"true\" data-placement=\"top\" data-toggle=\"tooltip\"' +\n",
            "     'data-title=\"runJob at PythonRDD.scala:153 (Job 17)<br>' +\n",
            "     'Status: FAILED<br>' +\n",
            "     'Submitted: 2019/08/13 04:53:48' +\n",
            "     '<br>Completed: 2019/08/13 04:53:48\">' +\n",
            "    'runJob at PythonRDD.scala:153 (Job 17)</div>'\n",
            "}\n",
            "         ,\n",
            "{\n",
            "  'className': 'job application-timeline-object failed',\n",
            "  'group': 'jobs',\n",
            "  'start': new Date(1565672002659),\n",
            "  'end': new Date(1565672002706),\n",
            "  'content': '<div class=\"application-timeline-content\"' +\n",
            "     'data-html=\"true\" data-placement=\"top\" data-toggle=\"tooltip\"' +\n",
            "     'data-title=\"runJob at PythonRDD.scala:153 (Job 16)<br>' +\n",
            "     'Status: FAILED<br>' +\n",
            "     'Submitted: 2019/08/13 04:53:22' +\n",
            "     '<br>Completed: 2019/08/13 04:53:22\">' +\n",
            "    'runJob at PythonRDD.scala:153 (Job 16)</div>'\n",
            "}\n",
            "         ,\n",
            "{\n",
            "  'className': 'job application-timeline-object failed',\n",
            "  'group': 'jobs',\n",
            "  'start': new Date(1565671965930),\n",
            "  'end': new Date(1565671966014),\n",
            "  'content': '<div class=\"application-timeline-content\"' +\n",
            "     'data-html=\"true\" data-placement=\"top\" data-toggle=\"tooltip\"' +\n",
            "     'data-title=\"runJob at PythonRDD.scala:153 (Job 14)<br>' +\n",
            "     'Status: FAILED<br>' +\n",
            "     'Submitted: 2019/08/13 04:52:45' +\n",
            "     '<br>Completed: 2019/08/13 04:52:46\">' +\n",
            "    'runJob at PythonRDD.scala:153 (Job 14)</div>'\n",
            "}\n",
            "         ,\n",
            "{\n",
            "  'className': 'executor added',\n",
            "  'group': 'executors',\n",
            "  'start': new Date(1565670948520),\n",
            "  'content': '<div class=\"executor-event-content\"' +\n",
            "    'data-toggle=\"tooltip\" data-placement=\"bottom\"' +\n",
            "    'data-title=\"Executor driver<br>' +\n",
            "    'Added at 2019/08/13 04:35:48\"' +\n",
            "    'data-html=\"true\">Executor driver added</div>'\n",
            "}\n",
            "         ], 1565670947354, 0);\n",
            "    </script><span id=\"completed\" class=\"collapse-aggregated-completedJobs collapse-table\" onClick=\"collapseTable('collapse-aggregated-completedJobs','aggregated-completedJobs')\">\n",
            "          <h4>\n",
            "            <span class=\"collapse-table-arrow arrow-open\"></span>\n",
            "            <a>Completed Jobs (15)</a>\n",
            "          </h4>\n",
            "        </span><div class=\"aggregated-completedJobs collapsible-table\">\n",
            "          <div>\n",
            "        \n",
            "        <table class=\"table table-bordered table-condensed table-striped table-head-clickable table-cell-width-limited\" id=\"completedJob-table\">\n",
            "          <thead><th class=\"\">\n",
            "            <a href=\"/jobs/?&completedJob.sort=Job+Id&completedJob.desc=false&completedJob.pageSize=100#completed\">\n",
            "              Job Id<span>\n",
            "              &nbsp;&#x25BE;\n",
            "            </span>\n",
            "            </a>\n",
            "          </th><th class=\"\">\n",
            "              <a href=\"/jobs/?&completedJob.sort=Description&completedJob.pageSize=100#completed\">\n",
            "                Description\n",
            "              </a>\n",
            "            </th><th class=\"\">\n",
            "              <a href=\"/jobs/?&completedJob.sort=Submitted&completedJob.pageSize=100#completed\">\n",
            "                Submitted\n",
            "              </a>\n",
            "            </th><th class=\"\">\n",
            "              <a href=\"/jobs/?&completedJob.sort=Duration&completedJob.pageSize=100#completed\">\n",
            "                Duration\n",
            "              </a>\n",
            "            </th><th class=\"\">\n",
            "              Stages: Succeeded/Total\n",
            "            </th><th class=\"\">\n",
            "              Tasks (for all stages): Succeeded/Total\n",
            "            </th></thead>\n",
            "          <tbody>\n",
            "            <tr id=\"job-15\">\n",
            "      <td>\n",
            "        15 \n",
            "      </td>\n",
            "      <td>\n",
            "        <span class=\"description-input\">runJob at PythonRDD.scala:153</span> \n",
            "        <a href=\"/jobs/job/?id=15\" class=\"name-link\">runJob at PythonRDD.scala:153</a>\n",
            "      </td>\n",
            "      <td>\n",
            "        2019/08/13 04:53:14\n",
            "      </td>\n",
            "      <td>21 ms</td>\n",
            "      <td class=\"stage-progress-cell\">\n",
            "        1/1\n",
            "        \n",
            "        \n",
            "      </td>\n",
            "      <td class=\"progress-cell\">\n",
            "        <div class=\"progress\">\n",
            "      <span style=\"text-align:center; position:absolute; width:100%; left:0;\">\n",
            "        1/1\n",
            "        \n",
            "        \n",
            "        \n",
            "        \n",
            "      </span>\n",
            "      <div class=\"bar bar-completed\" style=\"width: 100.0%\"></div>\n",
            "      <div class=\"bar bar-running\" style=\"width: 0.0%\"></div>\n",
            "    </div>\n",
            "      </td>\n",
            "    </tr><tr id=\"job-13\">\n",
            "      <td>\n",
            "        13 \n",
            "      </td>\n",
            "      <td>\n",
            "        <span class=\"description-input\">runJob at PythonRDD.scala:153</span> \n",
            "        <a href=\"/jobs/job/?id=13\" class=\"name-link\">runJob at PythonRDD.scala:153</a>\n",
            "      </td>\n",
            "      <td>\n",
            "        2019/08/13 04:50:21\n",
            "      </td>\n",
            "      <td>23 ms</td>\n",
            "      <td class=\"stage-progress-cell\">\n",
            "        1/1\n",
            "        \n",
            "        \n",
            "      </td>\n",
            "      <td class=\"progress-cell\">\n",
            "        <div class=\"progress\">\n",
            "      <span style=\"text-align:center; position:absolute; width:100%; left:0;\">\n",
            "        1/1\n",
            "        \n",
            "        \n",
            "        \n",
            "        \n",
            "      </span>\n",
            "      <div class=\"bar bar-completed\" style=\"width: 100.0%\"></div>\n",
            "      <div class=\"bar bar-running\" style=\"width: 0.0%\"></div>\n",
            "    </div>\n",
            "      </td>\n",
            "    </tr><tr id=\"job-12\">\n",
            "      <td>\n",
            "        12 \n",
            "      </td>\n",
            "      <td>\n",
            "        <span class=\"description-input\">runJob at PythonRDD.scala:153</span> \n",
            "        <a href=\"/jobs/job/?id=12\" class=\"name-link\">runJob at PythonRDD.scala:153</a>\n",
            "      </td>\n",
            "      <td>\n",
            "        2019/08/13 04:50:18\n",
            "      </td>\n",
            "      <td>27 ms</td>\n",
            "      <td class=\"stage-progress-cell\">\n",
            "        1/1\n",
            "        \n",
            "        \n",
            "      </td>\n",
            "      <td class=\"progress-cell\">\n",
            "        <div class=\"progress\">\n",
            "      <span style=\"text-align:center; position:absolute; width:100%; left:0;\">\n",
            "        1/1\n",
            "        \n",
            "        \n",
            "        \n",
            "        \n",
            "      </span>\n",
            "      <div class=\"bar bar-completed\" style=\"width: 100.0%\"></div>\n",
            "      <div class=\"bar bar-running\" style=\"width: 0.0%\"></div>\n",
            "    </div>\n",
            "      </td>\n",
            "    </tr><tr id=\"job-11\">\n",
            "      <td>\n",
            "        11 \n",
            "      </td>\n",
            "      <td>\n",
            "        <span class=\"description-input\">runJob at PythonRDD.scala:153</span> \n",
            "        <a href=\"/jobs/job/?id=11\" class=\"name-link\">runJob at PythonRDD.scala:153</a>\n",
            "      </td>\n",
            "      <td>\n",
            "        2019/08/13 04:50:16\n",
            "      </td>\n",
            "      <td>24 ms</td>\n",
            "      <td class=\"stage-progress-cell\">\n",
            "        1/1\n",
            "        \n",
            "        \n",
            "      </td>\n",
            "      <td class=\"progress-cell\">\n",
            "        <div class=\"progress\">\n",
            "      <span style=\"text-align:center; position:absolute; width:100%; left:0;\">\n",
            "        1/1\n",
            "        \n",
            "        \n",
            "        \n",
            "        \n",
            "      </span>\n",
            "      <div class=\"bar bar-completed\" style=\"width: 100.0%\"></div>\n",
            "      <div class=\"bar bar-running\" style=\"width: 0.0%\"></div>\n",
            "    </div>\n",
            "      </td>\n",
            "    </tr><tr id=\"job-10\">\n",
            "      <td>\n",
            "        10 \n",
            "      </td>\n",
            "      <td>\n",
            "        <span class=\"description-input\">runJob at PythonRDD.scala:153</span> \n",
            "        <a href=\"/jobs/job/?id=10\" class=\"name-link\">runJob at PythonRDD.scala:153</a>\n",
            "      </td>\n",
            "      <td>\n",
            "        2019/08/13 04:50:14\n",
            "      </td>\n",
            "      <td>27 ms</td>\n",
            "      <td class=\"stage-progress-cell\">\n",
            "        1/1\n",
            "        \n",
            "        \n",
            "      </td>\n",
            "      <td class=\"progress-cell\">\n",
            "        <div class=\"progress\">\n",
            "      <span style=\"text-align:center; position:absolute; width:100%; left:0;\">\n",
            "        1/1\n",
            "        \n",
            "        \n",
            "        \n",
            "        \n",
            "      </span>\n",
            "      <div class=\"bar bar-completed\" style=\"width: 100.0%\"></div>\n",
            "      <div class=\"bar bar-running\" style=\"width: 0.0%\"></div>\n",
            "    </div>\n",
            "      </td>\n",
            "    </tr><tr id=\"job-9\">\n",
            "      <td>\n",
            "        9 \n",
            "      </td>\n",
            "      <td>\n",
            "        <span class=\"description-input\">runJob at PythonRDD.scala:153</span> \n",
            "        <a href=\"/jobs/job/?id=9\" class=\"name-link\">runJob at PythonRDD.scala:153</a>\n",
            "      </td>\n",
            "      <td>\n",
            "        2019/08/13 04:50:12\n",
            "      </td>\n",
            "      <td>33 ms</td>\n",
            "      <td class=\"stage-progress-cell\">\n",
            "        1/1\n",
            "        \n",
            "        \n",
            "      </td>\n",
            "      <td class=\"progress-cell\">\n",
            "        <div class=\"progress\">\n",
            "      <span style=\"text-align:center; position:absolute; width:100%; left:0;\">\n",
            "        1/1\n",
            "        \n",
            "        \n",
            "        \n",
            "        \n",
            "      </span>\n",
            "      <div class=\"bar bar-completed\" style=\"width: 100.0%\"></div>\n",
            "      <div class=\"bar bar-running\" style=\"width: 0.0%\"></div>\n",
            "    </div>\n",
            "      </td>\n",
            "    </tr><tr id=\"job-8\">\n",
            "      <td>\n",
            "        8 \n",
            "      </td>\n",
            "      <td>\n",
            "        <span class=\"description-input\">runJob at PythonRDD.scala:153</span> \n",
            "        <a href=\"/jobs/job/?id=8\" class=\"name-link\">runJob at PythonRDD.scala:153</a>\n",
            "      </td>\n",
            "      <td>\n",
            "        2019/08/13 04:50:09\n",
            "      </td>\n",
            "      <td>31 ms</td>\n",
            "      <td class=\"stage-progress-cell\">\n",
            "        1/1\n",
            "        \n",
            "        \n",
            "      </td>\n",
            "      <td class=\"progress-cell\">\n",
            "        <div class=\"progress\">\n",
            "      <span style=\"text-align:center; position:absolute; width:100%; left:0;\">\n",
            "        1/1\n",
            "        \n",
            "        \n",
            "        \n",
            "        \n",
            "      </span>\n",
            "      <div class=\"bar bar-completed\" style=\"width: 100.0%\"></div>\n",
            "      <div class=\"bar bar-running\" style=\"width: 0.0%\"></div>\n",
            "    </div>\n",
            "      </td>\n",
            "    </tr><tr id=\"job-7\">\n",
            "      <td>\n",
            "        7 \n",
            "      </td>\n",
            "      <td>\n",
            "        <span class=\"description-input\">runJob at PythonRDD.scala:153</span> \n",
            "        <a href=\"/jobs/job/?id=7\" class=\"name-link\">runJob at PythonRDD.scala:153</a>\n",
            "      </td>\n",
            "      <td>\n",
            "        2019/08/13 04:50:07\n",
            "      </td>\n",
            "      <td>27 ms</td>\n",
            "      <td class=\"stage-progress-cell\">\n",
            "        1/1\n",
            "        \n",
            "        \n",
            "      </td>\n",
            "      <td class=\"progress-cell\">\n",
            "        <div class=\"progress\">\n",
            "      <span style=\"text-align:center; position:absolute; width:100%; left:0;\">\n",
            "        1/1\n",
            "        \n",
            "        \n",
            "        \n",
            "        \n",
            "      </span>\n",
            "      <div class=\"bar bar-completed\" style=\"width: 100.0%\"></div>\n",
            "      <div class=\"bar bar-running\" style=\"width: 0.0%\"></div>\n",
            "    </div>\n",
            "      </td>\n",
            "    </tr><tr id=\"job-6\">\n",
            "      <td>\n",
            "        6 \n",
            "      </td>\n",
            "      <td>\n",
            "        <span class=\"description-input\">runJob at PythonRDD.scala:153</span> \n",
            "        <a href=\"/jobs/job/?id=6\" class=\"name-link\">runJob at PythonRDD.scala:153</a>\n",
            "      </td>\n",
            "      <td>\n",
            "        2019/08/13 04:50:03\n",
            "      </td>\n",
            "      <td>28 ms</td>\n",
            "      <td class=\"stage-progress-cell\">\n",
            "        1/1\n",
            "        \n",
            "        \n",
            "      </td>\n",
            "      <td class=\"progress-cell\">\n",
            "        <div class=\"progress\">\n",
            "      <span style=\"text-align:center; position:absolute; width:100%; left:0;\">\n",
            "        1/1\n",
            "        \n",
            "        \n",
            "        \n",
            "        \n",
            "      </span>\n",
            "      <div class=\"bar bar-completed\" style=\"width: 100.0%\"></div>\n",
            "      <div class=\"bar bar-running\" style=\"width: 0.0%\"></div>\n",
            "    </div>\n",
            "      </td>\n",
            "    </tr><tr id=\"job-5\">\n",
            "      <td>\n",
            "        5 \n",
            "      </td>\n",
            "      <td>\n",
            "        <span class=\"description-input\">runJob at PythonRDD.scala:153</span> \n",
            "        <a href=\"/jobs/job/?id=5\" class=\"name-link\">runJob at PythonRDD.scala:153</a>\n",
            "      </td>\n",
            "      <td>\n",
            "        2019/08/13 04:49:57\n",
            "      </td>\n",
            "      <td>30 ms</td>\n",
            "      <td class=\"stage-progress-cell\">\n",
            "        1/1\n",
            "        \n",
            "        \n",
            "      </td>\n",
            "      <td class=\"progress-cell\">\n",
            "        <div class=\"progress\">\n",
            "      <span style=\"text-align:center; position:absolute; width:100%; left:0;\">\n",
            "        1/1\n",
            "        \n",
            "        \n",
            "        \n",
            "        \n",
            "      </span>\n",
            "      <div class=\"bar bar-completed\" style=\"width: 100.0%\"></div>\n",
            "      <div class=\"bar bar-running\" style=\"width: 0.0%\"></div>\n",
            "    </div>\n",
            "      </td>\n",
            "    </tr><tr id=\"job-4\">\n",
            "      <td>\n",
            "        4 \n",
            "      </td>\n",
            "      <td>\n",
            "        <span class=\"description-input\">runJob at PythonRDD.scala:153</span> \n",
            "        <a href=\"/jobs/job/?id=4\" class=\"name-link\">runJob at PythonRDD.scala:153</a>\n",
            "      </td>\n",
            "      <td>\n",
            "        2019/08/13 04:46:56\n",
            "      </td>\n",
            "      <td>21 ms</td>\n",
            "      <td class=\"stage-progress-cell\">\n",
            "        1/1\n",
            "        \n",
            "        \n",
            "      </td>\n",
            "      <td class=\"progress-cell\">\n",
            "        <div class=\"progress\">\n",
            "      <span style=\"text-align:center; position:absolute; width:100%; left:0;\">\n",
            "        1/1\n",
            "        \n",
            "        \n",
            "        \n",
            "        \n",
            "      </span>\n",
            "      <div class=\"bar bar-completed\" style=\"width: 100.0%\"></div>\n",
            "      <div class=\"bar bar-running\" style=\"width: 0.0%\"></div>\n",
            "    </div>\n",
            "      </td>\n",
            "    </tr><tr id=\"job-3\">\n",
            "      <td>\n",
            "        3 \n",
            "      </td>\n",
            "      <td>\n",
            "        <span class=\"description-input\">runJob at PythonRDD.scala:153</span> \n",
            "        <a href=\"/jobs/job/?id=3\" class=\"name-link\">runJob at PythonRDD.scala:153</a>\n",
            "      </td>\n",
            "      <td>\n",
            "        2019/08/13 04:46:54\n",
            "      </td>\n",
            "      <td>29 ms</td>\n",
            "      <td class=\"stage-progress-cell\">\n",
            "        1/1\n",
            "        \n",
            "        \n",
            "      </td>\n",
            "      <td class=\"progress-cell\">\n",
            "        <div class=\"progress\">\n",
            "      <span style=\"text-align:center; position:absolute; width:100%; left:0;\">\n",
            "        1/1\n",
            "        \n",
            "        \n",
            "        \n",
            "        \n",
            "      </span>\n",
            "      <div class=\"bar bar-completed\" style=\"width: 100.0%\"></div>\n",
            "      <div class=\"bar bar-running\" style=\"width: 0.0%\"></div>\n",
            "    </div>\n",
            "      </td>\n",
            "    </tr><tr id=\"job-2\">\n",
            "      <td>\n",
            "        2 \n",
            "      </td>\n",
            "      <td>\n",
            "        <span class=\"description-input\">runJob at SparkHadoopWriter.scala:78</span> \n",
            "        <a href=\"/jobs/job/?id=2\" class=\"name-link\">runJob at SparkHadoopWriter.scala:78</a>\n",
            "      </td>\n",
            "      <td>\n",
            "        2019/08/13 04:42:11\n",
            "      </td>\n",
            "      <td>1.1 min</td>\n",
            "      <td class=\"stage-progress-cell\">\n",
            "        1/1\n",
            "        \n",
            "        \n",
            "      </td>\n",
            "      <td class=\"progress-cell\">\n",
            "        <div class=\"progress\">\n",
            "      <span style=\"text-align:center; position:absolute; width:100%; left:0;\">\n",
            "        69/69\n",
            "        \n",
            "        \n",
            "        \n",
            "        \n",
            "      </span>\n",
            "      <div class=\"bar bar-completed\" style=\"width: 100.0%\"></div>\n",
            "      <div class=\"bar bar-running\" style=\"width: 0.0%\"></div>\n",
            "    </div>\n",
            "      </td>\n",
            "    </tr><tr id=\"job-1\">\n",
            "      <td>\n",
            "        1 \n",
            "      </td>\n",
            "      <td>\n",
            "        <span class=\"description-input\">runJob at PythonRDD.scala:153</span> \n",
            "        <a href=\"/jobs/job/?id=1\" class=\"name-link\">runJob at PythonRDD.scala:153</a>\n",
            "      </td>\n",
            "      <td>\n",
            "        2019/08/13 04:39:21\n",
            "      </td>\n",
            "      <td>66 ms</td>\n",
            "      <td class=\"stage-progress-cell\">\n",
            "        1/1\n",
            "        \n",
            "        \n",
            "      </td>\n",
            "      <td class=\"progress-cell\">\n",
            "        <div class=\"progress\">\n",
            "      <span style=\"text-align:center; position:absolute; width:100%; left:0;\">\n",
            "        1/1\n",
            "        \n",
            "        \n",
            "        \n",
            "        \n",
            "      </span>\n",
            "      <div class=\"bar bar-completed\" style=\"width: 100.0%\"></div>\n",
            "      <div class=\"bar bar-running\" style=\"width: 0.0%\"></div>\n",
            "    </div>\n",
            "      </td>\n",
            "    </tr><tr id=\"job-0\">\n",
            "      <td>\n",
            "        0 \n",
            "      </td>\n",
            "      <td>\n",
            "        <span class=\"description-input\">runJob at PythonRDD.scala:153</span> \n",
            "        <a href=\"/jobs/job/?id=0\" class=\"name-link\">runJob at PythonRDD.scala:153</a>\n",
            "      </td>\n",
            "      <td>\n",
            "        2019/08/13 04:38:36\n",
            "      </td>\n",
            "      <td>0.8 s</td>\n",
            "      <td class=\"stage-progress-cell\">\n",
            "        1/1\n",
            "        \n",
            "        \n",
            "      </td>\n",
            "      <td class=\"progress-cell\">\n",
            "        <div class=\"progress\">\n",
            "      <span style=\"text-align:center; position:absolute; width:100%; left:0;\">\n",
            "        1/1\n",
            "        \n",
            "        \n",
            "        \n",
            "        \n",
            "      </span>\n",
            "      <div class=\"bar bar-completed\" style=\"width: 100.0%\"></div>\n",
            "      <div class=\"bar bar-running\" style=\"width: 0.0%\"></div>\n",
            "    </div>\n",
            "      </td>\n",
            "    </tr>\n",
            "          </tbody>\n",
            "        </table>\n",
            "        \n",
            "      </div>\n",
            "        </div><span id=\"failed\" class=\"collapse-aggregated-failedJobs collapse-table\" onClick=\"collapseTable('collapse-aggregated-failedJobs','aggregated-failedJobs')\">\n",
            "          <h4>\n",
            "            <span class=\"collapse-table-arrow arrow-open\"></span>\n",
            "            <a>Failed Jobs (4)</a>\n",
            "          </h4>\n",
            "        </span><div class=\"aggregated-failedJobs collapsible-table\">\n",
            "        <div>\n",
            "        \n",
            "        <table class=\"table table-bordered table-condensed table-striped table-head-clickable table-cell-width-limited\" id=\"failedJob-table\">\n",
            "          <thead><th class=\"\">\n",
            "            <a href=\"/jobs/?&failedJob.sort=Job+Id&failedJob.desc=false&failedJob.pageSize=100#failed\">\n",
            "              Job Id<span>\n",
            "              &nbsp;&#x25BE;\n",
            "            </span>\n",
            "            </a>\n",
            "          </th><th class=\"\">\n",
            "              <a href=\"/jobs/?&failedJob.sort=Description&failedJob.pageSize=100#failed\">\n",
            "                Description\n",
            "              </a>\n",
            "            </th><th class=\"\">\n",
            "              <a href=\"/jobs/?&failedJob.sort=Submitted&failedJob.pageSize=100#failed\">\n",
            "                Submitted\n",
            "              </a>\n",
            "            </th><th class=\"\">\n",
            "              <a href=\"/jobs/?&failedJob.sort=Duration&failedJob.pageSize=100#failed\">\n",
            "                Duration\n",
            "              </a>\n",
            "            </th><th class=\"\">\n",
            "              Stages: Succeeded/Total\n",
            "            </th><th class=\"\">\n",
            "              Tasks (for all stages): Succeeded/Total\n",
            "            </th></thead>\n",
            "          <tbody>\n",
            "            <tr id=\"job-18\">\n",
            "      <td>\n",
            "        18 \n",
            "      </td>\n",
            "      <td>\n",
            "        <span class=\"description-input\">runJob at PythonRDD.scala:153</span> \n",
            "        <a href=\"/jobs/job/?id=18\" class=\"name-link\">runJob at PythonRDD.scala:153</a>\n",
            "      </td>\n",
            "      <td>\n",
            "        2019/08/13 04:53:52\n",
            "      </td>\n",
            "      <td>63 ms</td>\n",
            "      <td class=\"stage-progress-cell\">\n",
            "        0/1\n",
            "        (1 failed)\n",
            "        \n",
            "      </td>\n",
            "      <td class=\"progress-cell\">\n",
            "        <div class=\"progress\">\n",
            "      <span style=\"text-align:center; position:absolute; width:100%; left:0;\">\n",
            "        0/1\n",
            "        \n",
            "        (1 failed)\n",
            "        \n",
            "        \n",
            "      </span>\n",
            "      <div class=\"bar bar-completed\" style=\"width: 0.0%\"></div>\n",
            "      <div class=\"bar bar-running\" style=\"width: 0.0%\"></div>\n",
            "    </div>\n",
            "      </td>\n",
            "    </tr><tr id=\"job-17\">\n",
            "      <td>\n",
            "        17 \n",
            "      </td>\n",
            "      <td>\n",
            "        <span class=\"description-input\">runJob at PythonRDD.scala:153</span> \n",
            "        <a href=\"/jobs/job/?id=17\" class=\"name-link\">runJob at PythonRDD.scala:153</a>\n",
            "      </td>\n",
            "      <td>\n",
            "        2019/08/13 04:53:48\n",
            "      </td>\n",
            "      <td>55 ms</td>\n",
            "      <td class=\"stage-progress-cell\">\n",
            "        0/1\n",
            "        (1 failed)\n",
            "        \n",
            "      </td>\n",
            "      <td class=\"progress-cell\">\n",
            "        <div class=\"progress\">\n",
            "      <span style=\"text-align:center; position:absolute; width:100%; left:0;\">\n",
            "        0/1\n",
            "        \n",
            "        (1 failed)\n",
            "        \n",
            "        \n",
            "      </span>\n",
            "      <div class=\"bar bar-completed\" style=\"width: 0.0%\"></div>\n",
            "      <div class=\"bar bar-running\" style=\"width: 0.0%\"></div>\n",
            "    </div>\n",
            "      </td>\n",
            "    </tr><tr id=\"job-16\">\n",
            "      <td>\n",
            "        16 \n",
            "      </td>\n",
            "      <td>\n",
            "        <span class=\"description-input\">runJob at PythonRDD.scala:153</span> \n",
            "        <a href=\"/jobs/job/?id=16\" class=\"name-link\">runJob at PythonRDD.scala:153</a>\n",
            "      </td>\n",
            "      <td>\n",
            "        2019/08/13 04:53:22\n",
            "      </td>\n",
            "      <td>47 ms</td>\n",
            "      <td class=\"stage-progress-cell\">\n",
            "        0/1\n",
            "        (1 failed)\n",
            "        \n",
            "      </td>\n",
            "      <td class=\"progress-cell\">\n",
            "        <div class=\"progress\">\n",
            "      <span style=\"text-align:center; position:absolute; width:100%; left:0;\">\n",
            "        0/1\n",
            "        \n",
            "        (1 failed)\n",
            "        \n",
            "        \n",
            "      </span>\n",
            "      <div class=\"bar bar-completed\" style=\"width: 0.0%\"></div>\n",
            "      <div class=\"bar bar-running\" style=\"width: 0.0%\"></div>\n",
            "    </div>\n",
            "      </td>\n",
            "    </tr><tr id=\"job-14\">\n",
            "      <td>\n",
            "        14 \n",
            "      </td>\n",
            "      <td>\n",
            "        <span class=\"description-input\">runJob at PythonRDD.scala:153</span> \n",
            "        <a href=\"/jobs/job/?id=14\" class=\"name-link\">runJob at PythonRDD.scala:153</a>\n",
            "      </td>\n",
            "      <td>\n",
            "        2019/08/13 04:52:45\n",
            "      </td>\n",
            "      <td>84 ms</td>\n",
            "      <td class=\"stage-progress-cell\">\n",
            "        0/1\n",
            "        (1 failed)\n",
            "        \n",
            "      </td>\n",
            "      <td class=\"progress-cell\">\n",
            "        <div class=\"progress\">\n",
            "      <span style=\"text-align:center; position:absolute; width:100%; left:0;\">\n",
            "        0/1\n",
            "        \n",
            "        (1 failed)\n",
            "        \n",
            "        \n",
            "      </span>\n",
            "      <div class=\"bar bar-completed\" style=\"width: 0.0%\"></div>\n",
            "      <div class=\"bar bar-running\" style=\"width: 0.0%\"></div>\n",
            "    </div>\n",
            "      </td>\n",
            "    </tr>\n",
            "          </tbody>\n",
            "        </table>\n",
            "        \n",
            "      </div>\n",
            "      </div>\n",
            "        </div>\n",
            "      </body>\n",
            "    </html>"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ReoMdoeoGiRY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import xgboost as xgb\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import gzip\n",
        "import math\n",
        "import pickle\n",
        "import zlib\n",
        "import io\n",
        "import sklearn\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "from matplotlib import pyplot as pt\n",
        "import tensorboard\n",
        "import tensorflow\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import torchvision\n",
        "from collections import defaultdict\n",
        "from tqdm import tqdm, tqdm_notebook, tnrange"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RNyFNxr20W1R",
        "colab_type": "code",
        "outputId": "b21904f3-1478-4c21-df9f-9386fcba1c74",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 309
        }
      },
      "source": [
        "train, test=data.randomSplit([0.7, 0.3], seed = 123)\n",
        "train.show(10)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+--------+----+---------+----------+--------+---------------------+------------------+----------+-----------------+------------+-------------------+--------------+----------+-----------+-----+-----------------+-----------------+----------------+-----------------+----------------+-----------------+-----------------+-----------------+-----------------+-----------------+-----------------+-----------------+-----------------+-----------------+----------------+-----------------+-----------------+-----------------+-----------------+-----------------+----------------+---------------+-----------------+---------------+\n",
            "|ncodpers| age|ind_nuevo|antiguedad|cod_prov|ind_actividad_cliente|             renta|sexo_index|tiprel_1mes_index|indext_index|canal_entrada_index|segmento_index|fecha_year|fecha_month|total|ind_ahor_fin_ult1|ind_aval_fin_ult1|ind_cco_fin_ult1|ind_cder_fin_ult1|ind_cno_fin_ult1|ind_ctju_fin_ult1|ind_ctma_fin_ult1|ind_ctop_fin_ult1|ind_ctpp_fin_ult1|ind_deco_fin_ult1|ind_deme_fin_ult1|ind_dela_fin_ult1|ind_ecue_fin_ult1|ind_fond_fin_ult1|ind_hip_fin_ult1|ind_plan_fin_ult1|ind_pres_fin_ult1|ind_reca_fin_ult1|ind_tjcr_fin_ult1|ind_valo_fin_ult1|ind_viv_fin_ult1|ind_nomina_ult1|ind_nom_pens_ult1|ind_recibo_ult1|\n",
            "+--------+----+---------+----------+--------+---------------------+------------------+----------+-----------------+------------+-------------------+--------------+----------+-----------+-----+-----------------+-----------------+----------------+-----------------+----------------+-----------------+-----------------+-----------------+-----------------+-----------------+-----------------+-----------------+-----------------+-----------------+----------------+-----------------+-----------------+-----------------+-----------------+-----------------+----------------+---------------+-----------------+---------------+\n",
            "| 15889.0|56.0|      0.0|     245.0|    28.0|                  1.0|          326124.9|       0.0|              0.0|         0.0|                1.0|           2.0|         0|          1|    4|                0|                0|               1|                0|               0|                0|                0|                0|                1|                0|                0|                0|                0|                0|               0|                0|                0|                0|                1|                1|               0|            0.0|              0.0|              0|\n",
            "| 15894.0|59.0|      0.0|     246.0|    28.0|                  1.0|281757.72000000003|       0.0|              0.0|         0.0|                1.0|           2.0|         0|          1|   10|                0|                0|               1|                0|               1|                0|                0|                0|                0|                0|                0|                1|                1|                0|               0|                0|                0|                1|                1|                1|               0|            1.0|              1.0|              1|\n",
            "| 15895.0|49.0|      0.0|     208.0|    28.0|                  1.0|         205427.58|       1.0|              0.0|         0.0|                1.0|           0.0|         0|          1|    9|                0|                0|               1|                0|               1|                0|                0|                0|                0|                0|                0|                1|                1|                0|               0|                1|                0|                1|                1|                1|               0|            0.0|              0.0|              1|\n",
            "| 15897.0|61.0|      0.0|     246.0|    28.0|                  1.0|         175450.05|       0.0|              0.0|         0.0|                1.0|           2.0|         0|          1|   11|                0|                0|               1|                0|               1|                0|                0|                1|                0|                0|                0|                0|                1|                1|               0|                1|                0|                1|                1|                1|               0|            0.0|              1.0|              1|\n",
            "| 15899.0|57.0|      0.0|     246.0|    28.0|                  1.0|130835.63999999998|       0.0|              0.0|         0.0|                1.0|           2.0|         0|          1|    6|                0|                0|               1|                0|               0|                0|                0|                1|                1|                0|                0|                0|                0|                0|               0|                1|                0|                0|                0|                1|               0|            0.0|              0.0|              1|\n",
            "| 15901.0|55.0|      0.0|     246.0|    28.0|                  1.0|         167791.32|       0.0|              0.0|         0.0|                1.0|           2.0|         0|          1|    7|                0|                0|               1|                0|               0|                0|                0|                0|                1|                0|                0|                0|                1|                1|               0|                0|                0|                0|                1|                1|               0|            0.0|              0.0|              1|\n",
            "| 15903.0|56.0|      0.0|     246.0|    28.0|                  1.0|         106270.38|       0.0|              0.0|         0.0|                1.0|           0.0|         0|          1|    3|                0|                0|               1|                0|               0|                0|                0|                1|                0|                0|                0|                0|                0|                0|               0|                0|                0|                0|                1|                0|               0|            0.0|              0.0|              0|\n",
            "| 15906.0|55.0|      0.0|     227.0|    28.0|                  1.0|          81005.49|       1.0|              0.0|         0.0|                1.0|           2.0|         0|          1|    7|                0|                0|               0|                0|               1|                0|                0|                1|                1|                0|                0|                1|                0|                0|               1|                0|                0|                0|                0|                0|               0|            0.0|              1.0|              1|\n",
            "| 15907.0|51.0|      0.0|     246.0|    28.0|                  1.0|         246128.34|       0.0|              0.0|         0.0|                1.0|           2.0|         0|          1|    8|                0|                0|               1|                0|               0|                0|                0|                1|                0|                0|                0|                0|                0|                1|               0|                1|                0|                1|                1|                1|               0|            0.0|              0.0|              1|\n",
            "| 15908.0|57.0|      0.0|     246.0|    28.0|                  1.0|          77310.99|       0.0|              0.0|         0.0|                1.0|           2.0|         0|          1|   11|                0|                0|               1|                0|               1|                0|                0|                0|                1|                0|                0|                1|                1|                0|               0|                1|                0|                0|                1|                1|               0|            1.0|              1.0|              1|\n",
            "+--------+----+---------+----------+--------+---------------------+------------------+----------+-----------------+------------+-------------------+--------------+----------+-----------+-----+-----------------+-----------------+----------------+-----------------+----------------+-----------------+-----------------+-----------------+-----------------+-----------------+-----------------+-----------------+-----------------+-----------------+----------------+-----------------+-----------------+-----------------+-----------------+-----------------+----------------+---------------+-----------------+---------------+\n",
            "only showing top 10 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MKPonGjlU1_u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class RegressionColumnarDataset(Dataset):\n",
        "    def __init__(self, df, cats,dy):\n",
        "        self.dfcats = df[cats]\n",
        "        self.dfconts = df.drop(cats, axis=1)\n",
        "        self.dy=dy\n",
        "\n",
        "        \n",
        "        self.cats = np.stack([c.values for n, c in self.dfcats.items()], axis=1).astype(np.int64)\n",
        "        self.conts = np.stack([c.values for n, c in self.dfconts.items()], axis=1).astype(np.float32)\n",
        "        self.y = np.stack([c.values for n, c in self.dy.items()], axis=1).astype(np.float32)\n",
        "        \n",
        "    def __len__(self): return len(self.y)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return [self.cats[idx], self.conts[idx], self.y[idx]]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "11bSVRMnGnMa",
        "colab_type": "code",
        "outputId": "df435e2e-8887-42d3-f226-e442614fa325",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        }
      },
      "source": [
        "import sparkdl"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-4a9be7b8a3d0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0msparkdl\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sparkdl/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msparkdl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimageIO\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mimageSchema\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimageType\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreadImages\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msparkdl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransformers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras_image\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mKerasImageFileTransformer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msparkdl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransformers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnamed_image\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDeepImagePredictor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDeepImageFeaturizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msparkdl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransformers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtf_image\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTFImageTransformer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sparkdl/transformers/keras_image.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpyspark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mParams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTypeConverters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0msparkdl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtfx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msparkdl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransformers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mKSessionWrap\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m from sparkdl.param import (\n",
            "\u001b[0;31mAttributeError\u001b[0m: module 'sparkdl' has no attribute 'graph'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3U0m0-f3IxDc",
        "colab_type": "code",
        "outputId": "03b77476-d884-4abb-b4d5-964a35342f0f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        }
      },
      "source": [
        "train.items()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-45-e66f7d79b2e3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pyspark/sql/dataframe.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1298\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1299\u001b[0m             raise AttributeError(\n\u001b[0;32m-> 1300\u001b[0;31m                 \"'%s' object has no attribute '%s'\" % (self.__class__.__name__, name))\n\u001b[0m\u001b[1;32m   1301\u001b[0m         \u001b[0mjc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1302\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mColumn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'items'"
          ]
        }
      ]
    }
  ]
}